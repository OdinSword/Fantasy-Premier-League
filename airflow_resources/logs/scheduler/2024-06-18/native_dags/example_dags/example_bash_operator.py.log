[2024-06-18T10:02:08.629+0000] {processor.py:157} INFO - Started process (PID=197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:02:08.634+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:02:08.638+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:08.636+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:02:08.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:02:08.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:08.675+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 38, 664389, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:02:08.679+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:08.679+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:02:08.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:08.783+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 38, 782879, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:08.784+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:08.784+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:02:09.426+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:09.425+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 39, 424744, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:09.427+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:09.427+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:02:09.429+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:39.450+0000] {processor.py:157} INFO - Started process (PID=440) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:02:39.450+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:02:39.451+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:39.451+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:02:39.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:02:39.470+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:39.470+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:02:39.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:39.481+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:02:39.489+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.041 seconds
[2024-06-18T10:03:09.926+0000] {processor.py:157} INFO - Started process (PID=692) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:03:09.927+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:03:09.927+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:09.927+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:03:09.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:03:09.947+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:09.946+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:03:09.957+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:09.957+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:03:09.964+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.040 seconds
[2024-06-18T10:03:40.200+0000] {processor.py:157} INFO - Started process (PID=936) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:03:40.201+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:03:40.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.201+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:03:40.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:03:40.223+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.223+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:03:40.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.235+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:03:40.245+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T10:04:10.811+0000] {processor.py:157} INFO - Started process (PID=1178) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:04:10.811+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:04:10.812+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.812+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:04:10.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:04:10.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.823+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 818996, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:04:10.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.825+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:04:10.891+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.891+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 890841, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.892+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.892+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:04:11.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:11.133+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 41, 133373, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:11.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:11.134+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:04:11.135+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.965+0000] {processor.py:157} INFO - Started process (PID=1422) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:04:41.966+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:04:41.967+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.967+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:04:41.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:04:41.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.981+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 976209, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:04:41.984+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.984+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:04:42.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:42.259+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 12, 256415, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:42.285+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:42.284+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:04:42.703+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:42.702+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 12, 701026, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:42.705+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:42.704+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:04:42.707+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.873+0000] {processor.py:157} INFO - Started process (PID=1666) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:05:12.874+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:05:12.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.875+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:05:12.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:05:12.896+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.894+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 887026, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:05:12.897+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.897+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:05:13.191+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.189+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 186399, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.193+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.193+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:05:13.886+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.886+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 885405, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.887+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.887+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:05:13.889+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:44.285+0000] {processor.py:157} INFO - Started process (PID=1910) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:05:44.286+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:05:44.287+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.287+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:05:44.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:05:44.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.300+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:05:44.312+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.312+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:05:44.320+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.037 seconds
[2024-06-18T10:06:14.747+0000] {processor.py:157} INFO - Started process (PID=2151) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:06:14.748+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:06:14.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:14.748+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:06:14.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:06:14.768+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:14.765+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 44, 759158, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:06:14.769+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:14.769+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:06:14.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:14.997+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 44, 996285, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.000+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:06:15.519+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.518+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 45, 517155, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.519+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.519+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:06:15.521+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:45.695+0000] {processor.py:157} INFO - Started process (PID=2400) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:06:45.696+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:06:45.697+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:45.697+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:06:45.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:06:45.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:45.729+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:06:45.746+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:45.746+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:06:45.756+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.065 seconds
[2024-06-18T10:07:15.803+0000] {processor.py:157} INFO - Started process (PID=2642) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:07:15.804+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:07:15.805+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:15.805+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:07:15.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:07:15.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:15.825+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:07:15.837+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:15.837+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:07:15.844+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.042 seconds
[2024-06-18T10:07:46.106+0000] {processor.py:157} INFO - Started process (PID=2886) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:07:46.107+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:07:46.108+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:46.108+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:07:46.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:07:46.137+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:46.137+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:07:46.154+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:46.153+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:07:46.164+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T10:08:17.133+0000] {processor.py:157} INFO - Started process (PID=3120) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:08:17.135+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:08:17.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:17.135+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:08:17.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:08:17.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:17.198+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 7, 47, 189818, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:08:17.202+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:17.201+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:08:17.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:17.654+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 7, 47, 652648, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:08:17.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:17.656+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:08:18.154+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.153+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 7, 48, 152279, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:08:18.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.156+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:08:18.161+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:08:48.373+0000] {processor.py:157} INFO - Started process (PID=3374) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:08:48.374+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:08:48.376+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:48.375+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:08:48.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:08:48.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:48.406+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:08:48.419+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:48.419+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:08:48.427+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T10:09:18.530+0000] {processor.py:157} INFO - Started process (PID=3613) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:09:18.531+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:09:18.532+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:18.532+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:09:18.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:09:18.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:18.550+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 48, 544097, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:09:18.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:18.553+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:09:18.803+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:18.802+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 48, 802102, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:18.803+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:18.803+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:09:19.617+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.616+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 615853, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.618+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.618+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:09:19.619+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:49.652+0000] {processor.py:157} INFO - Started process (PID=3859) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:09:49.654+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:09:49.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:49.655+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:09:49.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:09:49.680+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:49.680+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:09:49.694+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:49.694+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:09:49.705+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.055 seconds
[2024-06-18T10:10:20.140+0000] {processor.py:157} INFO - Started process (PID=4100) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:10:20.141+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:10:20.142+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:20.142+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:10:20.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:10:20.175+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:20.175+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:10:20.188+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:20.188+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:10:20.198+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T10:10:50.876+0000] {processor.py:157} INFO - Started process (PID=4343) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:10:50.878+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:10:50.878+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:50.878+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:10:50.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:10:50.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:50.904+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:10:50.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:50.917+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:10:50.928+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T10:11:21.880+0000] {processor.py:157} INFO - Started process (PID=4581) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:11:21.882+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:11:21.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:21.883+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:11:21.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:11:21.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:21.902+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 51, 895772, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:11:21.906+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:21.906+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:11:21.975+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:21.974+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 51, 974237, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:21.975+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:21.975+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:11:22.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.065+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 64979, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.067+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:11:22.069+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:52.172+0000] {processor.py:157} INFO - Started process (PID=4819) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:11:52.173+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:11:52.173+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:52.173+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:11:52.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:11:52.195+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:52.195+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:11:52.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:52.207+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:11:52.216+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T10:12:22.551+0000] {processor.py:157} INFO - Started process (PID=5063) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:12:22.552+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:12:22.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:22.553+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:12:22.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:12:22.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:22.588+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:12:22.614+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:22.614+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:12:22.637+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.088 seconds
[2024-06-18T10:12:52.969+0000] {processor.py:157} INFO - Started process (PID=5304) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:12:52.973+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:12:52.974+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:52.974+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:12:52.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:12:53.013+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:53.007+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 12, 22, 994554, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:12:53.014+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:53.013+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:12:53.420+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:53.419+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 12, 23, 417795, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:12:53.421+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:53.421+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:12:53.726+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:53.725+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 12, 23, 724187, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:12:53.727+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:53.727+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:12:53.730+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:13:23.798+0000] {processor.py:157} INFO - Started process (PID=5556) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:13:23.799+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:13:23.800+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:23.800+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:13:23.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:13:23.827+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:23.827+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:13:23.841+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:23.841+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:13:23.854+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T10:13:54.025+0000] {processor.py:157} INFO - Started process (PID=5792) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:13:54.027+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:13:54.028+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:54.027+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:13:54.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:13:54.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:54.059+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:13:54.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:54.075+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:13:54.104+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.082 seconds
[2024-06-18T10:14:24.522+0000] {processor.py:157} INFO - Started process (PID=6033) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:14:24.523+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:14:24.525+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:24.524+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:14:24.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:14:24.570+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:24.566+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 13, 54, 554155, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:14:24.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:24.571+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:14:24.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:24.993+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 13, 54, 991443, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:24.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:24.998+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:14:25.186+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:25.185+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 13, 55, 183553, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:25.189+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:25.188+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:14:25.192+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:55.936+0000] {processor.py:157} INFO - Started process (PID=6284) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:14:55.937+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:14:55.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:55.937+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:14:55.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:14:55.953+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:55.951+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 25, 945828, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:14:55.954+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:55.954+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:14:56.285+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.283+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 26, 282290, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:56.287+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.286+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:14:57.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.204+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 27, 201715, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.207+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:14:57.211+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:15:27.449+0000] {processor.py:157} INFO - Started process (PID=6531) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:15:27.452+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:15:27.453+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:27.452+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:15:27.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:15:27.479+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:27.476+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 57, 468152, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:15:27.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:27.480+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:15:27.981+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:27.978+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 57, 975337, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:15:27.984+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:27.984+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:15:28.096+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.095+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 58, 94918, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:15:28.098+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.097+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:15:28.100+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:15:58.783+0000] {processor.py:157} INFO - Started process (PID=6775) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:15:58.786+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:15:58.787+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.787+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:15:58.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:15:58.818+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.814+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 28, 803402, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:15:58.819+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.819+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:15:59.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:59.233+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 29, 231105, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:15:59.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:59.235+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:15:59.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:59.299+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 29, 298180, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:15:59.302+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:59.302+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:15:59.307+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.436+0000] {processor.py:157} INFO - Started process (PID=7024) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:16:29.437+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:16:29.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.437+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:16:29.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:16:29.451+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.449+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 444755, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:16:29.452+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.452+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:16:29.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.915+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 913226, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.918+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:16:30.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.435+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 0, 432588, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:30.441+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.440+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:16:30.449+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:01.013+0000] {processor.py:157} INFO - Started process (PID=7275) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:17:01.015+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:17:01.015+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:01.015+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:17:01.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:17:01.043+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:01.043+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:17:01.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:01.059+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:17:01.068+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T10:17:31.147+0000] {processor.py:157} INFO - Started process (PID=7514) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:17:31.148+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:17:31.148+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.148+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:17:31.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:17:31.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.166+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 158611, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:17:31.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.169+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:17:31.604+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.601+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 598820, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.607+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.607+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:17:31.742+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.741+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 739079, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.745+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.745+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:17:31.749+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:02.314+0000] {processor.py:157} INFO - Started process (PID=7757) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:18:02.315+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:18:02.316+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.316+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:18:02.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:18:02.395+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.395+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:18:02.419+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.419+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:18:02.439+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.128 seconds
[2024-06-18T10:18:32.749+0000] {processor.py:157} INFO - Started process (PID=7996) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:18:32.750+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:18:32.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.751+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:18:32.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:18:32.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.786+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:18:32.800+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.800+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:18:32.809+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.064 seconds
[2024-06-18T10:19:03.540+0000] {processor.py:157} INFO - Started process (PID=8235) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:19:03.541+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:19:03.543+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.542+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:19:03.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:19:03.626+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.620+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 33, 590647, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:19:03.632+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.632+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:19:03.663+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.663+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 33, 662598, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:03.664+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.664+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:19:04.097+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:04.095+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 34, 92999, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:04.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:04.099+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:19:04.106+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.895+0000] {processor.py:157} INFO - Started process (PID=8485) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:19:34.896+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:19:34.897+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.896+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:19:34.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:19:34.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.914+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 906806, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:19:34.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.917+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:19:35.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:35.369+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 5, 366868, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:35.374+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:35.373+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:19:36.132+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:36.131+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 6, 130381, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:36.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:36.133+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:19:36.136+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:20:07.320+0000] {processor.py:157} INFO - Started process (PID=8742) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:20:07.321+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:20:07.322+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:07.322+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:20:07.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:20:07.350+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:07.347+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 37, 337471, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:20:07.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:07.351+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:20:07.646+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:07.644+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 37, 641382, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:20:07.648+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:07.648+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:20:07.685+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:07.683+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 37, 681703, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:20:07.687+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:07.686+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:20:07.691+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:20:38.308+0000] {processor.py:157} INFO - Started process (PID=8986) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:20:38.309+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:20:38.310+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:38.310+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:20:38.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:20:38.346+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:38.343+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 20, 8, 332453, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:20:38.347+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:38.347+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:20:38.390+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:38.390+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 20, 8, 390078, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:20:38.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:38.391+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:20:39.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:39.230+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 20, 9, 228491, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:20:39.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:39.234+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:20:39.239+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:21:09.336+0000] {processor.py:157} INFO - Started process (PID=9232) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:21:09.336+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:21:09.337+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:09.337+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:21:09.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:21:09.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:09.365+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:21:09.379+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:09.379+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:21:09.388+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.055 seconds
[2024-06-18T10:21:39.598+0000] {processor.py:157} INFO - Started process (PID=9471) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:21:39.601+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:21:39.604+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:39.603+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:21:39.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:21:39.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:39.648+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 9, 633992, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:21:39.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:39.654+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:21:40.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:40.129+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 10, 125311, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:21:40.132+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:40.131+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:21:40.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:40.225+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 10, 224413, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:21:40.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:40.227+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:21:40.240+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:10.821+0000] {processor.py:157} INFO - Started process (PID=9715) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:22:10.824+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:22:10.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:10.825+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:22:10.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:22:10.881+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:10.881+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:22:10.901+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:10.901+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:22:10.916+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.097 seconds
[2024-06-18T10:22:41.869+0000] {processor.py:157} INFO - Started process (PID=9959) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:22:41.870+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:22:41.871+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:41.871+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:22:41.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:22:41.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:41.910+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 11, 893549, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:22:41.919+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:41.918+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:22:42.258+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:42.245+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 12, 237653, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:42.306+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:42.305+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:22:42.819+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:42.811+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 12, 806585, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:42.822+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:42.822+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:22:42.833+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:13.109+0000] {processor.py:157} INFO - Started process (PID=10208) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:23:13.111+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:23:13.112+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:13.112+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:23:13.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:23:13.129+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:13.127+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 43, 122116, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:23:13.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:13.130+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:23:13.443+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:13.442+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 43, 440201, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:13.445+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:13.445+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:23:13.496+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:13.494+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 43, 493085, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:13.498+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:13.498+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:23:13.502+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:44.026+0000] {processor.py:157} INFO - Started process (PID=10452) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:23:44.030+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:23:44.033+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:44.033+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:23:44.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:23:44.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:44.075+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:23:44.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:44.125+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:23:44.145+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.124 seconds
[2024-06-18T10:24:14.382+0000] {processor.py:157} INFO - Started process (PID=10696) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:24:14.383+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:24:14.384+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:14.384+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:24:14.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:24:14.411+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:14.411+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:24:14.423+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:14.423+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:24:14.433+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T10:24:45.125+0000] {processor.py:157} INFO - Started process (PID=10940) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:24:45.127+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:24:45.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:45.128+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:24:45.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:24:45.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:45.169+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:24:45.181+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:45.181+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:24:45.189+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.069 seconds
[2024-06-18T10:25:15.258+0000] {processor.py:157} INFO - Started process (PID=11182) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:25:15.259+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:25:15.259+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:15.259+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:25:15.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:25:15.284+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:15.281+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 45, 272271, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:25:15.286+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:15.286+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:25:15.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:15.773+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 45, 770359, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:15.777+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:15.777+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:25:15.809+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:15.809+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 45, 808276, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:15.810+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:15.810+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:25:15.812+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:46.167+0000] {processor.py:157} INFO - Started process (PID=11428) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:25:46.169+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:25:46.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:46.169+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:25:46.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:25:46.199+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:46.199+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:25:46.211+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:46.211+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:25:46.303+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.140 seconds
[2024-06-18T10:26:16.761+0000] {processor.py:157} INFO - Started process (PID=11665) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:26:16.762+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:26:16.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:16.763+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:26:16.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:26:16.801+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:16.801+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:26:16.820+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:16.819+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:26:16.831+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.073 seconds
[2024-06-18T10:26:46.867+0000] {processor.py:157} INFO - Started process (PID=11901) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:26:46.869+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:26:46.870+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:46.870+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:26:46.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:26:46.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:46.969+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 16, 964704, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:26:46.971+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:46.971+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:26:47.068+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:47.067+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 17, 67243, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:47.068+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:47.068+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:26:47.638+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:47.636+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 17, 632672, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:47.641+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:47.641+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:26:47.646+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:18.425+0000] {processor.py:157} INFO - Started process (PID=12153) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:27:18.426+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:27:18.427+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:18.427+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:27:18.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:27:18.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:18.457+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:27:18.475+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:18.475+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:27:18.491+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.069 seconds
[2024-06-18T10:59:26.288+0000] {processor.py:157} INFO - Started process (PID=12292) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:59:26.289+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:59:26.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.289+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:59:26.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:59:26.332+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.332+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:59:26.443+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.443+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:59:26.501+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.215 seconds
[2024-06-18T10:59:57.417+0000] {processor.py:157} INFO - Started process (PID=12538) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:59:57.418+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T10:59:57.419+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:57.418+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:59:57.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T10:59:57.441+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:57.441+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T10:59:57.451+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:57.451+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:59:57.458+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T11:00:28.251+0000] {processor.py:157} INFO - Started process (PID=12780) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:00:28.252+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:00:28.252+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.252+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:00:28.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:00:28.267+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.266+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 58, 260895, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:00:28.268+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.268+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:00:28.476+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.471+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 58, 469274, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:28.477+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.477+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:00:28.642+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.642+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 58, 641519, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:28.643+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.643+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:00:28.645+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.947+0000] {processor.py:157} INFO - Started process (PID=13019) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:00:58.948+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:00:58.949+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.948+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:00:58.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:00:58.968+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.966+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 960620, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:00:58.969+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.969+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:00:59.468+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:59.467+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 29, 466250, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:59.470+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:59.470+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:01:00.394+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:00.394+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 30, 393597, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:01:00.395+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:00.395+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:01:00.397+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:01:31.301+0000] {processor.py:157} INFO - Started process (PID=13266) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:01:31.302+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:01:31.303+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:31.303+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:01:31.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:01:31.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:31.327+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:01:31.344+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:31.344+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:01:31.355+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T11:02:01.440+0000] {processor.py:157} INFO - Started process (PID=13507) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:02:01.441+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:02:01.442+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:01.441+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:02:01.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:02:01.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:01.456+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 1, 31, 450893, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:02:01.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:01.458+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:02:01.685+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:01.685+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 1, 31, 684820, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:01.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:01.686+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:02:02.077+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:02.076+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 1, 32, 75376, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:02.078+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:02.078+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:02:02.080+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:32.348+0000] {processor.py:157} INFO - Started process (PID=13761) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:02:32.349+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:02:32.349+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:32.349+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:02:32.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:02:32.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:32.371+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:02:32.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:32.383+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:02:32.392+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T11:03:03.108+0000] {processor.py:157} INFO - Started process (PID=14000) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:03:03.109+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:03:03.110+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:03.110+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:03:03.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:03:03.142+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:03.140+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 33, 127286, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:03:03.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:03.143+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:03:03.641+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:03.640+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 33, 637857, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:03:03.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:03.683+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:03:04.418+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:04.417+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 34, 417340, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:03:04.418+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:04.418+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:03:04.419+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:03:34.900+0000] {processor.py:157} INFO - Started process (PID=14249) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:03:34.901+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:03:34.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:34.902+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:03:34.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:03:34.934+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:34.934+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:03:34.947+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:34.947+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:03:34.956+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T11:04:05.830+0000] {processor.py:157} INFO - Started process (PID=14488) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:04:05.831+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:04:05.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:05.831+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:04:05.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:04:05.858+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:05.858+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:04:05.871+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:05.871+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:04:05.885+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T11:04:36.517+0000] {processor.py:157} INFO - Started process (PID=14726) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:04:36.519+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:04:36.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:36.520+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:04:36.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:04:36.556+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:36.556+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:04:36.576+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:36.576+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:04:36.589+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.078 seconds
[2024-06-18T11:05:06.701+0000] {processor.py:157} INFO - Started process (PID=14965) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:05:06.703+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:05:06.704+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:06.703+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:05:06.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:05:06.736+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:06.736+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:05:06.749+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:06.749+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:05:06.758+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T11:05:37.335+0000] {processor.py:157} INFO - Started process (PID=15206) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:05:37.337+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:05:37.338+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:37.338+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:05:37.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:05:37.363+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:37.363+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:05:37.375+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:37.375+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:05:37.383+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T11:06:07.735+0000] {processor.py:157} INFO - Started process (PID=15450) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:06:07.739+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:06:07.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:07.740+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:06:07.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:06:07.910+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:07.910+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:06:07.978+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:07.978+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:06:08.003+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.291 seconds
[2024-06-18T11:06:38.354+0000] {processor.py:157} INFO - Started process (PID=15692) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:06:38.357+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:06:38.358+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:38.358+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:06:38.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:06:38.401+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:38.391+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 8, 379541, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:06:38.401+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:38.401+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:06:38.841+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:38.840+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 8, 838709, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:38.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:38.842+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:06:39.288+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:39.287+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 9, 287229, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:39.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:39.293+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:06:39.297+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:07:10.092+0000] {processor.py:157} INFO - Started process (PID=15936) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:07:10.093+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:07:10.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:10.094+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:07:10.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:07:10.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:10.169+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:07:10.198+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:10.198+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:07:10.227+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.139 seconds
[2024-06-18T11:07:40.850+0000] {processor.py:157} INFO - Started process (PID=16179) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:07:40.860+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:07:40.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:40.864+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:07:40.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:07:41.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:41.098+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:07:41.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:41.161+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:07:41.215+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.464 seconds
[2024-06-18T11:08:12.207+0000] {processor.py:157} INFO - Started process (PID=16424) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:08:12.209+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:08:12.211+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:12.210+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:08:12.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:08:12.257+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:12.257+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:08:12.286+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:12.285+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:08:12.302+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.100 seconds
[2024-06-18T11:08:42.422+0000] {processor.py:157} INFO - Started process (PID=16665) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:08:42.424+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:08:42.425+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:42.424+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:08:42.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:08:42.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:42.457+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:08:42.474+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:42.474+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:08:42.492+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.072 seconds
[2024-06-18T11:09:13.035+0000] {processor.py:157} INFO - Started process (PID=16909) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:09:13.037+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:09:13.038+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:13.038+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:09:13.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:09:13.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:13.076+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 43, 63855, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:09:13.082+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:13.081+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:09:13.510+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:13.508+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 43, 506701, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:13.512+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:13.511+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:09:13.986+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:13.985+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 43, 985237, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:13.987+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:13.987+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:09:13.989+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:44.871+0000] {processor.py:157} INFO - Started process (PID=17153) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:09:44.873+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:09:44.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:44.874+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:09:44.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:09:44.914+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:44.910+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 14, 900010, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:09:44.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:44.917+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:09:45.303+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:45.301+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 15, 299930, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:45.306+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:45.305+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:09:45.548+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:45.546+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 15, 543281, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:45.551+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:45.551+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:09:45.556+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:15.712+0000] {processor.py:157} INFO - Started process (PID=17400) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:10:15.713+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:10:15.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:15.714+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:10:15.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:10:15.755+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:15.755+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:10:15.767+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:15.767+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:10:15.776+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T11:10:45.841+0000] {processor.py:157} INFO - Started process (PID=17641) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:10:45.843+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:10:45.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:45.844+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:10:45.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:10:45.878+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:45.875+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 15, 866196, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:10:45.879+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:45.879+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:10:46.193+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:46.188+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 16, 186833, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:46.195+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:46.195+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:10:46.498+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:46.497+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'example_bash_operator', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 16, 494883, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:46.501+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:46.501+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:10:46.506+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'example_bash_operator'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:12:14.595+0000] {processor.py:157} INFO - Started process (PID=197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:12:14.597+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:12:14.598+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.598+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:12:14.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:12:14.689+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.689+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.699+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.705+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.705+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.706+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.706+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:12:14.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.715+0000] {dag.py:2963} INFO - Creating ORM DAG for example_bash_operator
[2024-06-18T11:12:14.722+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.721+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:12:14.733+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.139 seconds
[2024-06-18T11:12:45.343+0000] {processor.py:157} INFO - Started process (PID=441) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:12:45.345+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:12:45.345+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.345+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:12:45.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:12:45.372+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.372+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:12:45.385+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.385+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:12:45.395+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T11:13:15.539+0000] {processor.py:157} INFO - Started process (PID=678) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:13:15.540+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:13:15.541+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.540+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:13:15.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:13:15.563+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.563+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:13:15.575+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.575+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:13:15.584+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T11:13:45.734+0000] {processor.py:157} INFO - Started process (PID=921) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:13:45.735+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:13:45.736+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.736+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:13:45.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:13:45.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.763+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:13:45.776+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.776+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:13:45.786+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T11:14:16.750+0000] {processor.py:157} INFO - Started process (PID=1169) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:14:16.755+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:14:16.768+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.764+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:14:16.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:14:16.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.943+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:14:16.993+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.993+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:14:17.079+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.359 seconds
[2024-06-18T11:14:47.640+0000] {processor.py:157} INFO - Started process (PID=1427) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:14:47.642+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:14:47.643+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:47.642+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:14:47.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:14:47.666+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:47.666+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:14:47.680+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:47.680+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:14:47.689+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T11:15:18.149+0000] {processor.py:157} INFO - Started process (PID=1671) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:15:18.150+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:15:18.151+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:18.151+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:15:18.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:15:18.175+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:18.175+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:15:18.188+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:18.188+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:15:18.201+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T11:15:48.376+0000] {processor.py:157} INFO - Started process (PID=1908) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:15:48.378+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:15:48.378+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:48.378+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:15:48.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:15:48.403+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:48.403+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:15:48.414+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:48.414+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:15:48.426+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T11:22:33.942+0000] {processor.py:157} INFO - Started process (PID=197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:22:33.946+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:22:33.947+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.947+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:22:33.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:22:33.985+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.985+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:22:34.013+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:34.013+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:22:34.030+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.092 seconds
[2024-06-18T11:23:06.229+0000] {processor.py:157} INFO - Started process (PID=447) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:23:06.252+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:23:06.257+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:06.256+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:23:06.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:23:06.375+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:06.375+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:23:06.446+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:06.446+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:23:06.486+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.273 seconds
[2024-06-18T11:23:37.111+0000] {processor.py:157} INFO - Started process (PID=694) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:23:37.113+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:23:37.113+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:37.113+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:23:37.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:23:37.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:37.143+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:23:37.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:37.159+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:23:37.171+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T11:24:08.189+0000] {processor.py:157} INFO - Started process (PID=943) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:24:08.191+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:24:08.194+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:08.194+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:24:08.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:24:08.304+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:08.304+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:24:08.332+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:08.332+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:24:08.374+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.199 seconds
[2024-06-18T11:24:38.722+0000] {processor.py:157} INFO - Started process (PID=1196) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:24:38.723+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:24:38.724+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:38.724+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:24:38.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:24:38.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:38.760+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:24:38.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:38.775+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:24:38.786+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T11:25:09.102+0000] {processor.py:157} INFO - Started process (PID=1440) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:25:09.103+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:25:09.103+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:09.103+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:25:09.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:25:09.123+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:09.123+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:25:09.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:09.134+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:25:09.143+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.042 seconds
[2024-06-18T11:25:39.929+0000] {processor.py:157} INFO - Started process (PID=1684) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:25:39.930+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:25:39.930+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:39.930+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:25:39.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:25:39.950+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:39.950+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:25:39.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:39.963+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:25:39.972+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T11:26:10.128+0000] {processor.py:157} INFO - Started process (PID=1922) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:26:10.129+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:26:10.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:10.130+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:26:10.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:26:10.162+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:10.162+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:26:10.176+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:10.176+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:26:10.186+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T11:26:40.429+0000] {processor.py:157} INFO - Started process (PID=2174) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:26:40.430+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:26:40.431+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:40.431+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:26:40.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:26:40.466+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:40.466+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:26:40.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:40.480+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:26:40.491+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.066 seconds
[2024-06-18T11:27:11.188+0000] {processor.py:157} INFO - Started process (PID=2418) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:27:11.190+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:27:11.191+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:11.191+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:27:11.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:27:11.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:11.231+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:27:11.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:11.246+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:27:11.257+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.073 seconds
[2024-06-18T11:27:41.359+0000] {processor.py:157} INFO - Started process (PID=2668) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:27:41.360+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:27:41.361+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:41.361+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:27:41.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:27:41.385+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:41.384+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:27:41.398+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:41.397+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:27:41.408+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T11:28:11.849+0000] {processor.py:157} INFO - Started process (PID=2914) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:28:11.851+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:28:11.851+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:11.851+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:28:11.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:28:11.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:11.883+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:28:11.897+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:11.897+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:28:11.907+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.063 seconds
[2024-06-18T11:28:42.409+0000] {processor.py:157} INFO - Started process (PID=3164) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:28:42.412+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:28:42.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:42.414+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:28:42.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:28:42.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:42.481+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:28:42.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:42.502+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:28:42.517+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.113 seconds
[2024-06-18T11:29:12.987+0000] {processor.py:157} INFO - Started process (PID=3410) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:29:12.989+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:29:12.989+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:12.989+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:29:12.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:29:13.024+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:13.024+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:29:13.045+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:13.045+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:29:13.056+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.072 seconds
[2024-06-18T11:29:43.717+0000] {processor.py:157} INFO - Started process (PID=3662) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:29:43.718+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:29:43.719+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:43.719+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:29:43.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:29:43.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:43.792+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:29:43.812+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:43.812+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:29:43.824+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.112 seconds
[2024-06-18T11:30:14.299+0000] {processor.py:157} INFO - Started process (PID=3906) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:30:14.300+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:30:14.301+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:14.301+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:30:14.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:30:14.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:14.334+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:30:14.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:14.351+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:30:14.363+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.066 seconds
[2024-06-18T11:30:44.862+0000] {processor.py:157} INFO - Started process (PID=4150) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:30:44.864+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:30:44.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:44.865+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:30:44.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:30:44.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:44.902+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:30:44.923+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:44.923+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:30:44.936+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.076 seconds
[2024-06-18T11:31:15.421+0000] {processor.py:157} INFO - Started process (PID=4394) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:31:15.422+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:31:15.424+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:15.423+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:31:15.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:31:15.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:15.456+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:31:15.470+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:15.470+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:31:15.483+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T11:31:45.979+0000] {processor.py:157} INFO - Started process (PID=4639) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:31:45.981+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:31:45.982+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:45.982+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:31:45.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:31:46.015+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:46.015+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:31:46.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:46.029+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:31:46.039+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.063 seconds
[2024-06-18T11:32:16.306+0000] {processor.py:157} INFO - Started process (PID=4883) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:32:16.307+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:32:16.308+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:16.308+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:32:16.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:32:16.343+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:16.343+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:32:16.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:16.359+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:32:16.373+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.071 seconds
[2024-06-18T11:32:46.850+0000] {processor.py:157} INFO - Started process (PID=5135) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:32:46.851+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:32:46.852+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:46.852+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:32:46.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:32:46.885+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:46.885+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:32:46.921+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:46.921+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:32:46.933+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.086 seconds
[2024-06-18T11:33:17.282+0000] {processor.py:157} INFO - Started process (PID=5379) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:33:17.283+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:33:17.284+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:17.284+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:33:17.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:33:17.318+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:17.317+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:33:17.330+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:17.330+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:33:17.340+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T11:33:48.100+0000] {processor.py:157} INFO - Started process (PID=5623) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:33:48.101+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:33:48.102+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:48.102+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:33:48.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:33:48.139+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:48.139+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:33:48.152+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:48.152+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:33:48.161+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.064 seconds
[2024-06-18T11:34:18.949+0000] {processor.py:157} INFO - Started process (PID=5867) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:34:18.950+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:34:18.950+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:18.950+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:34:18.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:34:18.971+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:18.971+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:34:18.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:18.982+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:34:18.992+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T11:34:49.480+0000] {processor.py:157} INFO - Started process (PID=6111) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:34:49.481+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:34:49.482+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:49.482+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:34:49.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:34:49.516+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:49.516+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:34:49.528+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:49.528+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:34:49.538+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T11:35:19.732+0000] {processor.py:157} INFO - Started process (PID=6355) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:35:19.734+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:35:19.735+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:19.735+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:35:19.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:35:19.772+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:19.772+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:35:19.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:19.786+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:35:19.796+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T11:35:50.325+0000] {processor.py:157} INFO - Started process (PID=6599) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:35:50.326+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:35:50.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:50.327+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:35:50.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:35:50.360+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:50.359+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:35:50.378+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:50.378+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:35:50.389+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.066 seconds
[2024-06-18T11:36:21.143+0000] {processor.py:157} INFO - Started process (PID=6843) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:36:21.144+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:36:21.146+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:21.145+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:36:21.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:36:21.183+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:21.183+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:36:21.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:21.197+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:36:21.206+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T11:36:51.624+0000] {processor.py:157} INFO - Started process (PID=7087) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:36:51.625+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:36:51.626+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:51.625+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:36:51.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:36:51.659+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:51.659+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:36:51.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:51.674+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:36:51.685+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T11:37:22.145+0000] {processor.py:157} INFO - Started process (PID=7331) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:37:22.146+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:37:22.147+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:22.147+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:37:22.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:37:22.180+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:22.180+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:37:22.193+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:22.193+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:37:22.202+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T11:37:52.793+0000] {processor.py:157} INFO - Started process (PID=7583) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:37:52.795+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:37:52.795+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:52.795+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:37:52.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:37:52.826+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:52.826+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:37:52.840+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:52.840+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:37:52.850+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T11:38:23.611+0000] {processor.py:157} INFO - Started process (PID=7827) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:38:23.614+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:38:23.616+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:23.616+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:38:23.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:38:23.646+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:23.646+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:38:23.662+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:23.662+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:38:23.672+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.064 seconds
[2024-06-18T11:38:54.194+0000] {processor.py:157} INFO - Started process (PID=8070) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:38:54.195+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:38:54.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:54.196+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:38:54.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:38:54.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:54.230+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:38:54.243+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:54.243+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:38:54.252+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T11:39:24.742+0000] {processor.py:157} INFO - Started process (PID=8314) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:39:24.743+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:39:24.745+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:24.745+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:39:24.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:39:24.808+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:24.808+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:39:24.868+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:24.867+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:39:24.885+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.146 seconds
[2024-06-18T11:39:55.353+0000] {processor.py:157} INFO - Started process (PID=8558) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:39:55.354+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:39:55.355+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:55.355+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:39:55.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:39:55.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:55.391+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:39:55.405+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:55.405+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:39:55.418+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T11:40:25.858+0000] {processor.py:157} INFO - Started process (PID=8802) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:40:25.859+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:40:25.860+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:25.860+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:40:25.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:40:26.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:26.016+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:40:26.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:26.036+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:40:26.049+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.195 seconds
[2024-06-18T11:40:56.817+0000] {processor.py:157} INFO - Started process (PID=9050) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:40:56.818+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:40:56.819+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:56.819+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:40:56.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:40:56.852+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:56.851+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:40:56.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:56.865+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:40:56.875+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T11:41:27.180+0000] {processor.py:157} INFO - Started process (PID=9298) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:41:27.181+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:41:27.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:27.182+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:41:27.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:41:27.217+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:27.216+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:41:27.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:27.234+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:41:27.245+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T11:41:58.060+0000] {processor.py:157} INFO - Started process (PID=9542) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:41:58.061+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:41:58.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:58.062+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:41:58.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:41:58.098+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:58.098+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:41:58.111+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:58.111+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:41:58.122+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.066 seconds
[2024-06-18T11:42:28.253+0000] {processor.py:157} INFO - Started process (PID=9786) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:42:28.256+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:42:28.257+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:28.256+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:42:28.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:42:28.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:28.289+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:42:28.303+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:28.303+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:42:28.401+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.153 seconds
[2024-06-18T11:42:58.863+0000] {processor.py:157} INFO - Started process (PID=10038) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:42:58.865+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:42:58.868+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:58.867+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:42:58.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:42:58.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:58.908+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:42:58.933+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:58.933+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:42:58.948+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.091 seconds
[2024-06-18T11:43:29.662+0000] {processor.py:157} INFO - Started process (PID=10289) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:43:29.663+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:43:29.663+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:29.663+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:43:29.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:43:29.694+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:29.694+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:43:29.711+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:29.710+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:43:29.723+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.063 seconds
[2024-06-18T11:44:00.584+0000] {processor.py:157} INFO - Started process (PID=10533) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:44:00.587+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:44:00.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:00.588+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:44:00.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:44:00.627+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:00.627+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:44:00.646+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:00.646+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:44:00.660+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.079 seconds
[2024-06-18T11:44:31.564+0000] {processor.py:157} INFO - Started process (PID=10777) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:44:31.566+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:44:31.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:31.566+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:44:31.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:44:31.603+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:31.603+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:44:31.722+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:31.722+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:44:31.732+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.172 seconds
[2024-06-18T11:45:02.709+0000] {processor.py:157} INFO - Started process (PID=11021) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:45:02.710+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:45:02.711+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:02.711+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:45:02.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:45:02.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:02.747+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:45:02.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:02.760+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:45:02.771+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.066 seconds
[2024-06-18T11:45:33.234+0000] {processor.py:157} INFO - Started process (PID=11265) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:45:33.235+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:45:33.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:33.236+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:45:33.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:45:33.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:33.269+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:45:33.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:33.282+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:45:33.292+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T11:46:04.316+0000] {processor.py:157} INFO - Started process (PID=11509) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:46:04.318+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:46:04.319+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:04.318+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:46:04.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:46:04.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:04.464+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:46:04.475+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:04.475+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:46:04.485+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.173 seconds
[2024-06-18T11:46:34.535+0000] {processor.py:157} INFO - Started process (PID=11753) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:46:34.535+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:46:34.536+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.536+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:46:34.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:46:34.558+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.558+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:46:34.657+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.657+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:46:34.667+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.134 seconds
[2024-06-18T11:47:05.425+0000] {processor.py:157} INFO - Started process (PID=11997) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:47:05.426+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:47:05.427+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.426+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:47:05.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:47:05.452+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.452+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:47:05.466+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.466+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:47:05.477+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T11:47:35.546+0000] {processor.py:157} INFO - Started process (PID=12245) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:47:35.547+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:47:35.547+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.547+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:47:35.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:47:35.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.568+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:47:35.582+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.582+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:47:35.592+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.049 seconds
[2024-06-18T11:48:06.327+0000] {processor.py:157} INFO - Started process (PID=12493) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:48:06.328+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:48:06.328+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.328+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:48:06.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:48:06.454+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.454+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:48:06.465+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.465+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:48:06.475+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.150 seconds
[2024-06-18T11:48:37.465+0000] {processor.py:157} INFO - Started process (PID=12737) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:48:37.466+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:48:37.467+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:37.467+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:48:37.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:48:37.498+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:37.498+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:48:37.512+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:37.512+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:48:37.523+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T11:49:08.347+0000] {processor.py:157} INFO - Started process (PID=12981) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:49:08.348+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:49:08.349+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:08.349+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:49:08.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:49:08.390+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:08.390+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:49:08.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:08.407+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:49:08.418+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.076 seconds
[2024-06-18T11:49:38.829+0000] {processor.py:157} INFO - Started process (PID=13225) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:49:38.831+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:49:38.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:38.832+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:49:38.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:49:38.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:38.875+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:49:38.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:38.903+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:49:38.981+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.155 seconds
[2024-06-18T11:50:09.569+0000] {processor.py:157} INFO - Started process (PID=13469) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:50:09.571+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:50:09.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:09.572+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:50:09.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:50:09.615+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:09.614+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:50:09.631+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:09.631+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:50:09.642+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.075 seconds
[2024-06-18T11:50:39.744+0000] {processor.py:157} INFO - Started process (PID=13712) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:50:39.746+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:50:39.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:39.747+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:50:39.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:50:39.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:39.786+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:50:39.802+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:39.802+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:50:39.813+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.074 seconds
[2024-06-18T11:51:10.405+0000] {processor.py:157} INFO - Started process (PID=13956) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:51:10.407+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:51:10.408+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:10.407+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:51:10.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:51:10.442+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:10.442+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:51:10.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:10.459+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:51:10.510+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.109 seconds
[2024-06-18T11:51:41.230+0000] {processor.py:157} INFO - Started process (PID=14203) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:51:41.231+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:51:41.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:41.232+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:51:41.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:51:41.266+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:41.266+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:51:41.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:41.278+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:51:41.290+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.063 seconds
[2024-06-18T11:52:11.781+0000] {processor.py:157} INFO - Started process (PID=14446) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:52:11.782+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:52:11.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:11.783+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:52:11.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:52:11.820+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:11.820+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:52:11.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:11.832+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:52:11.842+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.065 seconds
[2024-06-18T11:52:42.364+0000] {processor.py:157} INFO - Started process (PID=14689) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:52:42.365+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:52:42.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:42.365+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:52:42.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:52:42.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:42.396+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:52:42.412+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:42.412+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:52:42.424+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T11:53:12.671+0000] {processor.py:157} INFO - Started process (PID=14932) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:53:12.672+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:53:12.673+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:12.673+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:53:12.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:53:12.709+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:12.709+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:53:12.723+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:12.723+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:53:12.733+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T11:53:42.996+0000] {processor.py:157} INFO - Started process (PID=15185) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:53:42.997+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:53:42.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:42.998+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:53:43.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:53:43.045+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:43.045+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:53:43.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:43.062+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:53:43.074+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.082 seconds
[2024-06-18T11:54:13.233+0000] {processor.py:157} INFO - Started process (PID=15430) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:54:13.234+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:54:13.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:13.234+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:54:13.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:54:13.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:13.254+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:54:13.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:13.264+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:54:13.272+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.040 seconds
[2024-06-18T11:54:43.653+0000] {processor.py:157} INFO - Started process (PID=15674) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:54:43.654+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:54:43.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:43.654+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:54:43.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:54:43.677+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:43.677+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:54:43.687+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:43.687+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:54:43.697+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T11:55:13.915+0000] {processor.py:157} INFO - Started process (PID=15918) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:55:13.916+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:55:13.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:13.916+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:55:13.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:55:13.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:13.937+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:55:13.948+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:13.948+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:55:13.956+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T11:55:44.673+0000] {processor.py:157} INFO - Started process (PID=16162) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:55:44.674+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:55:44.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:44.674+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:55:44.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:55:44.694+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:44.694+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:55:44.705+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:44.705+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:55:44.713+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.041 seconds
[2024-06-18T11:56:14.948+0000] {processor.py:157} INFO - Started process (PID=16406) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:56:14.949+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:56:14.949+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:14.949+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:56:14.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:56:14.971+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:14.971+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:56:14.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:14.983+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:56:14.993+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T11:56:45.406+0000] {processor.py:157} INFO - Started process (PID=16650) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:56:45.408+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:56:45.408+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:45.408+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:56:45.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:56:45.433+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:45.433+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:56:45.450+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:45.450+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:56:45.464+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T11:57:15.713+0000] {processor.py:157} INFO - Started process (PID=16894) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:57:15.714+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:57:15.714+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:15.714+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:57:15.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:57:15.737+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:15.737+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:57:15.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:15.748+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:57:15.756+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T11:57:45.927+0000] {processor.py:157} INFO - Started process (PID=17138) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:57:45.927+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:57:45.928+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:45.928+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:57:45.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:57:45.949+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:45.949+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:57:45.959+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:45.959+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:57:45.968+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T11:58:16.219+0000] {processor.py:157} INFO - Started process (PID=17382) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:58:16.219+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:58:16.220+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:16.220+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:58:16.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:58:16.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:16.240+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:58:16.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:16.251+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:58:16.260+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T11:58:46.624+0000] {processor.py:157} INFO - Started process (PID=17626) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:58:46.625+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:58:46.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:46.625+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:58:46.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:58:46.647+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:46.647+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:58:46.658+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:46.658+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:58:46.666+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T11:59:17.576+0000] {processor.py:157} INFO - Started process (PID=17878) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:59:17.577+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:59:17.578+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:17.578+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:59:17.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:59:17.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:17.625+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:59:17.642+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:17.642+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:59:17.653+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.081 seconds
[2024-06-18T11:59:48.599+0000] {processor.py:157} INFO - Started process (PID=18122) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:59:48.600+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T11:59:48.600+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:48.600+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:59:48.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T11:59:48.621+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:48.621+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T11:59:48.632+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:48.632+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:59:48.641+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T12:00:18.967+0000] {processor.py:157} INFO - Started process (PID=18374) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:00:18.968+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:00:18.969+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:18.968+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:00:18.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:00:18.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:18.995+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:00:19.008+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:19.008+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:00:19.024+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T12:00:49.240+0000] {processor.py:157} INFO - Started process (PID=18618) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:00:49.244+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:00:49.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:49.245+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:00:49.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:00:49.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:49.275+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:00:49.287+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:49.287+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:00:49.298+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.065 seconds
[2024-06-18T12:01:19.585+0000] {processor.py:157} INFO - Started process (PID=18854) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:01:19.586+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:01:19.586+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:19.586+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:01:19.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:01:19.608+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:19.608+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:01:19.622+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:19.622+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:01:19.631+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:01:49.797+0000] {processor.py:157} INFO - Started process (PID=19094) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:01:49.798+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:01:49.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:49.798+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:01:49.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:01:49.820+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:49.820+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:01:49.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:49.832+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:01:49.840+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T12:02:20.589+0000] {processor.py:157} INFO - Started process (PID=19342) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:02:20.590+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:02:20.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:20.590+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:02:20.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:02:20.613+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:20.613+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:02:20.626+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:20.626+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:02:20.635+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:02:51.055+0000] {processor.py:157} INFO - Started process (PID=19585) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:02:51.056+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:02:51.057+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:51.057+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:02:51.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:02:51.083+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:51.082+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:02:51.097+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:51.097+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:02:51.112+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T12:06:13.277+0000] {processor.py:157} INFO - Started process (PID=19829) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:06:13.278+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:06:13.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.278+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:06:13.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:06:13.309+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.309+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:06:13.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.327+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:06:13.344+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.070 seconds
[2024-06-18T12:06:43.709+0000] {processor.py:157} INFO - Started process (PID=20076) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:06:43.710+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:06:43.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.710+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:06:43.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:06:43.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.740+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:06:43.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.761+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:06:43.777+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.071 seconds
[2024-06-18T12:07:13.864+0000] {processor.py:157} INFO - Started process (PID=20315) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:07:13.865+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:07:13.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.865+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:07:13.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:07:13.888+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.887+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:07:13.901+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.901+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:07:13.911+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.049 seconds
[2024-06-18T12:07:44.344+0000] {processor.py:157} INFO - Started process (PID=20563) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:07:44.345+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:07:44.346+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.345+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:07:44.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:07:44.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.367+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:07:44.380+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.380+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:07:44.389+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T12:08:15.467+0000] {processor.py:157} INFO - Started process (PID=20807) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:08:15.469+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:08:15.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.469+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:08:15.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:08:15.499+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.498+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:08:15.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.517+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:08:15.532+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T12:08:45.906+0000] {processor.py:157} INFO - Started process (PID=21052) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:08:45.907+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:08:45.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.908+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:08:45.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:08:45.936+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.936+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:08:45.949+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.949+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:08:45.957+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T12:09:16.354+0000] {processor.py:157} INFO - Started process (PID=21296) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:09:16.355+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:09:16.355+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.355+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:09:16.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:09:16.379+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.379+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:09:16.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.396+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:09:16.411+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T12:09:46.674+0000] {processor.py:157} INFO - Started process (PID=21540) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:09:46.675+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:09:46.676+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.676+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:09:46.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:09:46.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.699+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:09:46.711+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.711+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:09:46.721+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:10:17.007+0000] {processor.py:157} INFO - Started process (PID=21784) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:10:17.008+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:10:17.009+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:17.009+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:10:17.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:10:17.034+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:17.034+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:10:17.047+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:17.047+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:10:17.058+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.053 seconds
[2024-06-18T12:10:48.027+0000] {processor.py:157} INFO - Started process (PID=22028) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:10:48.029+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:10:48.031+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:48.031+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:10:48.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:10:48.092+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:48.092+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:10:48.108+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:48.108+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:10:48.121+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.099 seconds
[2024-06-18T12:11:18.261+0000] {processor.py:157} INFO - Started process (PID=22276) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:11:18.262+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:11:18.263+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.262+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:11:18.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:11:18.287+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.287+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:11:18.301+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.301+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:11:18.312+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T12:11:48.565+0000] {processor.py:157} INFO - Started process (PID=22520) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:11:48.566+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:11:48.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.567+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:11:48.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:11:48.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.594+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:11:48.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.610+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:11:48.619+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.057 seconds
[2024-06-18T12:12:18.840+0000] {processor.py:157} INFO - Started process (PID=22764) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:12:18.841+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:12:18.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.841+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:12:18.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:12:18.863+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.863+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:12:18.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.875+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:12:18.885+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T12:12:49.231+0000] {processor.py:157} INFO - Started process (PID=23012) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:12:49.232+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:12:49.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.233+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:12:49.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:12:49.266+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.266+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:12:49.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.279+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:12:49.288+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T12:13:20.229+0000] {processor.py:157} INFO - Started process (PID=23256) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:13:20.230+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:13:20.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.230+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:13:20.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:13:20.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.251+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:13:20.263+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.262+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:13:20.271+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T12:13:50.587+0000] {processor.py:157} INFO - Started process (PID=23500) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:13:50.588+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:13:50.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.588+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:13:50.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:13:50.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.610+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:13:50.622+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.622+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:13:50.631+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T12:14:20.903+0000] {processor.py:157} INFO - Started process (PID=23744) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:14:20.906+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:14:20.912+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.908+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:14:20.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:14:20.990+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.990+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:14:21.049+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:21.048+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:14:21.065+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.167 seconds
[2024-06-18T12:14:51.595+0000] {processor.py:157} INFO - Started process (PID=23987) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:14:51.596+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:14:51.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.596+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:14:51.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:14:51.620+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.620+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:14:51.634+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.634+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:14:51.644+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T12:15:22.659+0000] {processor.py:157} INFO - Started process (PID=24231) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:15:22.660+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:15:22.660+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.660+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:15:22.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:15:22.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.686+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:15:22.700+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.700+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:15:22.711+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T12:15:52.943+0000] {processor.py:157} INFO - Started process (PID=24475) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:15:52.943+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:15:52.944+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.944+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:15:52.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:15:52.966+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.966+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:15:52.978+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.978+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:15:52.986+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T12:16:23.125+0000] {processor.py:157} INFO - Started process (PID=24723) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:16:23.126+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:16:23.126+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.126+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:16:23.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:16:23.147+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.147+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:16:23.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.160+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:16:23.173+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T12:16:53.387+0000] {processor.py:157} INFO - Started process (PID=24967) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:16:53.388+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:16:53.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.388+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:16:53.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:16:53.409+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.409+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:16:53.421+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.421+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:16:53.433+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:17:23.604+0000] {processor.py:157} INFO - Started process (PID=25215) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:17:23.605+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:17:23.605+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.605+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:17:23.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:17:23.626+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.626+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:17:23.638+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.638+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:17:23.647+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T12:17:53.869+0000] {processor.py:157} INFO - Started process (PID=25459) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:17:53.870+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:17:53.871+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.870+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:17:53.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:17:53.891+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.891+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:17:53.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.903+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:17:53.913+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T12:18:24.158+0000] {processor.py:157} INFO - Started process (PID=25703) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:18:24.158+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:18:24.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.159+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:18:24.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:18:24.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.182+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:18:24.194+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.194+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:18:24.204+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:18:54.408+0000] {processor.py:157} INFO - Started process (PID=25946) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:18:54.409+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:18:54.410+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.410+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:18:54.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:18:54.435+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.435+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:18:54.448+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.448+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:18:54.457+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T12:19:24.594+0000] {processor.py:157} INFO - Started process (PID=26190) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:19:24.595+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:19:24.595+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.595+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:19:24.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:19:24.619+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.619+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:19:24.631+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.631+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:19:24.642+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T12:19:55.036+0000] {processor.py:157} INFO - Started process (PID=26434) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:19:55.037+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:19:55.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:55.037+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:19:55.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:19:55.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:55.059+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:19:55.071+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:55.071+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:19:55.080+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T12:20:25.371+0000] {processor.py:157} INFO - Started process (PID=26679) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:20:25.372+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:20:25.373+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.373+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:20:25.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:20:25.395+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.395+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:20:25.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.407+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:20:25.417+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:20:55.653+0000] {processor.py:157} INFO - Started process (PID=26923) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:20:55.654+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:20:55.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.655+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:20:55.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:20:55.676+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.676+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:20:55.691+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.691+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:20:55.700+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:21:26.015+0000] {processor.py:157} INFO - Started process (PID=27171) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:21:26.016+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:21:26.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:26.016+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:21:26.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:21:26.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:26.037+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:21:26.050+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:26.050+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:21:26.059+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T12:21:56.381+0000] {processor.py:157} INFO - Started process (PID=27415) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:21:56.383+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:21:56.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.383+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:21:56.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:21:56.406+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.406+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:21:56.420+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.420+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:21:56.431+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T12:22:26.768+0000] {processor.py:157} INFO - Started process (PID=27663) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:22:26.769+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:22:26.769+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.769+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:22:26.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:22:26.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.791+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:22:26.804+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.804+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:22:26.813+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T12:22:57.203+0000] {processor.py:157} INFO - Started process (PID=27907) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:22:57.204+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:22:57.204+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.204+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:22:57.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:22:57.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.226+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:22:57.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.238+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:22:57.247+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T12:23:28.023+0000] {processor.py:157} INFO - Started process (PID=28151) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:23:28.024+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:23:28.025+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:28.025+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:23:28.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:23:28.055+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:28.055+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:23:28.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:28.072+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:23:28.084+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.064 seconds
[2024-06-18T12:23:58.257+0000] {processor.py:157} INFO - Started process (PID=28395) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:23:58.258+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:23:58.259+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.259+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:23:58.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:23:58.286+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.286+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:23:58.302+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.302+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:23:58.313+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T12:24:28.878+0000] {processor.py:157} INFO - Started process (PID=28644) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:24:28.879+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:24:28.879+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.879+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:24:28.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:24:28.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.903+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:24:28.919+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.919+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:24:28.932+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T12:31:02.624+0000] {processor.py:157} INFO - Started process (PID=196) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:31:02.625+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:31:02.626+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.626+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:31:02.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:31:02.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.656+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:31:02.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.674+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:31:02.692+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.071 seconds
[2024-06-18T12:31:33.060+0000] {processor.py:157} INFO - Started process (PID=434) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:31:33.062+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:31:33.063+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:33.063+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:31:33.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:31:33.090+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:33.090+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:31:33.106+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:33.106+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:31:33.119+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T12:32:03.964+0000] {processor.py:157} INFO - Started process (PID=678) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:32:03.965+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:32:03.966+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.966+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:32:03.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:32:04.014+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:04.013+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:32:04.033+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:04.033+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:32:04.055+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.094 seconds
[2024-06-18T12:32:34.349+0000] {processor.py:157} INFO - Started process (PID=922) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:32:34.354+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:32:34.357+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.356+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:32:34.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:32:34.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.415+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:32:34.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.437+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:32:34.485+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.138 seconds
[2024-06-18T12:33:05.245+0000] {processor.py:157} INFO - Started process (PID=1166) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:33:05.246+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:33:05.247+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.247+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:33:05.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:33:05.280+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.280+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:33:05.296+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.296+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:33:05.311+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T12:33:36.497+0000] {processor.py:157} INFO - Started process (PID=1410) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:33:36.500+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:33:36.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.502+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:33:36.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:33:36.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.593+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:33:36.616+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.616+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:33:36.629+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.137 seconds
[2024-06-18T12:34:07.917+0000] {processor.py:157} INFO - Started process (PID=1654) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:34:07.923+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:34:07.928+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.928+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:34:07.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:34:07.989+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.989+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:34:08.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:08.036+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:34:08.081+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.172 seconds
[2024-06-18T12:34:38.312+0000] {processor.py:157} INFO - Started process (PID=1898) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:34:38.314+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:34:38.316+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:38.315+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:34:38.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:34:38.350+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:38.350+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:34:38.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:38.371+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:34:38.393+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.091 seconds
[2024-06-18T12:35:08.423+0000] {processor.py:157} INFO - Started process (PID=2144) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:35:08.424+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:35:08.424+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.424+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:35:08.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:35:08.449+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.449+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:35:08.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.464+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:35:08.473+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T12:35:38.711+0000] {processor.py:157} INFO - Started process (PID=2386) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:35:38.712+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:35:38.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.716+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:35:38.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:35:38.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.747+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:35:38.767+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.767+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:35:38.778+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.070 seconds
[2024-06-18T12:36:08.978+0000] {processor.py:157} INFO - Started process (PID=2630) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:36:08.979+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:36:08.980+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.980+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:36:08.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:36:09.001+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:09.001+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:36:09.014+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:09.014+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:36:09.025+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:36:39.795+0000] {processor.py:157} INFO - Started process (PID=2874) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:36:39.797+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:36:39.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.797+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:36:39.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:36:39.818+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.818+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:36:39.830+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.829+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:36:39.838+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T12:37:10.255+0000] {processor.py:157} INFO - Started process (PID=3117) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:37:10.256+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:37:10.256+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.256+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:37:10.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:37:10.277+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.277+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:37:10.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.290+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:37:10.299+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T12:37:40.511+0000] {processor.py:157} INFO - Started process (PID=3361) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:37:40.512+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:37:40.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.512+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:37:40.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:37:40.536+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.536+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:37:40.549+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.549+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:37:40.559+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T12:40:08.181+0000] {processor.py:157} INFO - Started process (PID=197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:40:08.183+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:40:08.185+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:08.185+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:40:08.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:40:08.206+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:08.206+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:40:08.224+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:08.223+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:40:08.239+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T12:40:38.389+0000] {processor.py:157} INFO - Started process (PID=459) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:40:38.390+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:40:38.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.391+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:40:38.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:40:38.428+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.428+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:40:38.445+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.445+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:40:38.459+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.072 seconds
[2024-06-18T12:41:08.924+0000] {processor.py:157} INFO - Started process (PID=700) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:41:08.925+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:41:08.926+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.926+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:41:08.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:41:08.960+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.960+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:41:08.981+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.980+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:41:08.998+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.076 seconds
[2024-06-18T12:41:39.133+0000] {processor.py:157} INFO - Started process (PID=947) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:41:39.134+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:41:39.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:39.134+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:41:39.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:41:39.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:39.156+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:41:39.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:39.169+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:41:39.179+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T12:42:09.421+0000] {processor.py:157} INFO - Started process (PID=1191) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:42:09.431+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:42:09.438+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.437+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:42:09.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:42:09.486+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.485+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:42:09.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.502+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:42:09.516+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.106 seconds
[2024-06-18T12:42:40.053+0000] {processor.py:157} INFO - Started process (PID=1435) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:42:40.053+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:42:40.054+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:40.054+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:42:40.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:42:40.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:40.075+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:42:40.087+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:40.087+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:42:40.096+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T12:43:10.372+0000] {processor.py:157} INFO - Started process (PID=1679) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:43:10.373+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:43:10.374+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.374+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:43:10.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:43:10.399+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.399+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:43:10.414+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.413+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:43:10.424+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T12:43:40.751+0000] {processor.py:157} INFO - Started process (PID=1923) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:43:40.752+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:43:40.752+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.752+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:43:40.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:43:40.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.775+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:43:40.787+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.787+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:43:40.796+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T12:44:11.035+0000] {processor.py:157} INFO - Started process (PID=2169) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:44:11.036+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:44:11.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:11.037+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:44:11.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:44:11.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:11.059+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:44:11.071+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:11.071+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:44:11.080+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T12:44:41.562+0000] {processor.py:157} INFO - Started process (PID=2411) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:44:41.563+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:44:41.563+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.563+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:44:41.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:44:41.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.590+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:44:41.603+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.603+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:44:41.612+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T12:45:13.915+0000] {processor.py:157} INFO - Started process (PID=2662) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:45:13.919+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:45:13.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.919+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:45:13.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:45:13.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.962+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:45:13.991+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.990+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:45:14.019+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.109 seconds
[2024-06-18T12:45:44.806+0000] {processor.py:157} INFO - Started process (PID=2908) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:45:44.807+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:45:44.812+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:44.811+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:45:44.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:45:44.838+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:44.838+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:45:44.854+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:44.854+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:45:44.866+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.063 seconds
[2024-06-18T12:46:15.384+0000] {processor.py:157} INFO - Started process (PID=3152) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:46:15.386+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:46:15.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:15.390+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:46:15.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:46:15.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:15.480+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:46:15.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:15.502+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:46:15.518+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.137 seconds
[2024-06-18T12:46:46.000+0000] {processor.py:157} INFO - Started process (PID=3396) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:46:46.001+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:46:46.002+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:46.001+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:46:46.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:46:46.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:46.023+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:46:46.036+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:46.036+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:46:46.048+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T12:47:16.467+0000] {processor.py:157} INFO - Started process (PID=3640) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:47:16.467+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:47:16.468+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:16.468+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:47:16.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:47:16.490+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:16.490+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:47:16.503+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:16.503+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:47:16.514+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.049 seconds
[2024-06-18T12:47:47.105+0000] {processor.py:157} INFO - Started process (PID=3894) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:47:47.110+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:47:47.118+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:47.116+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:47:47.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:47:47.196+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:47.196+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:47:47.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:47.227+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:47:47.308+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.206 seconds
[2024-06-18T12:48:18.037+0000] {processor.py:157} INFO - Started process (PID=4139) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:48:18.040+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:48:18.041+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:18.040+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:48:18.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:48:18.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:18.072+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:48:18.086+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:18.086+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:48:18.095+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T12:48:48.319+0000] {processor.py:157} INFO - Started process (PID=4386) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:48:48.323+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:48:48.324+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:48.324+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:48:48.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:48:48.364+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:48.364+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:48:48.411+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:48.411+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:48:48.427+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.120 seconds
[2024-06-18T12:49:18.951+0000] {processor.py:157} INFO - Started process (PID=4630) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:49:18.953+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:49:18.954+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:18.953+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:49:18.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:49:18.986+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:18.986+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:49:18.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:18.998+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:49:19.007+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T12:49:49.527+0000] {processor.py:157} INFO - Started process (PID=4874) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:49:49.529+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:49:49.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:49.530+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:49:49.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:49:49.561+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:49.560+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:49:49.575+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:49.575+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:49:49.589+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.065 seconds
[2024-06-18T12:50:19.749+0000] {processor.py:157} INFO - Started process (PID=5118) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:50:19.751+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T12:50:19.752+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:19.752+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:50:19.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T12:50:19.813+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:19.813+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T12:50:19.826+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:19.826+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:50:19.838+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.092 seconds
[2024-06-18T14:00:58.286+0000] {processor.py:157} INFO - Started process (PID=197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:00:58.288+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:00:58.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:58.290+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:00:58.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:00:58.337+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:58.337+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:00:58.380+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:58.379+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:00:58.403+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.119 seconds
[2024-06-18T14:01:09.127+0000] {processor.py:157} INFO - Started process (PID=197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:01:09.128+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:01:09.129+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:09.129+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:01:09.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:01:09.160+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:09.160+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:01:09.175+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:09.175+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:01:09.187+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.063 seconds
[2024-06-18T14:01:39.660+0000] {processor.py:157} INFO - Started process (PID=441) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:01:39.662+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:01:39.663+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.663+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:01:39.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:01:39.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.686+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:01:39.700+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.700+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:01:39.709+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T14:02:10.699+0000] {processor.py:157} INFO - Started process (PID=684) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:02:10.701+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:02:10.703+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:10.702+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:02:10.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:02:10.738+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:10.737+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:02:10.752+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:10.752+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:02:10.762+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T14:02:41.126+0000] {processor.py:157} INFO - Started process (PID=925) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:02:41.127+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:02:41.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:41.128+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:02:41.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:02:41.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:41.158+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:02:41.171+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:41.171+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:02:41.183+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T14:03:11.585+0000] {processor.py:157} INFO - Started process (PID=1169) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:03:11.588+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:03:11.589+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:11.589+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:03:11.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:03:11.624+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:11.624+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:03:11.638+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:11.638+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:03:11.648+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T14:03:42.522+0000] {processor.py:157} INFO - Started process (PID=1416) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:03:42.524+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:03:42.525+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:42.525+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:03:42.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:03:42.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:42.574+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:03:42.591+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:42.591+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:03:42.602+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.083 seconds
[2024-06-18T14:04:13.565+0000] {processor.py:157} INFO - Started process (PID=1660) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:04:13.567+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:04:13.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:13.567+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:04:13.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:04:13.592+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:13.592+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:04:13.603+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:13.603+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:04:13.615+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T14:04:44.437+0000] {processor.py:157} INFO - Started process (PID=1904) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:04:44.438+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:04:44.439+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:44.439+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:04:44.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:04:44.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:44.469+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:04:44.496+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:44.496+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:04:44.507+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.072 seconds
[2024-06-18T14:05:14.782+0000] {processor.py:157} INFO - Started process (PID=2145) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:05:14.783+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:05:14.784+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:14.784+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:05:14.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:05:14.807+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:14.807+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:05:14.822+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:14.822+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:05:14.835+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.055 seconds
[2024-06-18T14:05:45.595+0000] {processor.py:157} INFO - Started process (PID=2392) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:05:45.596+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:05:45.597+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:45.597+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:05:45.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:05:45.630+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:45.630+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:05:45.648+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:45.648+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:05:45.658+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T14:06:16.004+0000] {processor.py:157} INFO - Started process (PID=2633) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:06:16.006+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:06:16.008+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:16.007+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:06:16.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:06:16.040+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:16.039+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:06:16.052+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:16.052+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:06:16.062+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T14:06:46.464+0000] {processor.py:157} INFO - Started process (PID=2877) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:06:46.467+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:06:46.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:46.469+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:06:46.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:06:46.497+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:46.496+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:06:46.509+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:46.509+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:06:46.526+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.065 seconds
[2024-06-18T14:07:16.799+0000] {processor.py:157} INFO - Started process (PID=3121) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:07:16.801+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:07:16.804+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:16.803+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:07:16.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:07:16.907+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:16.906+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:07:16.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:16.920+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:07:16.932+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.138 seconds
[2024-06-18T14:07:46.992+0000] {processor.py:157} INFO - Started process (PID=3370) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:07:46.993+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:07:46.993+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:46.993+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:07:47.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:07:47.013+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:47.013+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:07:47.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:47.023+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:07:47.031+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.041 seconds
[2024-06-18T14:08:17.255+0000] {processor.py:157} INFO - Started process (PID=3608) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:08:17.257+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:08:17.258+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:17.257+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:08:17.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:08:17.285+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:17.285+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:08:17.299+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:17.299+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:08:17.311+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T14:08:48.077+0000] {processor.py:157} INFO - Started process (PID=3852) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:08:48.081+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:08:48.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:48.083+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:08:48.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:08:48.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:48.135+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:08:48.151+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:48.151+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:08:48.163+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.100 seconds
[2024-06-18T14:09:19.220+0000] {processor.py:157} INFO - Started process (PID=4096) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:09:19.221+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:09:19.222+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:19.222+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:09:19.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:09:19.266+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:19.265+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:09:19.288+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:19.288+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:09:19.302+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.085 seconds
[2024-06-18T14:09:50.183+0000] {processor.py:157} INFO - Started process (PID=4340) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:09:50.185+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:09:50.186+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:50.186+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:09:50.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:09:50.241+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:50.241+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:09:50.258+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:50.258+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:09:50.271+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.096 seconds
[2024-06-18T14:10:20.428+0000] {processor.py:157} INFO - Started process (PID=4584) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:10:20.429+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:10:20.430+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:20.430+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:10:20.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:10:20.462+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:20.461+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:10:20.476+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:20.476+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:10:20.489+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.064 seconds
[2024-06-18T14:10:50.728+0000] {processor.py:157} INFO - Started process (PID=4827) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:10:50.730+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:10:50.732+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:50.731+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:10:50.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:10:50.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:50.762+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:10:50.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:50.775+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:10:50.784+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T14:11:21.070+0000] {processor.py:157} INFO - Started process (PID=5071) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:11:21.071+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:11:21.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:21.072+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:11:21.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:11:21.098+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:21.098+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:11:21.110+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:21.110+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:11:21.120+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T14:11:51.404+0000] {processor.py:157} INFO - Started process (PID=5315) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:11:51.406+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:11:51.409+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:51.408+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:11:51.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:11:51.465+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:51.465+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:11:51.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:51.481+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:11:51.494+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.097 seconds
[2024-06-18T14:12:21.532+0000] {processor.py:157} INFO - Started process (PID=5558) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:12:21.533+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:12:21.534+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:21.534+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:12:21.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:12:21.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:21.568+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:12:21.581+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:21.581+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:12:21.590+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T14:12:52.405+0000] {processor.py:157} INFO - Started process (PID=5802) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:12:52.406+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:12:52.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:52.406+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:12:52.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:12:52.432+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:52.431+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:12:52.446+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:52.446+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:12:52.458+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T14:13:22.746+0000] {processor.py:157} INFO - Started process (PID=6046) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:13:22.747+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:13:22.749+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:22.748+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:13:22.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:13:22.784+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:22.783+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:13:22.802+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:22.801+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:13:22.822+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.082 seconds
[2024-06-18T14:13:53.187+0000] {processor.py:157} INFO - Started process (PID=6290) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:13:53.189+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:13:53.190+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:53.190+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:13:53.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:13:53.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:53.226+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:13:53.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:53.239+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:13:53.250+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T14:14:23.354+0000] {processor.py:157} INFO - Started process (PID=6534) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:14:23.356+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:14:23.357+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:23.357+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:14:23.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:14:23.389+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:23.389+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:14:23.402+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:23.401+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:14:23.411+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T14:14:54.352+0000] {processor.py:157} INFO - Started process (PID=6778) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:14:54.357+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:14:54.358+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:54.358+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:14:54.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:14:54.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:54.390+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:14:54.404+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:54.404+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:14:54.414+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.067 seconds
[2024-06-18T14:15:24.719+0000] {processor.py:157} INFO - Started process (PID=7022) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:15:24.721+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:15:24.722+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:24.722+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:15:24.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:15:24.753+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:24.753+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:15:24.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:24.765+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:15:24.774+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T14:15:55.333+0000] {processor.py:157} INFO - Started process (PID=7266) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:15:55.334+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:15:55.335+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:55.335+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:15:55.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:15:55.358+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:55.358+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:15:55.369+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:55.369+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:15:55.377+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T14:16:25.968+0000] {processor.py:157} INFO - Started process (PID=7509) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:16:25.970+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:16:25.972+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:25.971+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:16:25.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:16:26.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:26.007+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:16:26.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:26.019+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:16:26.028+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T14:16:56.308+0000] {processor.py:157} INFO - Started process (PID=7753) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:16:56.314+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:16:56.316+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:56.316+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:16:56.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:16:56.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:56.367+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:16:56.387+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:56.387+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:16:56.401+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.099 seconds
[2024-06-18T14:17:26.796+0000] {processor.py:157} INFO - Started process (PID=7997) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:17:26.798+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:17:26.799+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:26.799+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:17:26.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:17:26.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:26.842+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:17:26.857+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:26.857+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:17:26.869+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.078 seconds
[2024-06-18T14:17:57.638+0000] {processor.py:157} INFO - Started process (PID=8240) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:17:57.640+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:17:57.641+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:57.641+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:17:57.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:17:57.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:57.678+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:17:57.694+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:57.694+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:17:57.707+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.073 seconds
[2024-06-18T14:18:28.573+0000] {processor.py:157} INFO - Started process (PID=8483) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:18:28.575+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:18:28.576+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:28.576+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:18:28.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:18:28.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:28.610+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:18:28.629+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:28.629+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:18:28.643+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.077 seconds
[2024-06-18T14:18:58.674+0000] {processor.py:157} INFO - Started process (PID=8727) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:18:58.679+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:18:58.680+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:58.680+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:18:58.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:18:58.716+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:58.715+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:18:58.731+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:58.730+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:18:58.826+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.155 seconds
[2024-06-18T14:19:29.344+0000] {processor.py:157} INFO - Started process (PID=8971) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:19:29.345+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:19:29.346+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:29.345+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:19:29.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:19:29.370+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:29.370+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:19:29.384+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:29.384+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:19:29.397+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T14:19:59.632+0000] {processor.py:157} INFO - Started process (PID=9214) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:19:59.634+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:19:59.634+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:59.634+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:19:59.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:19:59.689+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:59.689+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:19:59.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:59.717+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:19:59.736+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.109 seconds
[2024-06-18T14:20:29.862+0000] {processor.py:157} INFO - Started process (PID=9458) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:20:29.864+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:20:29.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:29.865+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:20:29.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:20:29.896+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:29.896+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:20:29.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:29.908+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:20:29.917+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T14:21:00.895+0000] {processor.py:157} INFO - Started process (PID=9702) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:21:00.897+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:21:00.898+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:00.897+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:21:00.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:21:00.930+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:00.930+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:21:00.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:00.944+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:21:00.956+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.064 seconds
[2024-06-18T14:21:31.537+0000] {processor.py:157} INFO - Started process (PID=9946) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:21:31.539+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:21:31.539+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:31.539+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:21:31.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:21:31.704+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:31.704+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:21:31.809+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:31.809+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:21:31.819+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.286 seconds
[2024-06-18T14:22:02.420+0000] {processor.py:157} INFO - Started process (PID=10190) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:22:02.422+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T14:22:02.423+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:02.423+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:22:02.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T14:22:02.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:02.459+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T14:22:02.500+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:02.500+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:22:02.604+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.189 seconds
[2024-06-18T15:06:42.132+0000] {processor.py:157} INFO - Started process (PID=10464) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:06:42.133+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:06:42.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:42.133+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:06:42.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:06:42.170+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:42.170+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:06:42.185+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:42.185+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:06:42.195+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.066 seconds
[2024-06-18T15:06:49.838+0000] {processor.py:157} INFO - Started process (PID=197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:06:49.839+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:06:49.839+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.839+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:06:49.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:06:49.864+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.864+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:06:49.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.875+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:06:49.884+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T15:07:20.586+0000] {processor.py:157} INFO - Started process (PID=441) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:07:20.587+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:07:20.587+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.587+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:07:20.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:07:20.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.611+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:07:20.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.625+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:07:20.634+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T15:07:50.682+0000] {processor.py:157} INFO - Started process (PID=684) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:07:50.683+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:07:50.684+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.684+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:07:50.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:07:50.704+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.704+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:07:50.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.717+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:07:50.730+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.049 seconds
[2024-06-18T15:08:20.994+0000] {processor.py:157} INFO - Started process (PID=923) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:08:20.995+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:08:20.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.995+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:08:21.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:08:21.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:21.019+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:08:21.032+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:21.032+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:08:21.050+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.057 seconds
[2024-06-18T15:08:51.164+0000] {processor.py:157} INFO - Started process (PID=1167) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:08:51.165+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:08:51.166+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.166+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:08:51.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:08:51.181+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.181+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:08:51.196+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.196+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:08:51.208+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T15:09:21.801+0000] {processor.py:157} INFO - Started process (PID=1411) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:09:21.802+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:09:21.803+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.803+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:09:21.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:09:21.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.823+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:09:21.836+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.836+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:09:21.845+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:09:52.624+0000] {processor.py:157} INFO - Started process (PID=1655) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:09:52.625+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:09:52.626+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.625+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:09:52.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:09:52.648+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.648+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:09:52.668+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.667+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:09:52.680+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T15:10:23.114+0000] {processor.py:157} INFO - Started process (PID=1899) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:10:23.116+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:10:23.116+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.116+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:10:23.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:10:23.145+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.144+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:10:23.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.158+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:10:23.167+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.055 seconds
[2024-06-18T15:10:53.303+0000] {processor.py:157} INFO - Started process (PID=2143) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:10:53.304+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:10:53.305+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.305+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:10:53.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:10:53.326+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.326+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:10:53.339+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.339+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:10:53.348+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:11:23.908+0000] {processor.py:157} INFO - Started process (PID=2387) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:11:23.908+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:11:23.909+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.909+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:11:23.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:11:23.933+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.933+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:11:23.949+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.949+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:11:23.959+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.053 seconds
[2024-06-18T15:11:54.352+0000] {processor.py:157} INFO - Started process (PID=2631) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:11:54.352+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:11:54.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.353+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:11:54.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:11:54.374+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.374+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:11:54.386+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.386+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:11:54.396+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:12:24.722+0000] {processor.py:157} INFO - Started process (PID=2875) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:12:24.724+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:12:24.724+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.724+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:12:24.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:12:24.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.747+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:12:24.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.761+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:12:24.770+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T15:12:55.088+0000] {processor.py:157} INFO - Started process (PID=3119) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:12:55.089+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:12:55.090+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.090+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:12:55.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:12:55.116+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.116+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:12:55.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.128+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:12:55.139+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T15:13:25.291+0000] {processor.py:157} INFO - Started process (PID=3363) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:13:25.292+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:13:25.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.292+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:13:25.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:13:25.313+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.313+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:13:25.328+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.328+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:13:25.338+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T15:13:55.833+0000] {processor.py:157} INFO - Started process (PID=3607) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:13:55.834+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:13:55.835+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.835+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:13:55.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:13:55.856+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.856+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:13:55.869+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.869+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:13:55.882+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T15:14:26.123+0000] {processor.py:157} INFO - Started process (PID=3850) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:14:26.124+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:14:26.124+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.124+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:14:26.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:14:26.144+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.144+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:14:26.160+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.159+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:14:26.168+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T15:14:56.497+0000] {processor.py:157} INFO - Started process (PID=4094) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:14:56.498+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:14:56.499+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.499+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:14:56.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:14:56.524+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.524+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:14:56.538+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.538+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:14:56.549+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T15:15:26.885+0000] {processor.py:157} INFO - Started process (PID=4338) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:15:26.886+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:15:26.887+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.886+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:15:26.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:15:26.909+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.909+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:15:26.922+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.922+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:15:26.988+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.105 seconds
[2024-06-18T15:15:57.056+0000] {processor.py:157} INFO - Started process (PID=4582) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:15:57.057+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:15:57.058+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:57.058+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:15:57.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:15:57.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:57.079+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:15:57.093+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:57.093+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:15:57.103+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T15:16:27.519+0000] {processor.py:157} INFO - Started process (PID=4826) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:16:27.520+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:16:27.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.520+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:16:27.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:16:27.541+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.541+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:16:27.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.553+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:16:27.562+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T15:16:58.259+0000] {processor.py:157} INFO - Started process (PID=5070) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:16:58.260+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:16:58.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.260+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:16:58.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:16:58.280+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.280+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:16:58.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.292+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:16:58.301+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:17:28.626+0000] {processor.py:157} INFO - Started process (PID=5313) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:17:28.627+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:17:28.628+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.627+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:17:28.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:17:28.648+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.648+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:17:28.661+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.660+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:17:28.669+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:17:59.346+0000] {processor.py:157} INFO - Started process (PID=5557) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:17:59.347+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:17:59.348+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.348+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:17:59.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:17:59.375+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.375+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:17:59.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.388+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:17:59.406+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T15:18:29.693+0000] {processor.py:157} INFO - Started process (PID=5801) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:18:29.693+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:18:29.694+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.694+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:18:29.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:18:29.714+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.714+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:18:29.726+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.725+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:18:29.734+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:18:59.950+0000] {processor.py:157} INFO - Started process (PID=6045) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:18:59.951+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:18:59.951+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.951+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:18:59.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:18:59.972+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.972+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:18:59.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.983+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:18:59.992+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:19:30.805+0000] {processor.py:157} INFO - Started process (PID=6289) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:19:30.807+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:19:30.808+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.808+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:19:30.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:19:30.835+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.835+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:19:30.851+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.851+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:19:30.871+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.069 seconds
[2024-06-18T15:20:01.080+0000] {processor.py:157} INFO - Started process (PID=6533) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:20:01.081+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:20:01.082+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:01.082+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:20:01.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:20:01.110+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:01.110+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:20:01.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:01.124+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:20:01.136+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.059 seconds
[2024-06-18T15:20:31.466+0000] {processor.py:157} INFO - Started process (PID=6777) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:20:31.467+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:20:31.468+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.467+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:20:31.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:20:31.488+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.488+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:20:31.500+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.499+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:20:31.508+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:21:01.943+0000] {processor.py:157} INFO - Started process (PID=7021) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:21:01.944+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:21:01.944+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.944+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:21:01.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:21:01.964+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.964+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:21:01.975+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.975+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:21:01.983+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:21:32.353+0000] {processor.py:157} INFO - Started process (PID=7265) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:21:32.354+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:21:32.354+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.354+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:21:32.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:21:32.374+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.374+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:21:32.386+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.386+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:21:32.395+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:22:03.066+0000] {processor.py:157} INFO - Started process (PID=7509) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:22:03.066+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:22:03.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:03.067+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:22:03.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:22:03.089+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:03.089+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:22:03.101+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:03.101+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:22:03.110+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:22:33.278+0000] {processor.py:157} INFO - Started process (PID=7753) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:22:33.280+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:22:33.280+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.280+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:22:33.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:22:33.301+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.301+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:22:33.313+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.312+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:22:33.322+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:23:03.813+0000] {processor.py:157} INFO - Started process (PID=7997) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:23:03.814+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:23:03.815+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.814+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:23:03.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:23:03.848+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.848+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:23:03.863+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.863+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:23:03.876+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.069 seconds
[2024-06-18T15:23:33.961+0000] {processor.py:157} INFO - Started process (PID=8238) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:23:33.962+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:23:33.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:33.962+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:23:33.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:23:33.987+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:33.987+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:23:33.999+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:33.999+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:23:34.010+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T15:24:04.272+0000] {processor.py:157} INFO - Started process (PID=8480) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:24:04.273+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:24:04.274+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.274+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:24:04.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:24:04.297+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.297+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:24:04.310+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.310+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:24:04.319+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T15:24:34.882+0000] {processor.py:157} INFO - Started process (PID=8729) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:24:34.882+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:24:34.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.883+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:24:34.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:24:34.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.902+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:24:34.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.915+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:24:34.924+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:25:05.296+0000] {processor.py:157} INFO - Started process (PID=8973) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:25:05.299+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:25:05.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.300+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:25:05.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:25:05.323+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.323+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:25:05.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.336+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:25:05.346+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T15:25:35.696+0000] {processor.py:157} INFO - Started process (PID=9217) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:25:35.697+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:25:35.697+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.697+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:25:35.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:25:35.721+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.721+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:25:35.739+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.739+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:25:35.754+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T15:26:05.846+0000] {processor.py:157} INFO - Started process (PID=9461) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:26:05.847+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:26:05.848+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.847+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:26:05.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:26:05.868+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.868+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:26:05.880+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.880+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:26:05.888+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:26:37.236+0000] {processor.py:157} INFO - Started process (PID=9705) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:26:37.237+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:26:37.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:37.237+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:26:37.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:26:37.259+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:37.259+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:26:37.273+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:37.272+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:26:37.475+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.241 seconds
[2024-06-18T15:27:07.853+0000] {processor.py:157} INFO - Started process (PID=9954) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:27:07.854+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:27:07.855+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.854+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:27:07.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:27:07.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.874+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:27:07.885+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.885+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:27:07.894+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T15:27:38.681+0000] {processor.py:157} INFO - Started process (PID=10193) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:27:38.682+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:27:38.682+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.682+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:27:38.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:27:38.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.702+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:27:38.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.713+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:27:38.722+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.042 seconds
[2024-06-18T15:28:09.662+0000] {processor.py:157} INFO - Started process (PID=10437) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:28:09.663+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:28:09.664+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.663+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:28:09.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:28:09.684+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.684+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:28:09.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.778+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:28:09.786+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.125 seconds
[2024-06-18T15:28:40.620+0000] {processor.py:157} INFO - Started process (PID=10681) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:28:40.621+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:28:40.622+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.622+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:28:40.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:28:40.644+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.644+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:28:40.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.656+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:28:40.752+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.135 seconds
[2024-06-18T15:29:10.777+0000] {processor.py:157} INFO - Started process (PID=10930) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:29:10.777+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:29:10.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.778+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:29:10.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:29:10.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.798+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:29:10.809+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.809+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:29:10.819+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:29:41.755+0000] {processor.py:157} INFO - Started process (PID=11169) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:29:41.756+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:29:41.756+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.756+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:29:41.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:29:41.777+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.777+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:29:41.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.789+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:29:41.798+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T15:30:12.759+0000] {processor.py:157} INFO - Started process (PID=11413) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:30:12.760+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:30:12.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.760+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:30:12.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:30:12.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.902+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:30:12.913+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.912+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:30:12.924+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.167 seconds
[2024-06-18T15:30:43.789+0000] {processor.py:157} INFO - Started process (PID=11657) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:30:43.789+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:30:43.790+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.790+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:30:43.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:30:43.812+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.812+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:30:43.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.825+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:30:43.834+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T15:31:14.843+0000] {processor.py:157} INFO - Started process (PID=11901) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:31:14.844+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:31:14.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.844+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:31:14.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:31:14.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.865+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:31:14.876+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.876+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:31:14.886+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:31:45.084+0000] {processor.py:157} INFO - Started process (PID=12145) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:31:45.085+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:31:45.086+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.085+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:31:45.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:31:45.106+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.106+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:31:45.118+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.118+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:31:45.126+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:32:15.300+0000] {processor.py:157} INFO - Started process (PID=12389) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:32:15.301+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:32:15.302+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.302+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:32:15.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:32:15.325+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.325+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:32:15.339+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.339+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:32:15.349+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T15:32:45.493+0000] {processor.py:157} INFO - Started process (PID=12632) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:32:45.494+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:32:45.495+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.494+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:32:45.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:32:45.515+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.515+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:32:45.527+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.527+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:32:45.535+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:33:15.650+0000] {processor.py:157} INFO - Started process (PID=12875) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:33:15.651+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:33:15.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.651+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:33:15.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:33:15.672+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.672+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:33:15.684+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.684+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:33:15.692+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:33:46.069+0000] {processor.py:157} INFO - Started process (PID=13119) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:33:46.070+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:33:46.071+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:46.070+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:33:46.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:33:46.096+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:46.096+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:33:46.111+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:46.111+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:33:46.123+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T15:34:16.607+0000] {processor.py:157} INFO - Started process (PID=13363) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:34:16.607+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:34:16.608+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.608+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:34:16.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:34:16.628+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.628+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:34:16.640+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.640+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:34:16.648+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:34:46.886+0000] {processor.py:157} INFO - Started process (PID=13607) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:34:46.887+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:34:46.888+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.888+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:34:46.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:34:46.912+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.912+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:34:46.925+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.925+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:34:46.933+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.049 seconds
[2024-06-18T15:35:17.514+0000] {processor.py:157} INFO - Started process (PID=13851) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:35:17.515+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:35:17.515+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.515+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:35:17.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:35:17.539+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.539+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:35:17.554+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.553+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:35:17.565+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T15:35:47.882+0000] {processor.py:157} INFO - Started process (PID=14095) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:35:47.883+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:35:47.885+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.884+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:35:47.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:35:47.911+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.910+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:35:47.932+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.931+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:35:47.947+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.068 seconds
[2024-06-18T15:36:18.022+0000] {processor.py:157} INFO - Started process (PID=14338) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:36:18.023+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:36:18.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:18.023+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:36:18.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:36:18.045+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:18.045+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:36:18.056+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:18.056+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:36:18.066+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T15:36:48.277+0000] {processor.py:157} INFO - Started process (PID=14584) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:36:48.277+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:36:48.278+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.278+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:36:48.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:36:48.299+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.299+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:36:48.311+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.311+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:36:48.321+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:37:18.504+0000] {processor.py:157} INFO - Started process (PID=14826) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:37:18.504+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:37:18.505+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.505+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:37:18.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:37:18.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.530+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:37:18.543+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.543+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:37:18.560+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T15:37:48.852+0000] {processor.py:157} INFO - Started process (PID=15070) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:37:48.853+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:37:48.853+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.853+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:37:48.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:37:48.880+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.880+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:37:48.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.904+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:37:48.921+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.072 seconds
[2024-06-18T15:38:19.474+0000] {processor.py:157} INFO - Started process (PID=15314) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:38:19.475+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:38:19.475+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.475+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:38:19.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:38:19.496+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.496+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:38:19.508+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.507+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:38:19.516+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:38:50.492+0000] {processor.py:157} INFO - Started process (PID=15558) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:38:50.493+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:38:50.493+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.493+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:38:50.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:38:50.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.517+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:38:50.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.530+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:38:50.541+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T15:39:20.700+0000] {processor.py:157} INFO - Started process (PID=15801) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:39:20.700+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:39:20.701+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.701+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:39:20.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:39:20.723+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.723+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:39:20.734+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.733+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:39:20.742+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:39:50.821+0000] {processor.py:157} INFO - Started process (PID=16045) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:39:50.822+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:39:50.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.822+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:39:50.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:39:50.845+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.845+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:39:50.856+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.856+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:39:50.865+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T15:40:21.025+0000] {processor.py:157} INFO - Started process (PID=16288) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:40:21.026+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:40:21.026+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:21.026+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:40:21.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:40:21.048+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:21.048+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:40:21.061+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:21.061+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:40:21.070+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T15:40:51.192+0000] {processor.py:157} INFO - Started process (PID=16532) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:40:51.193+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:40:51.194+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.194+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:40:51.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:40:51.219+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.219+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:40:51.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.232+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:40:51.247+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T15:41:21.694+0000] {processor.py:157} INFO - Started process (PID=16783) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:41:21.696+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:41:21.697+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.696+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:41:21.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:41:21.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.718+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:41:21.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.729+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:41:21.741+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.049 seconds
[2024-06-18T15:41:51.777+0000] {processor.py:157} INFO - Started process (PID=17027) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:41:51.777+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:41:51.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.778+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:41:51.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:41:51.800+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.799+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:41:51.810+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.810+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:41:51.819+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:42:22.798+0000] {processor.py:157} INFO - Started process (PID=17265) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:42:22.799+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:42:22.799+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.799+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:42:22.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:42:22.821+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.821+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:42:22.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.832+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:42:22.840+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T15:42:52.901+0000] {processor.py:157} INFO - Started process (PID=17509) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:42:52.902+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:42:52.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.902+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:42:52.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:42:52.924+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.924+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:42:52.938+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.937+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:42:52.947+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T15:43:23.201+0000] {processor.py:157} INFO - Started process (PID=17747) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:43:23.202+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:43:23.203+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.203+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:43:23.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:43:23.225+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.225+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:43:23.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.237+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:43:23.246+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T15:43:54.145+0000] {processor.py:157} INFO - Started process (PID=17997) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:43:54.146+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:43:54.146+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:54.146+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:43:54.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:43:54.167+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:54.167+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:43:54.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:54.178+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:43:54.187+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:44:25.158+0000] {processor.py:157} INFO - Started process (PID=18241) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:44:25.159+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:44:25.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:25.161+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:44:25.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:44:25.184+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:25.184+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:44:25.195+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:25.195+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:44:25.204+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T15:44:56.250+0000] {processor.py:157} INFO - Started process (PID=18485) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:44:56.251+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:44:56.252+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.251+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:44:56.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:44:56.276+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.276+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:44:56.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.290+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:44:56.303+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T15:45:27.172+0000] {processor.py:157} INFO - Started process (PID=18729) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:45:27.173+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:45:27.174+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.174+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:45:27.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:45:27.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.197+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:45:27.211+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.211+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:45:27.222+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.053 seconds
[2024-06-18T15:45:58.125+0000] {processor.py:157} INFO - Started process (PID=18975) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:45:58.127+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:45:58.129+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:58.128+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:45:58.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:45:58.168+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:58.168+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:45:58.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:58.182+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:45:58.193+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.070 seconds
[2024-06-18T15:46:28.749+0000] {processor.py:157} INFO - Started process (PID=19217) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:46:28.750+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:46:28.750+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.750+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:46:28.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:46:28.781+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.781+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:46:28.797+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.796+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:46:28.811+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.064 seconds
[2024-06-18T15:46:58.977+0000] {processor.py:157} INFO - Started process (PID=19461) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:46:58.978+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:46:58.980+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.980+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:46:58.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:46:59.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:59.007+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:46:59.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:59.021+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:46:59.033+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.058 seconds
[2024-06-18T15:47:29.533+0000] {processor.py:157} INFO - Started process (PID=19705) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:47:29.535+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:47:29.539+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.538+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:47:29.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:47:29.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.572+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:47:29.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.594+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:47:29.608+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.077 seconds
[2024-06-18T15:47:59.842+0000] {processor.py:157} INFO - Started process (PID=19949) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:47:59.843+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:47:59.846+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.845+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:47:59.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:47:59.874+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.874+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:47:59.888+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.888+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:47:59.900+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T15:48:30.669+0000] {processor.py:157} INFO - Started process (PID=20195) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:48:30.669+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:48:30.670+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.670+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:48:30.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:48:30.690+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.690+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:48:30.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.702+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:48:30.710+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T15:49:00.730+0000] {processor.py:157} INFO - Started process (PID=20437) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:49:00.731+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:49:00.731+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.731+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:49:00.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:49:00.753+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.753+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:49:00.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.765+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:49:00.775+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T15:49:31.486+0000] {processor.py:157} INFO - Started process (PID=20681) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:49:31.487+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:49:31.488+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.488+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:49:31.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:49:31.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.511+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:49:31.526+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.525+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:49:31.539+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.055 seconds
[2024-06-18T15:50:02.475+0000] {processor.py:157} INFO - Started process (PID=20926) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:50:02.476+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:50:02.476+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.476+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:50:02.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:50:02.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.502+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:50:02.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.513+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:50:02.525+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T15:50:33.424+0000] {processor.py:157} INFO - Started process (PID=21168) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:50:33.425+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:50:33.426+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.425+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:50:33.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:50:33.448+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.448+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:50:33.460+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.460+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:50:33.469+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T15:51:03.534+0000] {processor.py:157} INFO - Started process (PID=21412) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:51:03.535+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:51:03.535+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.535+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:51:03.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:51:03.555+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.555+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:51:03.566+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.566+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:51:03.574+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.042 seconds
[2024-06-18T15:51:33.587+0000] {processor.py:157} INFO - Started process (PID=21652) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:51:33.587+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:51:33.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.587+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:51:33.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:51:33.599+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.599+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:51:33.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.610+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:51:33.617+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.033 seconds
[2024-06-18T15:52:04.332+0000] {processor.py:157} INFO - Started process (PID=21894) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:52:04.332+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:52:04.333+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.333+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:52:04.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:52:04.354+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.354+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:52:04.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.367+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:52:04.375+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:52:34.918+0000] {processor.py:157} INFO - Started process (PID=22138) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:52:34.920+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:52:34.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.920+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:52:34.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:52:35.216+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:35.216+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:52:35.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:35.231+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:52:35.243+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.328 seconds
[2024-06-18T15:53:05.271+0000] {processor.py:157} INFO - Started process (PID=22382) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:53:05.271+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:53:05.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.272+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:53:05.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:53:05.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.294+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:53:05.306+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.306+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:53:05.319+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T15:53:35.641+0000] {processor.py:157} INFO - Started process (PID=22626) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:53:35.642+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:53:35.643+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.643+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:53:35.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:53:35.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.669+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:53:35.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.683+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:53:35.696+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.057 seconds
[2024-06-18T15:54:06.804+0000] {processor.py:157} INFO - Started process (PID=22870) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:54:06.805+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:54:06.805+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.805+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:54:06.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:54:06.837+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.836+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:54:06.862+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.861+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:54:06.878+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.077 seconds
[2024-06-18T15:54:37.042+0000] {processor.py:157} INFO - Started process (PID=23114) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:54:37.043+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:54:37.044+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:37.044+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:54:37.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:54:37.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:37.067+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:54:37.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:37.081+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:54:37.093+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T15:55:07.217+0000] {processor.py:157} INFO - Started process (PID=23358) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:55:07.218+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:55:07.218+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.218+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:55:07.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:55:07.403+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.403+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:55:07.460+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.460+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:55:07.473+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.258 seconds
[2024-06-18T15:55:37.673+0000] {processor.py:157} INFO - Started process (PID=23602) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:55:37.674+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:55:37.675+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.675+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:55:37.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:55:37.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.699+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:55:37.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.711+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:55:37.722+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T15:56:08.618+0000] {processor.py:157} INFO - Started process (PID=23846) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:56:08.619+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:56:08.619+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.619+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:56:08.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:56:08.642+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.642+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:56:08.657+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.656+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:56:08.668+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.052 seconds
[2024-06-18T15:56:39.480+0000] {processor.py:157} INFO - Started process (PID=24090) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:56:39.482+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:56:39.482+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.482+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:56:39.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:56:39.509+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.509+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:56:39.522+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.522+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:56:39.531+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T15:57:09.935+0000] {processor.py:157} INFO - Started process (PID=24334) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:57:09.936+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:57:09.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.936+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:57:09.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:57:09.957+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.957+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:57:09.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.970+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:57:09.978+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T15:57:40.963+0000] {processor.py:157} INFO - Started process (PID=24578) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:57:40.964+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:57:40.965+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.965+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:57:40.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:57:40.991+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.991+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:57:41.004+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:41.004+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:57:41.013+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.053 seconds
[2024-06-18T15:58:11.177+0000] {processor.py:157} INFO - Started process (PID=24822) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:58:11.178+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:58:11.178+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.178+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:58:11.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:58:11.200+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.200+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:58:11.213+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.213+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:58:11.221+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:58:42.164+0000] {processor.py:157} INFO - Started process (PID=25066) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:58:42.165+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:58:42.165+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.165+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:58:42.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:58:42.188+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.188+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:58:42.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.201+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:58:42.211+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.049 seconds
[2024-06-18T15:59:12.861+0000] {processor.py:157} INFO - Started process (PID=25310) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:59:12.862+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:59:12.862+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.862+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:59:12.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:59:12.884+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.884+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:59:12.896+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.896+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:59:12.905+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T15:59:43.019+0000] {processor.py:157} INFO - Started process (PID=25554) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:59:43.020+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T15:59:43.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:43.021+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:59:43.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T15:59:43.047+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:43.047+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T15:59:43.060+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:43.060+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:59:43.071+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T16:00:13.487+0000] {processor.py:157} INFO - Started process (PID=25798) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:00:13.488+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:00:13.489+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.488+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:00:13.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:00:13.552+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.552+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:00:13.564+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.564+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:00:13.575+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.090 seconds
[2024-06-18T16:00:43.825+0000] {processor.py:157} INFO - Started process (PID=26042) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:00:43.826+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:00:43.827+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.826+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:00:43.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:00:43.919+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.919+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:00:43.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.945+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:00:43.955+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.132 seconds
[2024-06-18T16:01:14.828+0000] {processor.py:157} INFO - Started process (PID=26286) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:01:14.829+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:01:14.829+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.829+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:01:14.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:01:14.849+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.849+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:01:14.861+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.861+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:01:14.870+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T16:01:45.040+0000] {processor.py:157} INFO - Started process (PID=26530) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:01:45.041+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:01:45.043+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:45.043+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:01:45.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:01:45.065+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:45.065+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:01:45.078+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:45.078+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:01:45.089+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T16:02:15.178+0000] {processor.py:157} INFO - Started process (PID=26774) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:02:15.179+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:02:15.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.179+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:02:15.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:02:15.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.201+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:02:15.214+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.214+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:02:15.224+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T16:02:45.303+0000] {processor.py:157} INFO - Started process (PID=27017) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:02:45.304+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:02:45.305+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.305+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:02:45.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:02:45.325+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.324+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:02:45.335+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.335+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:02:45.344+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.042 seconds
[2024-06-18T16:03:15.575+0000] {processor.py:157} INFO - Started process (PID=27261) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:03:15.575+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:03:15.576+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.576+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:03:15.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:03:15.597+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.597+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:03:15.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.610+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:03:15.619+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T16:03:45.728+0000] {processor.py:157} INFO - Started process (PID=27505) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:03:45.729+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:03:45.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.729+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:03:45.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:03:45.749+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.749+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:03:45.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.761+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:03:45.770+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T16:04:15.877+0000] {processor.py:157} INFO - Started process (PID=27749) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:04:15.880+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:04:15.881+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.881+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:04:15.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:04:15.906+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.906+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:04:15.921+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.921+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:04:15.933+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.060 seconds
[2024-06-18T16:04:45.973+0000] {processor.py:157} INFO - Started process (PID=27993) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:04:45.974+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:04:45.974+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.974+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:04:45.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:04:45.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.995+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:04:46.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:46.007+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:04:46.015+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T16:05:16.829+0000] {processor.py:157} INFO - Started process (PID=28239) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:05:16.830+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:05:16.830+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.830+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:05:16.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:05:16.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.882+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:05:16.922+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.921+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:05:16.938+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.111 seconds
[2024-06-18T16:05:47.218+0000] {processor.py:157} INFO - Started process (PID=28481) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:05:47.219+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:05:47.219+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.219+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:05:47.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:05:47.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.239+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:05:47.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.251+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:05:47.259+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.043 seconds
[2024-06-18T16:06:17.496+0000] {processor.py:157} INFO - Started process (PID=28725) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:06:17.497+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:06:17.497+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.497+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:06:17.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:06:17.519+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.519+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:06:17.532+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.532+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:06:17.541+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T16:06:47.604+0000] {processor.py:157} INFO - Started process (PID=28969) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:06:47.605+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:06:47.605+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.605+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:06:47.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:06:47.630+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.630+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:06:47.644+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.644+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:06:47.653+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T16:07:18.005+0000] {processor.py:157} INFO - Started process (PID=29213) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:07:18.006+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:07:18.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:18.007+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:07:18.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:07:18.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:18.030+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:07:18.042+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:18.042+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:07:18.051+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T16:07:48.340+0000] {processor.py:157} INFO - Started process (PID=29457) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:07:48.341+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:07:48.341+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.341+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:07:48.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:07:48.362+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.362+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:07:48.374+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.374+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:07:48.383+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T16:08:18.447+0000] {processor.py:157} INFO - Started process (PID=29701) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:08:18.447+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:08:18.448+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.448+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:08:18.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:08:18.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.469+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:08:18.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.480+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:08:18.489+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T16:08:48.677+0000] {processor.py:157} INFO - Started process (PID=29945) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:08:48.678+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:08:48.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.678+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:08:48.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:08:48.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.699+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:08:48.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.710+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:08:48.719+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T16:46:37.643+0000] {processor.py:157} INFO - Started process (PID=30197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:46:37.646+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T16:46:37.647+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:37.646+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:46:37.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T16:46:37.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:37.698+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T16:46:37.726+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:37.726+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:46:37.753+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.112 seconds
[2024-06-18T17:23:56.463+0000] {processor.py:157} INFO - Started process (PID=30442) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:23:56.464+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:23:56.467+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:56.467+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:23:56.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:23:56.512+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:56.512+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:23:56.528+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:56.528+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:23:56.543+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.082 seconds
[2024-06-18T17:24:27.088+0000] {processor.py:157} INFO - Started process (PID=30686) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:24:27.090+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:24:27.091+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:27.090+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:24:27.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:24:27.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:27.128+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:24:27.150+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:27.150+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:24:27.166+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.081 seconds
[2024-06-18T17:24:57.359+0000] {processor.py:157} INFO - Started process (PID=30924) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:24:57.366+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:24:57.369+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.368+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:24:57.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:24:57.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.414+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:24:57.429+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.429+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:24:57.443+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.089 seconds
[2024-06-18T17:25:28.398+0000] {processor.py:157} INFO - Started process (PID=31174) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:25:28.400+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:25:28.401+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.401+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:25:28.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:25:28.445+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.445+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:25:28.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.464+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:25:28.485+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.091 seconds
[2024-06-18T17:25:58.534+0000] {processor.py:157} INFO - Started process (PID=31414) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:25:58.535+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:25:58.536+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.536+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:25:58.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:25:58.557+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.557+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:25:58.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.567+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:25:58.577+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T17:26:29.490+0000] {processor.py:157} INFO - Started process (PID=31656) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:26:29.491+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:26:29.492+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.491+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:26:29.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:26:29.512+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.512+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:26:29.523+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.523+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:26:29.533+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T17:27:00.093+0000] {processor.py:157} INFO - Started process (PID=31900) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:27:00.093+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:27:00.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.094+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:27:00.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:27:00.114+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.114+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:27:00.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.128+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:27:00.137+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T17:27:30.951+0000] {processor.py:157} INFO - Started process (PID=32144) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:27:30.952+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:27:30.953+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.953+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:27:30.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:27:30.976+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.975+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:27:30.987+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.987+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:27:30.996+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T17:28:01.652+0000] {processor.py:157} INFO - Started process (PID=32388) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:28:01.653+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:28:01.653+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.653+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:28:01.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:28:01.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.674+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:28:01.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.686+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:28:01.695+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T17:28:32.051+0000] {processor.py:157} INFO - Started process (PID=32632) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:28:32.053+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:28:32.054+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.053+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:28:32.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:28:32.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.079+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:28:32.091+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.090+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:28:32.100+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.051 seconds
[2024-06-18T17:29:02.415+0000] {processor.py:157} INFO - Started process (PID=32876) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:29:02.416+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:29:02.416+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.416+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:29:02.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:29:02.442+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.442+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:29:02.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.458+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:29:02.467+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T17:29:33.266+0000] {processor.py:157} INFO - Started process (PID=33119) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:29:33.266+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:29:33.267+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.267+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:29:33.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:29:33.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.289+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:29:33.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.300+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:29:33.308+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T17:30:03.926+0000] {processor.py:157} INFO - Started process (PID=33363) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:30:03.926+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:30:03.927+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.927+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:30:03.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:30:03.948+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.948+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:30:03.960+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.960+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:30:03.969+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T17:30:34.311+0000] {processor.py:157} INFO - Started process (PID=33607) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:30:34.312+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:30:34.312+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.312+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:30:34.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:30:34.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.334+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:30:34.347+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.347+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:30:34.357+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.048 seconds
[2024-06-18T17:31:04.571+0000] {processor.py:157} INFO - Started process (PID=33851) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:31:04.572+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:31:04.573+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.573+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:31:04.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:31:04.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.594+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:31:04.605+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.605+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:31:04.613+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.044 seconds
[2024-06-18T17:31:34.774+0000] {processor.py:157} INFO - Started process (PID=34095) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:31:34.776+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:31:34.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.777+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:31:34.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:31:34.824+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.824+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:31:34.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.842+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:31:34.856+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.085 seconds
[2024-06-18T17:32:05.656+0000] {processor.py:157} INFO - Started process (PID=34339) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:32:05.658+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:32:05.659+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.659+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:32:05.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:32:05.709+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.709+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:32:05.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.740+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:32:05.764+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.111 seconds
[2024-06-18T17:32:36.164+0000] {processor.py:157} INFO - Started process (PID=34583) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:32:36.165+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:32:36.165+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.165+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:32:36.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:32:36.188+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.188+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:32:36.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.235+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:32:36.244+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.082 seconds
[2024-06-18T17:33:06.676+0000] {processor.py:157} INFO - Started process (PID=34826) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:33:06.677+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:33:06.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.678+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:33:06.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:33:06.707+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.707+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:33:06.724+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.724+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:33:06.737+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.062 seconds
[2024-06-18T17:33:37.188+0000] {processor.py:157} INFO - Started process (PID=35070) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:33:37.189+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:33:37.190+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.190+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:33:37.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:33:37.215+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.215+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:33:37.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.230+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:33:37.241+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T17:34:07.829+0000] {processor.py:157} INFO - Started process (PID=35314) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:34:07.830+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:34:07.830+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.830+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:34:07.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:34:07.853+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.852+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:34:07.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.865+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:34:07.874+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.047 seconds
[2024-06-18T17:34:38.179+0000] {processor.py:157} INFO - Started process (PID=35558) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:34:38.181+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:34:38.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.182+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:34:38.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:34:38.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.205+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:34:38.222+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.221+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:34:38.233+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T17:35:08.689+0000] {processor.py:157} INFO - Started process (PID=35803) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:35:08.691+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:35:08.692+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.691+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:35:08.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:35:08.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.713+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:35:08.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.725+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:35:08.734+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.046 seconds
[2024-06-18T17:35:39.072+0000] {processor.py:157} INFO - Started process (PID=36047) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:35:39.073+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:35:39.073+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.073+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:35:39.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:35:39.096+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.096+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:35:39.111+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.111+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:35:39.124+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T17:36:09.820+0000] {processor.py:157} INFO - Started process (PID=36290) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:36:09.822+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:36:09.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.822+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:36:09.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:36:09.851+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.851+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:36:09.864+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.864+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:36:09.874+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.056 seconds
[2024-06-18T17:36:40.536+0000] {processor.py:157} INFO - Started process (PID=36534) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:36:40.537+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:36:40.538+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.537+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:36:40.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:36:40.561+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.561+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:36:40.578+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.578+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:36:40.588+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T17:37:11.180+0000] {processor.py:157} INFO - Started process (PID=36778) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:37:11.181+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:37:11.181+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.181+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:37:11.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:37:11.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.207+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:37:11.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.221+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:37:11.231+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.053 seconds
[2024-06-18T17:37:41.824+0000] {processor.py:157} INFO - Started process (PID=37022) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:37:41.826+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:37:41.827+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.827+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:37:41.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:37:41.860+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.860+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:37:41.873+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.873+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:37:41.882+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.061 seconds
[2024-06-18T17:38:12.240+0000] {processor.py:157} INFO - Started process (PID=37273) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:38:12.242+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:38:12.243+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.243+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:38:12.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:38:12.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.268+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:38:12.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.281+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:38:12.292+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.054 seconds
[2024-06-18T17:38:42.799+0000] {processor.py:157} INFO - Started process (PID=37517) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:38:42.800+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:38:42.801+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.800+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:38:42.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:38:42.828+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.827+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:38:42.849+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.849+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:38:42.860+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.065 seconds
[2024-06-18T17:39:13.558+0000] {processor.py:157} INFO - Started process (PID=37761) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:39:13.559+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T17:39:13.560+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.560+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:39:13.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T17:39:13.581+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.581+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T17:39:13.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.593+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:39:13.601+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.045 seconds
[2024-06-18T18:11:08.977+0000] {processor.py:157} INFO - Started process (PID=38006) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T18:11:08.978+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T18:11:08.979+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.979+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T18:11:08.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T18:11:09.005+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:09.005+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T18:11:09.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:09.037+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T18:11:09.054+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.079 seconds
[2024-06-18T19:34:54.750+0000] {processor.py:157} INFO - Started process (PID=38250) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T19:34:54.751+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T19:34:54.752+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.751+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T19:34:54.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T19:34:54.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.775+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T19:34:54.788+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.787+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T19:34:54.798+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.050 seconds
[2024-06-18T20:57:01.585+0000] {processor.py:157} INFO - Started process (PID=38494) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T20:57:01.587+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T20:57:01.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.588+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T20:57:01.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T20:57:01.613+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.613+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T20:57:01.629+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.629+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T20:57:01.640+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.057 seconds
[2024-06-18T22:35:27.275+0000] {processor.py:157} INFO - Started process (PID=38738) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T22:35:27.276+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T22:35:27.278+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:27.277+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T22:35:27.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T22:35:27.348+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:27.348+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T22:35:27.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:27.390+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T22:35:27.426+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.155 seconds
[2024-06-18T23:55:34.355+0000] {processor.py:157} INFO - Started process (PID=38982) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T23:55:34.356+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py for tasks to queue
[2024-06-18T23:55:34.357+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.357+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T23:55:34.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['example_bash_operator']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py
[2024-06-18T23:55:34.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.382+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-06-18T23:55:34.398+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.398+0000] {dag.py:3722} INFO - Setting next_dagrun for example_bash_operator to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T23:55:34.410+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_bash_operator.py took 0.057 seconds
