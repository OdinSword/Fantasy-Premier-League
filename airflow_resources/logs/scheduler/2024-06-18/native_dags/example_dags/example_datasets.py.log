[2024-06-18T10:02:06.228+0000] {processor.py:157} INFO - Started process (PID=177) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:02:06.231+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:02:06.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.233+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:02:06.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:02:06.328+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.301+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 274582, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:02:06.341+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.339+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 337213, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.349+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.349+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 347376, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.356+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.356+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 354547, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.359+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 358483, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.365+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 362571, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.366+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:02:06.483+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.482+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 481075, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.484+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 484546, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.493+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.491+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 488583, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.496+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.495+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 494829, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.510+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.501+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 499350, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.516+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.515+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 513223, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.518+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.518+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:02:06.928+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.928+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 926882, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.932+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.931+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 930839, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.934+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.934+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 933486, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.936+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.935+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 935480, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.939+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.938+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 937967, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.942+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.942+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 1, 36, 940711, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:06.944+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:06.944+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:02:06.948+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:02:37.495+0000] {processor.py:157} INFO - Started process (PID=416) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:02:37.497+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:02:37.498+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.498+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:02:37.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:02:37.543+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.543+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:02:37.557+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.556+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:02:37.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.559+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:02:37.560+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.560+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:02:37.561+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.561+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:02:37.562+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.562+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:02:37.563+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:02:37.563+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:02:37.580+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T10:03:07.767+0000] {processor.py:157} INFO - Started process (PID=672) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:03:07.769+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:03:07.770+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.770+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:03:07.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:03:07.796+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.793+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 37, 784286, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:03:07.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.797+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 37, 797038, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:07.799+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.799+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 37, 799010, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:07.800+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.800+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 37, 800134, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:07.801+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.801+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 37, 801359, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:07.803+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.802+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 37, 802481, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:07.803+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:07.803+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:03:08.181+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.180+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 178849, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.186+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.185+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 184084, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.190+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.189+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 188036, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.194+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.193+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 192321, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.198+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.197+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 196182, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.200+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 199756, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.203+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.202+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:03:08.870+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.870+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 869967, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.873+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.872+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 871849, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.875+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 874546, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.877+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.876+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 876453, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.878+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.878+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 877864, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.879+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.879+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 2, 38, 879027, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:08.880+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:08.880+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:03:08.881+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.350+0000] {processor.py:157} INFO - Started process (PID=916) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:03:39.352+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:03:39.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.353+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:03:39.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:03:39.381+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.377+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 367707, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:03:39.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.382+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 381995, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.384+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.384+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 383744, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.385+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.385+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 385038, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.386+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.386+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 386212, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.387+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 387464, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.389+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.389+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:03:39.802+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.800+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 797926, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.805+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.805+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 804234, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.809+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.808+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 807333, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.813+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.811+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 810936, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.818+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.817+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 815884, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.821+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.820+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 9, 819935, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:39.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:39.823+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:03:40.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.079+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 10, 77677, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:40.087+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.086+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 10, 84713, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:40.091+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.090+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 10, 89467, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:40.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.093+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 10, 93012, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:40.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.098+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 10, 96963, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:40.103+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.102+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 10, 101549, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:03:40.104+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:03:40.104+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:03:40.108+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.418+0000] {processor.py:157} INFO - Started process (PID=1165) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:04:10.419+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:04:10.420+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.420+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:04:10.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:04:10.442+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.440+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 431719, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:04:10.444+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.444+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 443746, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.449+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.449+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 448469, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.453+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.453+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 452709, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.454+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.454+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 453820, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.456+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 455792, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.457+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:04:10.696+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.695+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 695011, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.697+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 697340, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.699+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 698936, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.701+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.700+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 700402, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.702+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 702007, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.704+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.704+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 703559, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.705+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.705+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:04:10.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.970+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 969519, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.972+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.972+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 971845, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.974+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.974+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 973549, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.976+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.975+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 975246, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.977+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.977+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 976786, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.979+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.978+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 3, 40, 978355, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:10.979+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:10.979+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:04:10.981+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.032+0000] {processor.py:157} INFO - Started process (PID=1404) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:04:41.033+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:04:41.034+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.033+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:04:41.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:04:41.060+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.056+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 45326, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:04:41.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.061+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 61115, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.064+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.064+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 63487, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.065+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 65251, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.067+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 66897, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.069+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.068+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 68378, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.069+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.069+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:04:41.408+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.407+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 405572, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.412+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.411+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 410596, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.416+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.415+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 414513, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.420+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.419+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 418375, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.423+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.422+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 421765, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.426+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.425+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 425026, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.428+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.427+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:04:41.629+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.627+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 624434, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.636+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.635+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 633336, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.640+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.639+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 638033, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.644+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.643+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 641966, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.647+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.646+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 645756, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.650+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 11, 649565, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:04:41.653+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:04:41.652+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:04:41.655+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.392+0000] {processor.py:157} INFO - Started process (PID=1648) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:05:12.394+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:05:12.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.395+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:05:12.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:05:12.426+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.422+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 412224, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:05:12.428+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.427+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 426900, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.429+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.429+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 429174, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.431+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.430+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 430451, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.432+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.432+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 431630, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.433+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.433+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 432872, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.434+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.434+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:05:12.767+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.765+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 762264, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.773+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.772+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 770553, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.777+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 775741, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.781+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 780141, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.785+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 784583, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.788+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.788+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 42, 787338, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:12.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:12.789+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:05:13.697+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.695+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 692276, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.703+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.702+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 700669, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.706+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.705+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 704784, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.709+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 708312, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.713+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 712396, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.716+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.715+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 4, 43, 715168, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:13.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:13.717+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:05:13.721+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:43.817+0000] {processor.py:157} INFO - Started process (PID=1900) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:05:43.818+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:05:43.819+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.818+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:05:43.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:05:43.841+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.839+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 13, 830548, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:05:43.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.842+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 13, 842093, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:43.843+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.843+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 13, 843070, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:43.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.844+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 13, 844155, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:43.845+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.845+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 13, 845009, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:43.846+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.846+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 13, 845901, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:43.847+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:43.846+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:05:44.137+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.133+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 14, 129766, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:44.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.142+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 14, 141012, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:44.147+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.146+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 14, 145675, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:44.151+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.150+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 14, 149256, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:44.155+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.154+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 14, 153043, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:44.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.158+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 14, 157361, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:44.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:44.160+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:05:45.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:45.123+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 15, 120655, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:45.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:45.138+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 15, 128560, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:45.165+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:45.161+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 15, 143012, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:45.173+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:45.171+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 15, 169124, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:45.191+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:45.185+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 15, 177243, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:45.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:45.196+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 15, 194438, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:05:45.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:05:45.200+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:05:45.207+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.522+0000] {processor.py:157} INFO - Started process (PID=2164) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:06:15.523+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:06:15.524+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.524+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:06:15.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:06:15.544+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.541+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 45, 534533, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:06:15.545+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.545+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 45, 544977, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.547+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.546+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 45, 546388, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.548+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.547+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 45, 547476, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.548+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.548+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 45, 548454, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.550+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.549+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 45, 549426, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:15.550+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:15.550+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:06:16.010+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.009+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 7733, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.012+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.011+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 11411, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.013+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.013+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 12890, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.014+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.014+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 14086, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.016+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 15531, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.017+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 16882, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.018+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.018+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:06:16.679+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.677+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 675994, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.682+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.681+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 681265, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.683+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 683076, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.685+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.684+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 684366, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.686+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 685624, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.687+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.687+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 5, 46, 687017, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:16.688+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:16.688+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:06:16.690+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:06:46.786+0000] {processor.py:157} INFO - Started process (PID=2413) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:06:46.787+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:06:46.788+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.788+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:06:46.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:06:46.913+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.913+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:06:46.930+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.930+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:06:46.933+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.933+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:06:46.934+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.934+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:06:46.934+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.934+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:06:46.936+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.936+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:06:46.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:06:46.937+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:06:46.958+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.173 seconds
[2024-06-18T10:07:17.914+0000] {processor.py:157} INFO - Started process (PID=2654) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:07:17.917+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:07:17.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.917+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:07:17.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:07:17.955+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.955+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:07:17.968+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.968+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:07:17.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.970+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:07:17.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.970+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:07:17.971+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.971+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:07:17.972+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.972+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:07:17.973+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:17.973+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:07:17.985+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.075 seconds
[2024-06-18T10:07:48.153+0000] {processor.py:157} INFO - Started process (PID=2896) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:07:48.155+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:07:48.156+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.156+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:07:48.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:07:48.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.196+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:07:48.217+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.216+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:07:48.220+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.220+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:07:48.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.221+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:07:48.222+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.222+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:07:48.224+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.224+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:07:48.225+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:07:48.225+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:07:48.246+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.097 seconds
[2024-06-18T10:08:18.902+0000] {processor.py:157} INFO - Started process (PID=3137) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:08:18.904+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:08:18.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.904+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:08:18.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:08:18.955+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.955+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:08:18.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.970+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:08:18.972+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.972+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:08:18.973+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.973+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:08:18.974+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.973+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:08:18.975+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.975+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:08:18.976+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:18.976+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:08:18.992+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.093 seconds
[2024-06-18T10:08:49.152+0000] {processor.py:157} INFO - Started process (PID=3381) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:08:49.153+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:08:49.154+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.154+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:08:49.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:08:49.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.182+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:08:49.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.197+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:08:49.199+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.199+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:08:49.200+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.200+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:08:49.200+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.200+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:08:49.202+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.202+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:08:49.203+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:08:49.203+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:08:49.218+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.068 seconds
[2024-06-18T10:09:19.563+0000] {processor.py:157} INFO - Started process (PID=3618) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:09:19.565+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:09:19.566+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.565+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:09:19.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:09:19.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.587+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 578367, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:09:19.592+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.592+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 591785, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.593+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 593187, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.594+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 594414, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.595+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 595311, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.596+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 596423, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.597+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.597+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:09:19.724+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.723+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 723310, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.725+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 724985, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.726+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.726+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 726282, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.727+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.727+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 727356, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.728+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 728494, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.730+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.729+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 729588, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.730+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.730+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:09:19.891+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.889+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 888960, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.893+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.892+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 892162, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.895+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.894+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 894202, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.896+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.896+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 895956, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.898+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.898+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 897688, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.900+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.900+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 8, 49, 899507, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:19.901+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:19.901+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:09:19.903+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:09:50.702+0000] {processor.py:157} INFO - Started process (PID=3864) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:09:50.704+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:09:50.705+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.705+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:09:50.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:09:50.743+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.743+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:09:50.758+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.758+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:09:50.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.760+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:09:50.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:09:50.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:09:50.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.763+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:09:50.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:09:50.763+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:09:50.781+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2024-06-18T10:10:21.232+0000] {processor.py:157} INFO - Started process (PID=4107) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:10:21.236+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:10:21.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.236+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:10:21.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:10:21.273+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.273+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:10:21.287+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.287+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:10:21.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.289+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:10:21.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.290+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:10:21.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.290+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:10:21.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.292+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:10:21.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:21.292+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:10:21.308+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.079 seconds
[2024-06-18T10:10:51.899+0000] {processor.py:157} INFO - Started process (PID=4348) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:10:51.902+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:10:51.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.903+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:10:51.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:10:51.940+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.940+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:10:51.953+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.953+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:10:51.955+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.955+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:10:51.956+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.956+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:10:51.956+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.956+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:10:51.958+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.957+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:10:51.958+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:10:51.958+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:10:51.972+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.079 seconds
[2024-06-18T10:11:22.090+0000] {processor.py:157} INFO - Started process (PID=4586) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:11:22.091+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:11:22.092+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.092+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:11:22.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:11:22.107+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.105+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 99667, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:11:22.108+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.108+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 108259, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.109+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.109+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 109252, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.110+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.110+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 110177, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.111+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.111+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 111033, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.112+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.112+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 111788, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.112+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.112+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:11:22.476+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.476+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 476148, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.477+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.477+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 477322, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.478+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.478+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 478125, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.479+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.479+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 478856, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.479+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 479646, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.480+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 52, 480357, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:22.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:22.481+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:11:23.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:23.258+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 53, 255449, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:23.265+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:23.265+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 53, 263770, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:23.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:23.268+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 53, 267789, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:23.273+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:23.272+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 53, 271615, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:23.276+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:23.275+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 53, 274722, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:23.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:23.278+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 10, 53, 277574, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:23.280+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:23.280+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:11:23.284+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.327+0000] {processor.py:157} INFO - Started process (PID=4834) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:11:53.328+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:11:53.329+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.329+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:11:53.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:11:53.355+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.351+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 339993, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:11:53.357+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.356+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 356419, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.358+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.358+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 357746, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.359+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 358721, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.360+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.360+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 359834, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.361+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.361+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 360822, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.361+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.361+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:11:53.807+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.806+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 805060, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.809+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.808+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 808172, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.810+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.810+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 809936, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.812+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.811+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 811493, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.813+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.813+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 813128, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.816+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.815+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 23, 814777, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:53.817+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:53.817+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:11:54.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:54.233+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 24, 230912, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:54.241+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:54.240+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 24, 238806, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:54.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:54.245+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 24, 243355, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:54.250+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:54.249+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 24, 248215, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:54.255+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:54.254+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 24, 253124, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:54.258+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:54.258+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 11, 24, 257480, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:11:54.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:11:54.259+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:11:54.262+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:12:24.760+0000] {processor.py:157} INFO - Started process (PID=5079) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:12:24.762+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:12:24.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.764+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:12:24.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:12:24.870+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.870+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:12:24.881+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.881+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:12:24.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.883+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:12:24.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.883+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:12:24.884+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.884+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:12:24.885+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.885+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:12:24.886+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:24.886+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:12:24.902+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.147 seconds
[2024-06-18T10:12:55.220+0000] {processor.py:157} INFO - Started process (PID=5322) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:12:55.222+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:12:55.225+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.225+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:12:55.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:12:55.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.282+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:12:55.305+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.305+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:12:55.308+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.307+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:12:55.308+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.308+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:12:55.309+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.309+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:12:55.311+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.311+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:12:55.312+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:12:55.312+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:12:55.334+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.118 seconds
[2024-06-18T10:13:25.660+0000] {processor.py:157} INFO - Started process (PID=5563) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:13:25.661+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:13:25.662+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.662+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:13:25.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:13:25.696+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.695+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:13:25.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.710+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:13:25.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.712+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:13:25.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.713+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:13:25.714+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.714+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:13:25.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.717+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:13:25.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:25.718+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:13:25.735+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.079 seconds
[2024-06-18T10:13:56.211+0000] {processor.py:157} INFO - Started process (PID=5807) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:13:56.214+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:13:56.217+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.216+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:13:56.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:13:56.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.271+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:13:56.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.290+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:13:56.293+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.293+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:13:56.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.294+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:13:56.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.295+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:13:56.297+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.296+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:13:56.298+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:13:56.298+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:13:56.384+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.183 seconds
[2024-06-18T10:14:26.547+0000] {processor.py:157} INFO - Started process (PID=6050) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:14:26.549+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:14:26.550+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.550+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:14:26.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:14:26.601+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.600+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:14:26.615+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.615+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:14:26.617+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.617+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:14:26.618+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.618+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:14:26.618+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.618+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:14:26.620+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.620+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:14:26.621+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:26.621+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:14:26.635+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.091 seconds
[2024-06-18T10:14:56.981+0000] {processor.py:157} INFO - Started process (PID=6292) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:14:56.981+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:14:56.982+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.982+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:14:56.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:14:56.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.993+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 26, 988846, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:14:56.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.996+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 26, 996276, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:56.997+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.997+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 26, 997264, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:56.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.998+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 26, 998092, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:56.999+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.999+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 26, 998881, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:56.999+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 26, 999632, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.000+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:14:57.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.389+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 27, 387287, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.399+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.398+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 27, 396228, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.403+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.402+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 27, 400946, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.406+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.405+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 27, 404707, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.410+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.409+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 27, 408272, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.413+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.412+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 27, 411742, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:57.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:57.415+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:14:58.011+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:58.010+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 28, 9025, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:58.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:58.015+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 28, 14515, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:58.022+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:58.021+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 28, 19721, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:58.025+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:58.024+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 28, 23722, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:58.029+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:58.028+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 28, 26992, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:58.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:58.030+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 14, 28, 29891, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:14:58.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:14:58.030+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:14:58.033+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:15:28.127+0000] {processor.py:157} INFO - Started process (PID=6536) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:15:28.128+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:15:28.129+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.128+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:15:28.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:15:28.158+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.158+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:15:28.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.168+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:15:28.170+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.170+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:15:28.171+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.171+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:15:28.171+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.171+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:15:28.173+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.173+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:15:28.173+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:28.173+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:15:28.186+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.063 seconds
[2024-06-18T10:15:58.767+0000] {processor.py:157} INFO - Started process (PID=6772) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:15:58.770+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:15:58.772+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.771+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:15:58.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:15:58.843+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.843+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:15:58.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.902+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:15:58.905+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.905+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:15:58.906+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.906+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:15:58.907+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.906+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:15:58.909+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.909+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:15:58.910+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:15:58.910+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:15:58.963+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.205 seconds
[2024-06-18T10:16:29.175+0000] {processor.py:157} INFO - Started process (PID=7014) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:16:29.177+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:16:29.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.178+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:16:29.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:16:29.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.203+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 193929, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:16:29.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.208+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 207968, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.209+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 209398, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.210+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.210+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 210416, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.211+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.211+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 211325, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.212+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.212+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 212188, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.213+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.213+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:16:29.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.707+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 704599, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.714+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 713263, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.719+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.718+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 717110, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.723+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.722+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 721504, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.726+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.725+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 724765, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.728+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 15, 59, 727534, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:29.731+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:29.730+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:16:30.155+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.153+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 0, 152400, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:30.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.156+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 0, 156455, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:30.158+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.158+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 0, 158134, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:30.160+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.160+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 0, 159807, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:30.162+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.161+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 0, 161352, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:30.163+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.163+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 0, 162914, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:16:30.164+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:16:30.164+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:16:30.166+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.311+0000] {processor.py:157} INFO - Started process (PID=7262) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:17:00.313+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:17:00.314+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.314+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:17:00.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:17:00.339+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.336+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 327508, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:17:00.341+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.341+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 340673, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.343+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.342+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 342527, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.344+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.344+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 343755, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.345+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.345+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 344982, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.346+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.346+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 346236, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.347+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.347+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:17:00.731+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.729+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 725656, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.736+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.735+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 734443, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.739+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 738233, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.743+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.742+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 741900, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.746+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.746+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 745292, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.750+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.749+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 748133, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.751+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:17:00.954+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.952+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 950855, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.959+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.958+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 956851, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.962+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 961227, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.967+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.966+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 965138, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.969+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 968907, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.973+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.972+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 16, 30, 971940, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:00.974+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:00.974+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:17:00.978+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.141+0000] {processor.py:157} INFO - Started process (PID=7511) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:17:31.142+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:17:31.142+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.142+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:17:31.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:17:31.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.158+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 152205, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:17:31.163+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.163+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 162861, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.165+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.165+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 164777, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.167+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.166+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 166360, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.169+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.168+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 168274, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.170+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.170+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 169838, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.170+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.170+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:17:31.503+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.501+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 499414, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.509+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.508+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 506880, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.512+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 511594, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.516+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 515232, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.519+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 518595, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.523+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.522+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 1, 522042, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:31.524+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:31.524+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:17:32.206+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:32.205+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 2, 204136, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:32.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:32.208+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 2, 207403, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:32.210+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:32.209+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 2, 209368, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:32.211+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:32.211+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 2, 210920, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:32.213+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:32.213+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 2, 212685, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:32.215+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:32.214+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 17, 2, 214316, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:17:32.216+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:17:32.215+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:17:32.217+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:02.311+0000] {processor.py:157} INFO - Started process (PID=7754) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:18:02.312+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:18:02.314+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.313+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:18:02.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:18:02.529+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.529+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:18:02.547+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.546+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:18:02.756+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.756+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:18:02.758+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.758+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:18:02.759+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.759+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:18:02.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:18:02.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:02.762+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:18:02.783+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.475 seconds
[2024-06-18T10:18:32.823+0000] {processor.py:157} INFO - Started process (PID=8001) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:18:32.823+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:18:32.824+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.824+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:18:32.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:18:32.837+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.836+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 2, 830999, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:18:32.838+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.838+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 2, 838271, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:32.839+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.839+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 2, 839281, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:32.840+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.840+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 2, 840309, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:32.841+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.841+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 2, 841180, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:32.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.842+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 2, 841960, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:32.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:32.842+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:18:33.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.226+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 225517, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.229+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 228734, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.231+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 231176, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.233+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 233297, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.236+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 235467, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.237+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 237367, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.238+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:18:33.564+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.562+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 562032, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.566+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.566+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 565329, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.568+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 567715, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.570+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 569985, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.572+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 571955, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.574+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 18, 3, 573710, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:18:33.575+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:18:33.575+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:18:33.577+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:03.686+0000] {processor.py:157} INFO - Started process (PID=8240) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:19:03.689+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:19:03.691+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.691+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:19:03.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:19:03.722+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.722+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:19:03.736+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.736+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:19:03.739+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.738+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:19:03.739+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.739+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:19:03.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.740+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:19:03.742+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.742+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:19:03.742+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:03.742+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:19:03.788+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.105 seconds
[2024-06-18T10:19:33.967+0000] {processor.py:157} INFO - Started process (PID=8475) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:19:33.969+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:19:33.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:33.970+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:19:33.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:19:34.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:33.993+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 3, 983148, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:19:34.020+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.020+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 19351, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.022+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.022+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 21197, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.024+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.024+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 23539, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.026+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.026+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 25443, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.032+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.031+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 28314, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.033+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.033+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:19:34.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.457+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 456243, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.459+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 458979, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.460+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.460+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 460034, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.462+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.462+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 461255, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.464+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 463748, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.465+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.465+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 465289, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.466+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.466+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:19:34.850+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.849+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 847749, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.853+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.852+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 851943, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.856+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.855+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 854783, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.859+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.858+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 857833, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.861+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.861+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 860363, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.864+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.864+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 19, 4, 863211, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:19:34.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:19:34.865+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:19:34.869+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:20:04.935+0000] {processor.py:157} INFO - Started process (PID=8719) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:20:04.937+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:20:04.938+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:04.938+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:20:04.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:20:05.005+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:05.004+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:20:05.031+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:05.031+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:20:05.034+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:05.034+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:20:05.035+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:05.035+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:20:05.036+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:05.036+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:20:05.038+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:05.038+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:20:05.040+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:05.039+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:20:05.058+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.129 seconds
[2024-06-18T10:20:35.383+0000] {processor.py:157} INFO - Started process (PID=8963) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:20:35.384+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:20:35.385+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.385+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:20:35.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:20:35.428+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.428+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:20:35.444+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.443+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:20:35.450+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.449+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:20:35.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.456+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:20:35.462+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.462+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:20:35.484+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.484+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:20:35.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:20:35.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:20:35.535+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.156 seconds
[2024-06-18T10:21:06.005+0000] {processor.py:157} INFO - Started process (PID=9207) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:21:06.006+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:21:06.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.007+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:21:06.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:21:06.137+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.137+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:21:06.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.156+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:21:06.160+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.160+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:21:06.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.161+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:21:06.164+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.164+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:21:06.172+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.172+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:21:06.173+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:06.173+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:21:06.282+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.279 seconds
[2024-06-18T10:21:36.603+0000] {processor.py:157} INFO - Started process (PID=9451) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:21:36.606+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:21:36.608+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.608+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:21:36.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:21:36.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.669+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:21:36.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.683+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:21:36.685+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.685+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:21:36.685+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.685+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:21:36.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.686+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:21:36.688+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.687+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:21:36.688+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:21:36.688+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:21:36.704+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.108 seconds
[2024-06-18T10:22:07.243+0000] {processor.py:157} INFO - Started process (PID=9695) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:22:07.244+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:22:07.245+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.245+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:22:07.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:22:07.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.265+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 256516, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:22:07.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.270+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 270308, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.272+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 271921, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.273+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.273+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 273084, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.274+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.274+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 274105, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.275+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 274972, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.275+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:22:07.562+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.561+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 559126, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.566+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 564998, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.570+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.569+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 568777, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.573+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.573+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 572166, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.577+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.576+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 575396, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.580+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.579+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 578827, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.583+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.582+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:22:07.640+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.638+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 635084, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.645+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.644+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 642415, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.650+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.648+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 647680, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.655+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 654422, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.661+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.659+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 658418, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.664+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.663+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 21, 37, 662636, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:07.666+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:07.666+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:22:07.669+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:37.731+0000] {processor.py:157} INFO - Started process (PID=9939) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:22:37.732+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:22:37.733+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.733+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:22:37.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:22:37.757+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.754+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 7, 745759, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:22:37.759+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.758+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 7, 758123, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:37.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.760+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 7, 759611, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:37.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.761+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 7, 760871, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:37.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.762+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 7, 762145, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:37.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.763+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 7, 763327, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:37.764+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:37.764+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:22:38.220+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:38.216+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 8, 215036, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:38.249+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:38.248+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 8, 244412, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:38.255+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:38.253+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 8, 251732, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:38.258+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:38.257+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 8, 256547, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:38.261+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:38.261+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 8, 260145, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:38.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:38.263+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 8, 262979, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:38.265+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:38.265+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:22:39.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:39.082+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 9, 34352, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:39.086+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:39.086+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 9, 85537, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:39.088+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:39.088+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 9, 87787, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:39.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:39.098+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 9, 95862, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:39.100+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:39.100+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 9, 99798, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:39.102+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:39.101+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 9, 101110, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:22:39.102+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:22:39.102+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:22:39.109+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.008+0000] {processor.py:157} INFO - Started process (PID=10188) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:23:10.009+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:23:10.009+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.009+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:23:10.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:23:10.026+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.024+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 20050, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:23:10.027+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.027+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 26773, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.028+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.028+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 27761, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.029+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.029+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 28790, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.031+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.030+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 30336, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.032+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.032+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 31727, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.032+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.032+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:23:10.172+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.171+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 170824, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.174+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.174+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 173718, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.176+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.175+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 175458, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.177+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.177+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 176945, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.179+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 178418, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.181+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 181076, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.182+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:23:10.777+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.775+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 771763, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.782+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.781+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 780664, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.785+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.784+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 783767, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.788+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 787455, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.791+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 790773, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.796+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.795+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 22, 40, 794138, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:10.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:10.797+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:23:10.801+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:23:41.738+0000] {processor.py:157} INFO - Started process (PID=10432) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:23:41.739+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:23:41.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.740+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:23:41.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:23:41.770+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.769+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:23:41.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.785+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:23:41.788+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.788+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:23:41.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.789+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:23:41.790+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.790+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:23:41.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.792+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:23:41.793+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:23:41.793+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:23:41.815+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.081 seconds
[2024-06-18T10:24:12.282+0000] {processor.py:157} INFO - Started process (PID=10676) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:24:12.283+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:24:12.284+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.284+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:24:12.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:24:12.313+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.313+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:24:12.328+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.327+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:24:12.330+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.330+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:24:12.332+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.332+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:24:12.333+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.333+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:24:12.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.334+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:24:12.335+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:12.335+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:24:12.350+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.071 seconds
[2024-06-18T10:24:42.945+0000] {processor.py:157} INFO - Started process (PID=10920) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:24:42.946+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:24:42.946+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.946+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:24:42.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:24:42.974+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.974+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:24:42.986+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.986+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:24:42.988+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.988+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:24:42.989+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.989+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:24:42.989+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.989+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:24:42.991+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.991+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:24:42.991+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:24:42.991+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:24:43.005+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.062 seconds
[2024-06-18T10:25:13.609+0000] {processor.py:157} INFO - Started process (PID=11157) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:25:13.610+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:25:13.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.610+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:25:13.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:25:13.624+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.622+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 617483, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:25:13.627+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.626+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 626406, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.628+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.628+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 627703, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.629+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.629+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 628968, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.630+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.630+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 630002, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.631+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.631+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 631035, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.632+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.632+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:25:13.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.831+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 828777, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.836+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.835+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 834794, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.840+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.839+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 838124, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.842+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 841584, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.844+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 843791, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.847+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.846+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 845947, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.848+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.848+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:25:13.861+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.860+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 858798, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.863+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.863+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 862542, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.865+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 864623, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.867+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.866+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 866321, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.868+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.868+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 867840, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.870+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.869+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 24, 43, 869495, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:13.871+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:13.871+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:25:13.872+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.036+0000] {processor.py:157} INFO - Started process (PID=11398) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:25:44.038+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:25:44.038+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.038+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:25:44.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:25:44.057+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.055+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 48446, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:25:44.058+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.058+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 58082, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.059+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 59016, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.060+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.060+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 60003, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.061+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.061+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 60814, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.061+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 61609, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.062+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:25:44.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.243+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 242465, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.248+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.247+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 246530, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.252+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.251+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 250716, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.255+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.254+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 253650, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.257+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.256+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 256188, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.259+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.259+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 258492, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.260+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:25:44.305+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.304+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 301807, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.309+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.308+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 307298, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.312+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.311+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 310484, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.314+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.313+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 313253, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.316+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.316+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 315498, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.318+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.318+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 25, 14, 317734, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:25:44.319+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:25:44.319+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:25:44.322+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:14.413+0000] {processor.py:157} INFO - Started process (PID=11642) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:26:14.414+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:26:14.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.415+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:26:14.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:26:14.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.456+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:26:14.475+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.475+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:26:14.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:26:14.482+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.482+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:26:14.483+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.483+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:26:14.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.485+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:26:14.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:14.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:26:14.640+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.230 seconds
[2024-06-18T10:26:44.997+0000] {processor.py:157} INFO - Started process (PID=11889) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:26:44.999+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:26:45.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.000+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:26:45.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:26:45.306+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.303+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 298580, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:26:45.307+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.307+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 307025, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.308+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.308+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 308048, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.309+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.309+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 308987, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.310+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.310+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 309854, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.311+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.311+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 310815, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.311+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.311+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:26:45.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.370+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 370530, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.372+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.372+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 371866, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.373+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.373+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 372959, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.374+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.374+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 373763, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.376+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.376+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 376018, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.377+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.377+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 377067, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.378+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.378+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:26:45.705+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.704+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 704157, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.706+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.706+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 705962, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.707+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.707+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 706974, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.708+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.708+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 708084, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.709+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.709+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 708992, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.710+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 15, 710359, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:26:45.711+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:26:45.711+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:26:45.713+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.332+0000] {processor.py:157} INFO - Started process (PID=12133) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:27:16.333+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:27:16.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.334+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:27:16.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:27:16.349+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.347+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 342951, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T10:27:16.350+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.350+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 350097, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.351+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 351106, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.352+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.352+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 352011, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.353+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 352869, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.354+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.353+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 353635, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.354+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.354+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:27:16.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.654+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 653434, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.655+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 654942, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.656+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 655832, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.657+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.657+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 656778, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.658+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.657+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 657657, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.659+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.658+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 46, 658547, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:16.659+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:16.659+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:27:17.360+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:17.359+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 47, 359149, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:17.361+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:17.360+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 47, 360559, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:17.362+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:17.361+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 47, 361590, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:17.362+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:17.362+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 47, 362517, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:17.363+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:17.363+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 47, 363375, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:17.364+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:17.364+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 26, 47, 364264, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:27:17.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:27:17.365+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:27:17.366+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T10:59:25.405+0000] {processor.py:157} INFO - Started process (PID=12273) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:59:25.411+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:59:25.414+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:25.414+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:59:25.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:59:26.035+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.034+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:59:26.069+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.068+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:59:26.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.072+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:59:26.073+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.073+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:59:26.074+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.074+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:59:26.085+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.085+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:59:26.087+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:26.087+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:59:26.157+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.761 seconds
[2024-06-18T10:59:56.235+0000] {processor.py:157} INFO - Started process (PID=12518) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:59:56.236+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T10:59:56.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.237+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:59:56.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T10:59:56.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.272+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T10:59:56.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.289+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T10:59:56.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.292+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T10:59:56.293+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.293+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T10:59:56.293+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.293+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T10:59:56.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.295+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T10:59:56.296+0000] {logging_mixin.py:154} INFO - [2024-06-18T10:59:56.296+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T10:59:56.324+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.091 seconds
[2024-06-18T11:00:27.021+0000] {processor.py:157} INFO - Started process (PID=12760) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:00:27.022+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:00:27.022+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.022+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:00:27.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:00:27.042+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.039+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 32962, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:00:27.043+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.043+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 43046, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.044+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.044+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 44079, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.045+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.045+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 45245, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.046+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.046+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 46253, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.047+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.047+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 47321, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.048+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.048+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:00:27.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.280+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 279620, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.284+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.284+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 283514, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.287+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.286+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 286084, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.289+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 288467, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.291+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 290823, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.293+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 292929, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.294+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:00:27.993+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.992+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 992393, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.994+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 994227, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.996+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 995746, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.997+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 997281, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:27.999+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.998+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 998520, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:28.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:27.999+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 10, 59, 57, 999407, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:28.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:28.000+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:00:28.001+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.203+0000] {processor.py:157} INFO - Started process (PID=13003) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:00:58.205+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:00:58.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.205+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:00:58.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:00:58.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.228+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 219869, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:00:58.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.238+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 237153, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.241+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.241+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 240572, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.242+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.242+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 242092, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.243+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 243303, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.245+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.245+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 244695, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.246+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:00:58.401+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.401+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 400272, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.404+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.403+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 402912, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.405+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.405+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 404786, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.406+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.406+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 406236, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.407+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 407296, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.408+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.408+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 408246, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.409+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.409+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:00:58.981+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.981+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 981112, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.982+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.982+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 982467, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.983+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 983394, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.984+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.984+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 984176, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.985+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.985+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 985158, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.987+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.986+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 0, 28, 986377, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:00:58.987+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:00:58.987+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:00:58.988+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_produces_1', 'dag_id_4_3': 'dataset_consumes_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:01:29.144+0000] {processor.py:157} INFO - Started process (PID=13247) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:01:29.145+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:01:29.146+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.146+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:01:29.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:01:29.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.209+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:01:29.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.225+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:01:29.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:01:29.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:01:29.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.231+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:01:29.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.233+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:01:29.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:29.233+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:01:29.257+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.117 seconds
[2024-06-18T11:01:59.747+0000] {processor.py:157} INFO - Started process (PID=13491) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:01:59.748+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:01:59.749+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.749+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:01:59.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:01:59.780+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.780+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:01:59.807+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.807+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:01:59.809+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.809+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:01:59.810+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.810+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:01:59.811+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.811+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:01:59.813+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.813+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:01:59.814+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:01:59.814+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:01:59.831+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.086 seconds
[2024-06-18T11:02:30.061+0000] {processor.py:157} INFO - Started process (PID=13732) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:02:30.064+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:02:30.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.066+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:02:30.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:02:30.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.124+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 101436, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:02:30.139+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.139+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 137798, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.142+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 141936, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.148+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.147+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 145857, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.151+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.151+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 149797, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.155+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.154+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 154162, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.156+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.156+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:02:30.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.236+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 236044, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.238+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 237971, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.240+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 239453, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.243+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.242+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 241842, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.244+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 243937, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.248+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.248+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 247327, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.251+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:02:30.791+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.790+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 790082, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.792+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 792127, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.794+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.793+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 793391, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.795+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.794+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 794474, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.796+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.796+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 795808, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.797+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 2, 0, 797229, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:02:30.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:02:30.798+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:02:30.800+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:03:00.841+0000] {processor.py:157} INFO - Started process (PID=13976) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:03:00.843+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:03:00.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.844+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:03:00.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:03:00.881+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.881+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:03:00.897+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.896+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:03:00.899+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.898+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:03:00.899+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.899+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:03:00.900+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.900+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:03:00.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.902+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:03:00.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:00.903+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:03:00.920+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.083 seconds
[2024-06-18T11:03:31.390+0000] {processor.py:157} INFO - Started process (PID=14220) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:03:31.391+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:03:31.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.392+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:03:31.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:03:31.421+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.421+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:03:31.435+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.434+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:03:31.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.436+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:03:31.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.437+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:03:31.438+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.438+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:03:31.439+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.439+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:03:31.440+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:03:31.440+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:03:31.456+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.069 seconds
[2024-06-18T11:04:01.645+0000] {processor.py:157} INFO - Started process (PID=14462) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:04:01.647+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:04:01.648+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.648+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:04:01.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:04:01.720+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.720+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:04:01.735+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.735+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:04:01.737+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.737+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:04:01.737+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.737+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:04:01.738+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.738+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:04:01.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.740+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:04:01.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:01.740+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:04:01.758+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.116 seconds
[2024-06-18T11:04:31.878+0000] {processor.py:157} INFO - Started process (PID=14703) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:04:31.880+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:04:31.881+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.880+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:04:31.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:04:31.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.905+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 1, 897569, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:04:31.910+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.910+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 1, 909779, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:31.912+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.911+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 1, 911206, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:31.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.915+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 1, 914731, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:31.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.916+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 1, 916042, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:31.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.917+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 1, 917197, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:31.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:31.918+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:04:32.349+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:32.347+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 2, 345454, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:32.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:32.352+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 2, 351596, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:32.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:32.366+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 2, 358628, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:32.376+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:32.375+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 2, 374690, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:32.378+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:32.377+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 2, 377441, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:32.381+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:32.381+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 2, 380528, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:32.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:32.383+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:04:33.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:33.129+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 3, 128763, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:33.131+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:33.131+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 3, 131116, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:33.132+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:33.132+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 3, 132324, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:33.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:33.133+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 3, 133225, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:33.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:33.134+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 3, 133998, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:33.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:33.135+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 3, 134819, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:04:33.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:04:33.135+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:04:33.136+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.181+0000] {processor.py:157} INFO - Started process (PID=14952) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:05:03.182+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:05:03.183+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.183+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:05:03.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:05:03.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.204+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 197007, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:05:03.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.208+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 208212, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.210+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.209+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 209580, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.211+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.211+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 210765, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.212+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.212+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 211874, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.213+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.213+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 212971, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.214+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.213+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:05:03.421+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.418+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 416328, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.426+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.425+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 423721, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.428+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.428+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 427497, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.431+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.430+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 430181, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.433+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.433+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 432651, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.436+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.435+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 33, 434912, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:03.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:03.437+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:05:04.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:04.066+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 34, 64378, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:04.073+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:04.071+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 34, 69881, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:04.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:04.077+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 34, 75366, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:04.083+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:04.082+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 34, 81687, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:04.087+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:04.086+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 34, 85590, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:04.091+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:04.090+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 4, 34, 89758, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:04.093+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:04.092+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:05:04.097+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:05:34.299+0000] {processor.py:157} INFO - Started process (PID=15196) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:05:34.300+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:05:34.301+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.301+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:05:34.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:05:34.347+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.347+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:05:34.362+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.362+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:05:34.364+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.364+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:05:34.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.365+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:05:34.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.366+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:05:34.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.367+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:05:34.368+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:05:34.368+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:05:34.384+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T11:06:04.978+0000] {processor.py:157} INFO - Started process (PID=15438) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:06:04.981+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:06:04.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:04.983+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:06:04.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:06:05.050+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:05.050+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:06:05.112+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:05.111+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:06:05.119+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:05.119+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:06:05.124+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:05.124+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:06:05.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:05.125+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:06:05.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:05.128+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:06:05.132+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:05.132+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:06:05.157+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.201 seconds
[2024-06-18T11:06:35.678+0000] {processor.py:157} INFO - Started process (PID=15679) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:06:35.681+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:06:35.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.682+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:06:35.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:06:35.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.720+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 707620, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:06:35.727+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.726+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 726057, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.729+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 728629, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.732+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.732+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 731423, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.734+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.733+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 733322, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.736+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.736+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 735483, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.737+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.737+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:06:35.931+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.930+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 930247, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.933+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.933+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 932762, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.937+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 936473, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.939+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.939+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 938661, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.941+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.940+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 940338, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.942+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.942+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 5, 941848, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:35.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:35.942+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:06:36.266+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:36.264+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 6, 264222, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:36.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:36.271+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 6, 270521, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:36.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:36.274+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 6, 274334, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:36.277+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:36.276+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 6, 276366, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:36.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:36.278+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 6, 278346, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:36.280+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:36.280+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 6, 6, 279777, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:06:36.281+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:06:36.281+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:06:36.282+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:07:06.362+0000] {processor.py:157} INFO - Started process (PID=15926) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:07:06.364+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:07:06.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.366+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:07:06.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:07:06.643+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.643+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:07:06.884+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.882+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:07:06.909+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.908+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:07:06.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.917+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:07:06.922+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.922+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:07:06.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.935+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:07:06.941+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:06.941+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:07:06.978+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.621 seconds
[2024-06-18T11:07:37.152+0000] {processor.py:157} INFO - Started process (PID=16169) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:07:37.186+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:07:37.189+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.188+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:07:37.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:07:37.335+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.335+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:07:37.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.391+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:07:37.397+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.397+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:07:37.400+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.400+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:07:37.403+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.403+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:07:37.430+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.430+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:07:37.434+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:07:37.434+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:07:37.504+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.368 seconds
[2024-06-18T11:08:08.102+0000] {processor.py:157} INFO - Started process (PID=16414) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:08:08.103+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:08:08.104+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.104+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:08:08.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:08:08.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.129+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 119204, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:08:08.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.135+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 134402, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.137+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.136+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 136048, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.138+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.138+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 137719, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.140+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.139+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 139305, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.141+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 140764, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.142+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.142+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:08:08.439+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.438+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 437450, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.443+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.442+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 441280, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.446+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.445+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 444689, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.450+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.449+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 448175, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.452+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.452+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 451449, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.455+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.454+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 38, 453988, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:08.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:08.456+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:08:09.114+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:09.113+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 39, 112804, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:09.117+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:09.116+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 39, 116395, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:09.118+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:09.118+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 39, 117836, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:09.119+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:09.119+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 39, 119004, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:09.120+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:09.120+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 39, 119945, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:09.121+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:09.121+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 7, 39, 120868, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:09.122+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:09.122+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:08:09.123+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:08:39.319+0000] {processor.py:157} INFO - Started process (PID=16660) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:08:39.319+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:08:39.320+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.320+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:08:39.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:08:39.343+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.343+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:08:39.354+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.353+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:08:39.355+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.355+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:08:39.356+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.356+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:08:39.356+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.356+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:08:39.358+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.358+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:08:39.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:08:39.358+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:08:39.377+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.060 seconds
[2024-06-18T11:09:09.584+0000] {processor.py:157} INFO - Started process (PID=16902) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:09:09.585+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:09:09.586+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.585+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:09:09.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:09:09.599+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.597+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 592839, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:09:09.600+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.600+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 600011, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.601+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.601+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 601062, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.602+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.602+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 602291, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.603+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.603+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 603257, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.604+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.604+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 604259, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.605+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.605+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:09:09.616+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.615+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 615382, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.617+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.616+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 616669, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.618+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.618+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 617688, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.619+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.618+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 618643, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.619+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.619+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 619477, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.620+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.620+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 39, 620274, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:09.620+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:09.620+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:09:10.404+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:10.403+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 40, 401872, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:10.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:10.406+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 40, 406146, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:10.408+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:10.408+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 40, 408021, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:10.410+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:10.410+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 40, 409663, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:10.411+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:10.411+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 40, 411245, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:10.413+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:10.412+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 8, 40, 412539, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:10.413+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:10.413+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:09:10.415+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:09:40.726+0000] {processor.py:157} INFO - Started process (PID=17146) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:09:40.728+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:09:40.730+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.729+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:09:40.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:09:40.770+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.769+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:09:40.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.785+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:09:40.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.788+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:09:40.790+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.790+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:09:40.791+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.791+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:09:40.793+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.793+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:09:40.795+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:09:40.795+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:09:40.816+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.094 seconds
[2024-06-18T11:10:11.165+0000] {processor.py:157} INFO - Started process (PID=17390) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:10:11.166+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:10:11.167+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.167+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:10:11.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:10:11.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.180+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 175283, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:10:11.183+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.183+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 183094, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.184+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.184+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 184045, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.185+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.185+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 185201, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.186+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.186+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 186059, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.187+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.187+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 186822, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.187+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.187+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:10:11.614+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.613+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 612088, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.618+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.617+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 616071, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.622+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.621+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 619959, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.624+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 623585, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.628+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.627+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 626763, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.631+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.631+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 41, 630260, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:11.633+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:11.632+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:10:12.613+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:12.612+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 42, 609432, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:12.617+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:12.616+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 42, 615530, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:12.620+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:12.619+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 42, 618919, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:12.622+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:12.621+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 42, 621398, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:12.624+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:12.624+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 42, 623574, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:12.627+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:12.626+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 9, 42, 625819, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:12.628+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:12.627+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:10:12.630+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.515+0000] {processor.py:157} INFO - Started process (PID=17636) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:10:43.516+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:10:43.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.517+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:10:43.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:10:43.550+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.543+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "serialized_dag" does not exist
LINE 2: FROM serialized_dag 
             ^

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 532910, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-06-18T11:10:43.552+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.552+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 551507, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.555+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.555+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 553970, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.609+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.594+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 556908, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.714+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.713+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 703606, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.767+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.746+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 745152, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.788+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:10:43.913+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.912+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 912044, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.914+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.914+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 913801, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.915+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 914723, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.915+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 915616, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.916+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 916405, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.917+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 13, 917223, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:43.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:43.917+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:10:44.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:44.774+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 14, 772877, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:44.777+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:44.776+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 14, 776217, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:44.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:44.778+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 14, 777620, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:44.779+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:44.779+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_produces_1', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 14, 778912, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:44.780+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:44.780+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_unknown_never_scheduled', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 14, 779972, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:44.781+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:44.781+0000] {dagbag.py:644} ERROR - Failed to write serialized DAG: /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 633, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT %(param_1)s AS anon_1 
FROM serialized_dag 
WHERE serialized_dag.dag_id = %(dag_id_1)s AND serialized_dag.last_updated > %(last_updated_1)s]
[parameters: {'param_1': True, 'dag_id_1': 'dataset_consumes_1_and_2', 'last_updated_1': datetime.datetime(2024, 6, 18, 11, 10, 14, 781061, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:10:44.782+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:10:44.782+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:10:44.784+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 654, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 668, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 2953, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.InternalError: (psycopg2.errors.InFailedSqlTransaction) current transaction is aborted, commands ignored until end of transaction block

[SQL: SELECT dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.max_active_tasks, dag.max_active_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_3, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_1, task_outlet_dataset_reference_1.updated_at AS updated_at_1 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_4_1)s, %(dag_id_4_2)s, %(dag_id_4_3)s, %(dag_id_4_4)s, %(dag_id_4_5)s, %(dag_id_4_6)s) FOR UPDATE OF dag]
[parameters: {'dag_id_4_1': 'dataset_consumes_1_and_2', 'dag_id_4_2': 'dataset_consumes_1', 'dag_id_4_3': 'dataset_produces_1', 'dag_id_4_4': 'dataset_consumes_unknown_never_scheduled', 'dag_id_4_5': 'dataset_consumes_1_never_scheduled', 'dag_id_4_6': 'dataset_produces_2'}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
[2024-06-18T11:12:14.137+0000] {processor.py:157} INFO - Started process (PID=177) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:12:14.137+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:12:14.138+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.138+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:12:14.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:12:14.224+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.224+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.231+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.236+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.245+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.253+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.259+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.259+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.269+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.275+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.280+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.280+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.290+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.295+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.300+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.307+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.307+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.311+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.311+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.314+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.314+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.320+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.320+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.324+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.323+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.327+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-06-18T11:12:14.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.327+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:12:14.335+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.335+0000] {dag.py:2963} INFO - Creating ORM DAG for dataset_consumes_1_and_2
[2024-06-18T11:12:14.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.336+0000] {dag.py:2963} INFO - Creating ORM DAG for dataset_consumes_1_never_scheduled
[2024-06-18T11:12:14.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.336+0000] {dag.py:2963} INFO - Creating ORM DAG for dataset_produces_1
[2024-06-18T11:12:14.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.336+0000] {dag.py:2963} INFO - Creating ORM DAG for dataset_consumes_unknown_never_scheduled
[2024-06-18T11:12:14.337+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.337+0000] {dag.py:2963} INFO - Creating ORM DAG for dataset_consumes_1
[2024-06-18T11:12:14.337+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.337+0000] {dag.py:2963} INFO - Creating ORM DAG for dataset_produces_2
[2024-06-18T11:12:14.343+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.343+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:12:14.343+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.343+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:12:14.344+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.344+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:12:14.344+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.344+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:12:14.347+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.347+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:12:14.347+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:14.347+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:12:14.377+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.244 seconds
[2024-06-18T11:12:44.996+0000] {processor.py:157} INFO - Started process (PID=421) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:12:44.997+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:12:44.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:44.998+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:12:45.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:12:45.026+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.026+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:12:45.055+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.055+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:12:45.058+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.058+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:12:45.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.059+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:12:45.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.059+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:12:45.061+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.061+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:12:45.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:12:45.062+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:12:45.084+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T11:13:15.364+0000] {processor.py:157} INFO - Started process (PID=657) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:13:15.367+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:13:15.369+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.368+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:13:15.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:13:15.417+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.417+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:13:15.431+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.431+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:13:15.433+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.433+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:13:15.434+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.434+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:13:15.435+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.434+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:13:15.436+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.436+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:13:15.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:15.437+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:13:15.457+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.107 seconds
[2024-06-18T11:13:45.623+0000] {processor.py:157} INFO - Started process (PID=901) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:13:45.624+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:13:45.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.624+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:13:45.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:13:45.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.650+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:13:45.664+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.663+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:13:45.665+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.665+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:13:45.666+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.666+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:13:45.667+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.667+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:13:45.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.669+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:13:45.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:13:45.669+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:13:45.684+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.064 seconds
[2024-06-18T11:14:16.072+0000] {processor.py:157} INFO - Started process (PID=1146) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:14:16.079+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:14:16.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.082+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:14:16.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:14:16.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.182+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:14:16.228+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.227+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:14:16.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.234+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:14:16.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.237+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:14:16.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.239+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:14:16.247+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.247+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:14:16.256+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:16.254+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:14:16.340+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.281 seconds
[2024-06-18T11:14:46.466+0000] {processor.py:157} INFO - Started process (PID=1407) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:14:46.467+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:14:46.467+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.467+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:14:46.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:14:46.497+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.496+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:14:46.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.511+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:14:46.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.513+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:14:46.514+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.514+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:14:46.515+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.514+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:14:46.516+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.516+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:14:46.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:14:46.517+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:14:46.540+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.076 seconds
[2024-06-18T11:15:16.961+0000] {processor.py:157} INFO - Started process (PID=1649) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:15:16.962+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:15:16.964+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:16.963+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:15:16.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:15:17.004+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:17.004+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:15:17.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:17.017+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:15:17.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:17.019+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:15:17.020+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:17.020+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:15:17.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:17.021+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:15:17.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:17.022+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:15:17.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:17.023+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:15:17.038+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T11:15:47.185+0000] {processor.py:157} INFO - Started process (PID=1885) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:15:47.187+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:15:47.188+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.188+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:15:47.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:15:47.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.237+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:15:47.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.251+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:15:47.253+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.252+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:15:47.253+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.253+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:15:47.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.254+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:15:47.256+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.256+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:15:47.256+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:15:47.256+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:15:47.271+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.092 seconds
[2024-06-18T11:22:33.127+0000] {processor.py:157} INFO - Started process (PID=177) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:22:33.128+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:22:33.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.129+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:22:33.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:22:33.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.327+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:22:33.378+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.377+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:22:33.381+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.381+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:22:33.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.383+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:22:33.384+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.384+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:22:33.387+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.386+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:22:33.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:22:33.388+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:22:33.418+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.296 seconds
[2024-06-18T11:23:04.615+0000] {processor.py:157} INFO - Started process (PID=420) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:23:04.636+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:23:04.665+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:04.651+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:23:04.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:23:05.198+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:05.198+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:23:05.333+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:05.333+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:23:05.346+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:05.346+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:23:05.350+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:05.349+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:23:05.352+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:05.352+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:23:05.361+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:05.361+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:23:05.364+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:05.364+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:23:05.477+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 1.020 seconds
[2024-06-18T11:23:35.842+0000] {processor.py:157} INFO - Started process (PID=673) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:23:35.845+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:23:35.846+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.846+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:23:35.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:23:35.935+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.935+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:23:35.950+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.950+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:23:35.952+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.952+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:23:35.953+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.953+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:23:35.954+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.954+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:23:35.956+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.955+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:23:35.956+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:23:35.956+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:23:35.979+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.141 seconds
[2024-06-18T11:24:06.612+0000] {processor.py:157} INFO - Started process (PID=924) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:24:06.619+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:24:06.621+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.621+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:24:06.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:24:06.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.711+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:24:06.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.748+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:24:06.754+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.753+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:24:06.755+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.755+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:24:06.756+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.756+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:24:06.759+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.759+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:24:06.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:06.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:24:06.787+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.183 seconds
[2024-06-18T11:24:37.479+0000] {processor.py:157} INFO - Started process (PID=1176) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:24:37.480+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:24:37.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.481+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:24:37.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:24:37.504+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.503+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:24:37.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.517+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:24:37.519+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.518+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:24:37.519+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.519+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:24:37.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.520+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:24:37.521+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.521+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:24:37.522+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:24:37.522+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:24:37.540+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.062 seconds
[2024-06-18T11:25:07.624+0000] {processor.py:157} INFO - Started process (PID=1416) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:25:07.625+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:25:07.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.625+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:25:07.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:25:07.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.655+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:25:07.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.669+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:25:07.672+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.672+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:25:07.672+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.672+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:25:07.673+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.673+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:25:07.675+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.675+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:25:07.676+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:07.675+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:25:07.691+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.069 seconds
[2024-06-18T11:25:37.731+0000] {processor.py:157} INFO - Started process (PID=1660) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:25:37.732+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:25:37.732+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.732+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:25:37.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:25:37.757+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.757+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:25:37.769+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.769+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:25:37.771+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.771+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:25:37.772+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.772+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:25:37.772+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.772+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:25:37.774+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.774+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:25:37.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:25:37.775+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:25:37.790+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.061 seconds
[2024-06-18T11:26:07.903+0000] {processor.py:157} INFO - Started process (PID=1902) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:26:07.905+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:26:07.907+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:07.906+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:26:07.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:26:07.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:07.963+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:26:07.991+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:07.990+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:26:07.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:07.996+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:26:07.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:07.998+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:26:08.001+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:08.001+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:26:08.004+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:08.004+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:26:08.006+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:08.006+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:26:08.043+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.145 seconds
[2024-06-18T11:26:38.261+0000] {processor.py:157} INFO - Started process (PID=2154) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:26:38.263+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:26:38.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.264+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:26:38.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:26:38.302+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.302+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:26:38.317+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.316+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:26:38.319+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.319+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:26:38.322+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.322+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:26:38.322+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.322+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:26:38.324+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.324+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:26:38.325+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:26:38.325+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:26:38.341+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2024-06-18T11:27:09.028+0000] {processor.py:157} INFO - Started process (PID=2398) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:27:09.029+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:27:09.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.030+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:27:09.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:27:09.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.066+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:27:09.080+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.080+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:27:09.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.081+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:27:09.082+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.082+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:27:09.083+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.083+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:27:09.085+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.085+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:27:09.085+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:09.085+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:27:09.101+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.078 seconds
[2024-06-18T11:27:39.218+0000] {processor.py:157} INFO - Started process (PID=2646) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:27:39.219+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:27:39.220+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.219+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:27:39.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:27:39.256+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.256+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:27:39.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.269+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:27:39.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.271+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:27:39.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.272+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:27:39.273+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.273+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:27:39.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.275+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:27:39.276+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:27:39.276+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:27:39.298+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T11:28:09.600+0000] {processor.py:157} INFO - Started process (PID=2894) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:28:09.602+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:28:09.604+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.603+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:28:09.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:28:09.681+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.681+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:28:09.704+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.703+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:28:09.709+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.709+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:28:09.711+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.711+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:28:09.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.712+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:28:09.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.717+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:28:09.719+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:09.719+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:28:09.741+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.148 seconds
[2024-06-18T11:28:39.958+0000] {processor.py:157} INFO - Started process (PID=3146) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:28:39.959+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:28:39.960+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:39.960+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:28:39.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:28:39.999+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:39.999+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:28:40.013+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:40.013+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:28:40.015+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:40.015+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:28:40.015+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:40.015+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:28:40.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:40.016+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:28:40.018+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:40.018+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:28:40.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:28:40.018+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:28:40.035+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.082 seconds
[2024-06-18T11:29:10.696+0000] {processor.py:157} INFO - Started process (PID=3390) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:29:10.697+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:29:10.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.698+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:29:10.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:29:10.780+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.780+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:29:10.839+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.839+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:29:10.843+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.843+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:29:10.845+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.845+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:29:10.846+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.846+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:29:10.849+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.849+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:29:10.852+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:10.852+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:29:10.891+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.201 seconds
[2024-06-18T11:29:41.391+0000] {processor.py:157} INFO - Started process (PID=3642) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:29:41.394+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:29:41.395+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.395+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:29:41.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:29:41.449+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.449+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:29:41.476+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.476+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:29:41.479+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.479+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:29:41.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:29:41.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.481+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:29:41.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.485+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:29:41.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:29:41.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:29:41.510+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.136 seconds
[2024-06-18T11:30:12.064+0000] {processor.py:157} INFO - Started process (PID=3886) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:30:12.066+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:30:12.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.066+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:30:12.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:30:12.131+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.131+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:30:12.172+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.172+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:30:12.175+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.175+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:30:12.177+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.177+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:30:12.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.179+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:30:12.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.181+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:30:12.183+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:12.183+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:30:12.203+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.145 seconds
[2024-06-18T11:30:42.627+0000] {processor.py:157} INFO - Started process (PID=4130) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:30:42.630+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:30:42.632+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.631+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:30:42.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:30:42.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.712+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:30:42.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.741+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:30:42.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.746+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:30:42.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.747+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:30:42.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.748+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:30:42.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.750+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:30:42.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:30:42.751+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:30:42.769+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.149 seconds
[2024-06-18T11:31:13.191+0000] {processor.py:157} INFO - Started process (PID=4373) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:31:13.196+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:31:13.198+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.197+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:31:13.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:31:13.266+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.266+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:31:13.286+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.286+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:31:13.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.289+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:31:13.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.290+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:31:13.291+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.291+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:31:13.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.294+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:31:13.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:13.295+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:31:13.310+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.134 seconds
[2024-06-18T11:31:43.726+0000] {processor.py:157} INFO - Started process (PID=4619) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:31:43.728+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:31:43.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.729+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:31:43.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:31:43.799+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.798+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:31:43.818+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.818+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:31:43.820+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.820+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:31:43.821+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.821+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:31:43.822+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.822+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:31:43.824+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.824+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:31:43.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:31:43.825+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:31:43.844+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.125 seconds
[2024-06-18T11:32:14.107+0000] {processor.py:157} INFO - Started process (PID=4863) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:32:14.109+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:32:14.111+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.110+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:32:14.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:32:14.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.156+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:32:14.171+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.171+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:32:14.173+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.173+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:32:14.174+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.174+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:32:14.174+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.174+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:32:14.177+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.177+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:32:14.178+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:14.178+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:32:14.201+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.102 seconds
[2024-06-18T11:32:44.630+0000] {processor.py:157} INFO - Started process (PID=5115) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:32:44.632+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:32:44.634+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.633+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:32:44.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:32:44.696+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.696+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:32:44.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.713+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:32:44.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.715+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:32:44.716+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.716+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:32:44.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.717+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:32:44.719+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.719+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:32:44.720+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:32:44.720+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:32:44.737+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.120 seconds
[2024-06-18T11:33:15.081+0000] {processor.py:157} INFO - Started process (PID=5359) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:33:15.085+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:33:15.086+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.086+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:33:15.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:33:15.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.136+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:33:15.153+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.153+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:33:15.156+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.155+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:33:15.156+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.156+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:33:15.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.157+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:33:15.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.159+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:33:15.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:15.159+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:33:15.177+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.120 seconds
[2024-06-18T11:33:45.881+0000] {processor.py:157} INFO - Started process (PID=5603) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:33:45.883+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:33:45.884+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.883+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:33:45.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:33:45.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.937+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:33:45.964+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.964+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:33:45.971+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.971+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:33:45.972+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.971+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:33:45.972+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.972+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:33:45.975+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.975+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:33:45.976+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:33:45.976+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:33:45.993+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.126 seconds
[2024-06-18T11:34:16.763+0000] {processor.py:157} INFO - Started process (PID=5847) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:34:16.765+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:34:16.767+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.766+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:34:16.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:34:16.820+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.819+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:34:16.838+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.838+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:34:16.840+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.840+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:34:16.841+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.841+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:34:16.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.842+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:34:16.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.844+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:34:16.845+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:16.845+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:34:16.861+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.104 seconds
[2024-06-18T11:34:47.251+0000] {processor.py:157} INFO - Started process (PID=6091) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:34:47.253+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:34:47.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.253+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:34:47.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:34:47.308+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.308+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:34:47.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.327+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:34:47.331+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.331+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:34:47.333+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.333+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:34:47.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.334+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:34:47.341+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.340+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:34:47.345+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:34:47.344+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:34:47.369+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.123 seconds
[2024-06-18T11:35:17.553+0000] {processor.py:157} INFO - Started process (PID=6335) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:35:17.555+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:35:17.556+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.556+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:35:17.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:35:17.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.593+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:35:17.608+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.607+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:35:17.609+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.609+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:35:17.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.610+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:35:17.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.611+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:35:17.613+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.612+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:35:17.613+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:17.613+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:35:17.629+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.080 seconds
[2024-06-18T11:35:48.117+0000] {processor.py:157} INFO - Started process (PID=6579) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:35:48.118+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:35:48.119+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.119+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:35:48.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:35:48.184+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.183+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:35:48.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.205+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:35:48.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.208+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:35:48.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.209+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:35:48.210+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.210+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:35:48.212+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.212+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:35:48.213+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:35:48.213+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:35:48.235+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.126 seconds
[2024-06-18T11:36:18.929+0000] {processor.py:157} INFO - Started process (PID=6823) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:36:18.932+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:36:18.933+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:18.933+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:36:18.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:36:18.989+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:18.988+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:36:19.009+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:19.008+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:36:19.011+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:19.011+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:36:19.012+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:19.011+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:36:19.012+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:19.012+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:36:19.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:19.020+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:36:19.022+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:19.022+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:36:19.046+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.140 seconds
[2024-06-18T11:36:49.378+0000] {processor.py:157} INFO - Started process (PID=7067) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:36:49.381+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:36:49.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.382+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:36:49.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:36:49.448+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.447+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:36:49.470+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.470+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:36:49.473+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:36:49.473+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.473+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:36:49.474+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.474+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:36:49.477+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.477+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:36:49.478+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:36:49.478+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:36:49.501+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.144 seconds
[2024-06-18T11:37:19.931+0000] {processor.py:157} INFO - Started process (PID=7311) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:37:19.934+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:37:19.936+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:19.935+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:37:19.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:37:19.987+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:19.987+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:37:20.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:20.016+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:37:20.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:20.019+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:37:20.020+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:20.020+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:37:20.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:20.021+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:37:20.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:20.023+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:37:20.024+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:20.023+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:37:20.042+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.127 seconds
[2024-06-18T11:37:50.595+0000] {processor.py:157} INFO - Started process (PID=7563) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:37:50.596+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:37:50.597+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.597+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:37:50.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:37:50.644+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.644+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:37:50.659+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.659+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:37:50.661+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.661+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:37:50.662+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.662+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:37:50.663+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.663+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:37:50.665+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.665+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:37:50.666+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:37:50.666+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:37:50.686+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.094 seconds
[2024-06-18T11:38:21.358+0000] {processor.py:157} INFO - Started process (PID=7807) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:38:21.361+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:38:21.363+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.363+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:38:21.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:38:21.434+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.434+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:38:21.454+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.454+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:38:21.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.457+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:38:21.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.458+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:38:21.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.458+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:38:21.461+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.461+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:38:21.462+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:21.462+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:38:21.479+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T11:38:51.963+0000] {processor.py:157} INFO - Started process (PID=8049) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:38:51.965+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:38:51.966+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:51.966+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:38:51.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:38:52.039+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:52.039+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:38:52.060+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:52.060+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:38:52.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:52.062+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:38:52.064+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:52.063+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:38:52.064+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:52.064+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:38:52.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:52.066+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:38:52.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:38:52.067+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:38:52.086+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.129 seconds
[2024-06-18T11:39:22.498+0000] {processor.py:157} INFO - Started process (PID=8294) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:39:22.499+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:39:22.501+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.500+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:39:22.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:39:22.560+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.560+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:39:22.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.590+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:39:22.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.594+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:39:22.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.596+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:39:22.597+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.597+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:39:22.600+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.600+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:39:22.602+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:22.601+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:39:22.621+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T11:39:53.157+0000] {processor.py:157} INFO - Started process (PID=8537) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:39:53.159+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:39:53.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.160+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:39:53.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:39:53.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.207+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:39:53.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.233+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:39:53.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.235+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:39:53.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.236+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:39:53.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.237+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:39:53.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.239+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:39:53.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:39:53.240+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:39:53.257+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.105 seconds
[2024-06-18T11:40:23.614+0000] {processor.py:157} INFO - Started process (PID=8781) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:40:23.617+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:40:23.619+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.618+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:40:23.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:40:23.687+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.687+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:40:23.709+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.709+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:40:23.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.712+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:40:23.714+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.714+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:40:23.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.714+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:40:23.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.717+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:40:23.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:23.718+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:40:23.736+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.146 seconds
[2024-06-18T11:40:54.435+0000] {processor.py:157} INFO - Started process (PID=9030) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:40:54.436+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:40:54.438+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.437+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:40:54.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:40:54.509+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.509+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:40:54.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.530+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:40:54.533+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.533+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:40:54.534+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.533+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:40:54.534+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.534+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:40:54.538+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.538+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:40:54.539+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:40:54.539+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:40:54.763+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.334 seconds
[2024-06-18T11:41:24.945+0000] {processor.py:157} INFO - Started process (PID=9278) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:41:24.947+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:41:24.949+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:24.948+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:41:24.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:41:25.010+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:25.010+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:41:25.048+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:25.047+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:41:25.052+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:25.051+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:41:25.053+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:25.053+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:41:25.054+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:25.054+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:41:25.056+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:25.056+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:41:25.057+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:25.057+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:41:25.076+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.153 seconds
[2024-06-18T11:41:55.806+0000] {processor.py:157} INFO - Started process (PID=9522) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:41:55.807+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:41:55.808+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.808+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:41:55.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:41:55.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.883+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:41:55.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.915+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:41:55.919+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.919+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:41:55.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.920+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:41:55.921+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.921+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:41:55.928+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.928+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:41:55.929+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:41:55.929+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:41:55.949+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.150 seconds
[2024-06-18T11:42:26.568+0000] {processor.py:157} INFO - Started process (PID=9765) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:42:26.571+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:42:26.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:26.572+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:42:26.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:42:26.646+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:26.646+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:42:27.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:27.015+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:42:27.018+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:27.018+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:42:27.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:27.019+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:42:27.020+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:27.019+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:42:27.022+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:27.021+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:42:27.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:27.023+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:42:27.043+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.483 seconds
[2024-06-18T11:42:57.334+0000] {processor.py:157} INFO - Started process (PID=10018) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:42:57.335+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:42:57.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.335+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:42:57.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:42:57.436+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.436+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:42:57.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:42:57.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:42:57.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.485+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:42:57.488+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.488+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:42:57.495+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.495+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:42:57.497+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:42:57.497+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:42:57.802+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.473 seconds
[2024-06-18T11:43:28.466+0000] {processor.py:157} INFO - Started process (PID=10262) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:43:28.476+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:43:28.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.480+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:43:28.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:43:28.533+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.533+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:43:28.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.553+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:43:28.555+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.555+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:43:28.556+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.556+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:43:28.557+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.557+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:43:28.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.559+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:43:28.560+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:28.560+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:43:28.579+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.132 seconds
[2024-06-18T11:43:59.352+0000] {processor.py:157} INFO - Started process (PID=10513) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:43:59.353+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:43:59.355+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.355+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:43:59.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:43:59.434+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.434+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:43:59.454+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.454+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:43:59.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.458+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:43:59.460+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.460+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:43:59.461+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.461+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:43:59.465+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.465+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:43:59.467+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:43:59.467+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:43:59.487+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.141 seconds
[2024-06-18T11:44:29.951+0000] {processor.py:157} INFO - Started process (PID=10756) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:44:29.954+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:44:29.957+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:29.956+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:44:30.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:44:30.044+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:30.044+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:44:30.318+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:30.318+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:44:30.320+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:30.320+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:44:30.320+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:30.320+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:44:30.321+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:30.321+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:44:30.323+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:30.323+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:44:30.324+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:44:30.324+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:44:30.344+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.403 seconds
[2024-06-18T11:45:01.367+0000] {processor.py:157} INFO - Started process (PID=11001) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:45:01.370+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:45:01.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.371+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:45:01.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:45:01.428+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.428+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:45:01.449+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.449+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:45:01.452+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.452+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:45:01.452+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.452+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:45:01.453+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.453+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:45:01.455+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.455+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:45:01.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:01.456+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:45:01.723+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.370 seconds
[2024-06-18T11:45:32.023+0000] {processor.py:157} INFO - Started process (PID=11245) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:45:32.028+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:45:32.031+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.030+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:45:32.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:45:32.090+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.090+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:45:32.110+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.110+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:45:32.112+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.112+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:45:32.113+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.113+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:45:32.114+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.114+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:45:32.116+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.116+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:45:32.117+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:45:32.117+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:45:32.134+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T11:46:02.730+0000] {processor.py:157} INFO - Started process (PID=11489) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:46:02.734+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:46:02.739+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:02.738+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:46:02.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:46:02.805+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:02.805+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:46:03.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:03.075+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:46:03.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:03.079+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:46:03.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:03.081+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:46:03.083+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:03.083+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:46:03.087+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:03.086+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:46:03.090+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:03.090+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:46:03.113+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.408 seconds
[2024-06-18T11:46:34.012+0000] {processor.py:157} INFO - Started process (PID=11733) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:46:34.014+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:46:34.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.016+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:46:34.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:46:34.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.071+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:46:34.346+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.346+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:46:34.349+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.349+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:46:34.350+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.350+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:46:34.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.351+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:46:34.352+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.352+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:46:34.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:46:34.353+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:46:34.371+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.382 seconds
[2024-06-18T11:47:04.908+0000] {processor.py:157} INFO - Started process (PID=11977) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:47:04.935+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:47:04.944+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:04.940+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:47:04.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:47:05.047+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.046+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:47:05.076+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.076+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:47:05.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.079+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:47:05.080+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.080+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:47:05.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.081+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:47:05.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.084+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:47:05.086+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:05.085+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:47:05.395+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.513 seconds
[2024-06-18T11:47:35.463+0000] {processor.py:157} INFO - Started process (PID=12234) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:47:35.464+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:47:35.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.464+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:47:35.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:47:35.491+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.491+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:47:35.504+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.504+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:47:35.507+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.507+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:47:35.508+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.508+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:47:35.509+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.509+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:47:35.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.510+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:47:35.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:47:35.511+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:47:35.531+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.072 seconds
[2024-06-18T11:48:05.630+0000] {processor.py:157} INFO - Started process (PID=12473) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:48:05.633+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:48:05.635+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:05.634+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:48:05.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:48:06.053+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.052+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:48:06.069+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.069+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:48:06.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.072+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:48:06.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.075+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:48:06.077+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.076+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:48:06.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.079+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:48:06.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:06.081+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:48:06.112+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.497 seconds
[2024-06-18T11:48:36.217+0000] {processor.py:157} INFO - Started process (PID=12717) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:48:36.219+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:48:36.220+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.219+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:48:36.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:48:36.310+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.310+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:48:36.331+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.331+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:48:36.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.334+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:48:36.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.334+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:48:36.335+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.335+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:48:36.337+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.337+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:48:36.338+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:48:36.338+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:48:36.359+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.148 seconds
[2024-06-18T11:49:07.114+0000] {processor.py:157} INFO - Started process (PID=12961) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:49:07.116+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:49:07.117+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.117+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:49:07.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:49:07.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.204+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:49:07.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.227+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:49:07.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:49:07.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.231+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:49:07.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.231+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:49:07.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.233+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:49:07.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:07.234+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:49:07.258+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.150 seconds
[2024-06-18T11:49:37.599+0000] {processor.py:157} INFO - Started process (PID=13205) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:49:37.602+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:49:37.606+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.605+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:49:37.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:49:37.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.677+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:49:37.696+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.696+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:49:37.700+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.700+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:49:37.701+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.701+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:49:37.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.702+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:49:37.704+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.704+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:49:37.705+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:49:37.705+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:49:37.723+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.132 seconds
[2024-06-18T11:50:08.405+0000] {processor.py:157} INFO - Started process (PID=13449) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:50:08.408+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:50:08.409+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.409+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:50:08.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:50:08.453+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.453+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:50:08.471+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.471+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:50:08.473+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.473+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:50:08.474+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.474+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:50:08.475+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.475+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:50:08.478+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.478+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:50:08.479+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:08.479+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:50:08.495+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T11:50:38.563+0000] {processor.py:157} INFO - Started process (PID=13692) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:50:38.565+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:50:38.566+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.566+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:50:38.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:50:38.604+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.604+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:50:38.617+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.617+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:50:38.620+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.620+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:50:38.621+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.620+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:50:38.621+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.621+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:50:38.624+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.624+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:50:38.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:50:38.625+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:50:38.644+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.086 seconds
[2024-06-18T11:51:09.188+0000] {processor.py:157} INFO - Started process (PID=13936) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:51:09.193+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:51:09.196+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.195+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:51:09.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:51:09.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.264+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:51:09.285+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.285+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:51:09.288+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.288+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:51:09.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.288+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:51:09.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.289+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:51:09.291+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.291+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:51:09.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:09.292+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:51:09.318+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.140 seconds
[2024-06-18T11:51:39.989+0000] {processor.py:157} INFO - Started process (PID=14183) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:51:39.992+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:51:39.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:39.994+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:51:40.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:51:40.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:40.072+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:51:40.092+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:40.092+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:51:40.095+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:40.095+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:51:40.096+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:40.096+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:51:40.097+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:40.097+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:51:40.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:40.099+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:51:40.101+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:51:40.101+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:51:40.123+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.143 seconds
[2024-06-18T11:52:10.537+0000] {processor.py:157} INFO - Started process (PID=14426) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:52:10.540+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:52:10.542+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.541+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:52:10.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:52:10.627+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.627+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:52:10.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.650+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:52:10.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.655+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:52:10.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.656+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:52:10.657+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.657+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:52:10.662+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.662+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:52:10.663+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:10.663+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:52:10.684+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.153 seconds
[2024-06-18T11:52:40.839+0000] {processor.py:157} INFO - Started process (PID=14669) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:52:40.846+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:52:40.847+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.846+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:52:40.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:52:40.921+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.921+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:52:40.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.943+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:52:40.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.945+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:52:40.946+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.946+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:52:40.947+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.947+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:52:40.949+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.949+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:52:40.950+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:52:40.949+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:52:40.967+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.148 seconds
[2024-06-18T11:53:11.469+0000] {processor.py:157} INFO - Started process (PID=14912) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:53:11.471+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:53:11.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.472+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:53:11.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:53:11.531+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.530+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:53:11.550+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.549+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:53:11.552+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.551+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:53:11.552+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.552+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:53:11.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.553+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:53:11.555+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.555+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:53:11.556+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:11.556+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:53:11.580+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.117 seconds
[2024-06-18T11:53:41.737+0000] {processor.py:157} INFO - Started process (PID=15164) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:53:41.739+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:53:41.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.740+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:53:41.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:53:41.813+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.813+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:53:41.829+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.828+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:53:41.831+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.830+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:53:41.831+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.831+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:53:41.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.832+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:53:41.834+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.834+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:53:41.835+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:53:41.835+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:53:41.857+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T11:54:12.042+0000] {processor.py:157} INFO - Started process (PID=15408) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:54:12.043+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:54:12.046+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.046+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:54:12.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:54:12.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.081+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:54:12.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.094+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:54:12.096+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.096+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:54:12.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.098+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:54:12.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.099+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:54:12.101+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.101+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:54:12.102+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:12.102+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:54:12.118+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.078 seconds
[2024-06-18T11:54:42.410+0000] {processor.py:157} INFO - Started process (PID=15652) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:54:42.411+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:54:42.412+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.412+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:54:42.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:54:42.462+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.461+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:54:42.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:54:42.483+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.483+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:54:42.484+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.484+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:54:42.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.485+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:54:42.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:54:42.488+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:54:42.488+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:54:42.513+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.107 seconds
[2024-06-18T11:55:12.715+0000] {processor.py:157} INFO - Started process (PID=15896) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:55:12.716+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:55:12.717+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.717+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:55:12.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:55:12.756+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.756+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:55:12.773+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.773+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:55:12.777+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.776+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:55:12.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.778+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:55:12.779+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.779+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:55:12.781+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.781+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:55:12.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:12.783+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:55:12.808+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.096 seconds
[2024-06-18T11:55:43.448+0000] {processor.py:157} INFO - Started process (PID=16140) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:55:43.455+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:55:43.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.456+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:55:43.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:55:43.514+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.514+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:55:43.529+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.529+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:55:43.531+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.531+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:55:43.532+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.531+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:55:43.532+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.532+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:55:43.534+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.534+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:55:43.535+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:55:43.535+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:55:43.551+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T11:56:13.767+0000] {processor.py:157} INFO - Started process (PID=16384) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:56:13.768+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:56:13.769+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.769+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:56:13.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:56:13.800+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.800+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:56:13.814+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.814+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:56:13.816+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.816+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:56:13.817+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.817+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:56:13.818+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.818+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:56:13.820+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.820+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:56:13.821+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:13.821+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:56:13.842+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.077 seconds
[2024-06-18T11:56:44.215+0000] {processor.py:157} INFO - Started process (PID=16628) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:56:44.220+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:56:44.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.220+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:56:44.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:56:44.261+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.261+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:56:44.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.275+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:56:44.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.279+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:56:44.281+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.281+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:56:44.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.281+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:56:44.288+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.287+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:56:44.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:56:44.289+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:56:44.308+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.108 seconds
[2024-06-18T11:57:14.522+0000] {processor.py:157} INFO - Started process (PID=16872) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:57:14.523+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:57:14.524+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.524+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:57:14.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:57:14.557+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.557+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:57:14.569+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.569+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:57:14.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.571+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:57:14.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.572+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:57:14.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.572+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:57:14.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.574+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:57:14.575+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:14.575+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:57:14.590+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.072 seconds
[2024-06-18T11:57:44.752+0000] {processor.py:157} INFO - Started process (PID=17115) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:57:44.754+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:57:44.755+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.754+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:57:44.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:57:44.819+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.819+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:57:44.833+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.833+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:57:44.835+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.835+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:57:44.835+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.835+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:57:44.836+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.836+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:57:44.838+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.838+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:57:44.839+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:57:44.839+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:57:44.854+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.106 seconds
[2024-06-18T11:58:15.022+0000] {processor.py:157} INFO - Started process (PID=17360) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:58:15.024+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:58:15.025+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.025+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:58:15.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:58:15.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.062+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:58:15.077+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.077+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:58:15.080+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.079+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:58:15.080+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.080+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:58:15.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.081+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:58:15.083+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.083+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:58:15.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:15.084+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:58:15.104+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2024-06-18T11:58:45.425+0000] {processor.py:157} INFO - Started process (PID=17604) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:58:45.426+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:58:45.427+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.426+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:58:45.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:58:45.466+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.466+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:58:45.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:58:45.484+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.483+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:58:45.486+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.486+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:58:45.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:58:45.488+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.488+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:58:45.489+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:58:45.489+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:58:45.506+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T11:59:16.333+0000] {processor.py:157} INFO - Started process (PID=17856) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:59:16.334+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:59:16.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.335+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:59:16.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:59:16.364+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.364+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:59:16.376+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.376+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:59:16.379+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.379+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:59:16.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.381+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:59:16.384+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.384+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:59:16.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.392+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:59:16.402+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:16.401+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:59:16.462+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.131 seconds
[2024-06-18T11:59:46.767+0000] {processor.py:157} INFO - Started process (PID=18093) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:59:46.768+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T11:59:46.769+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.769+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:59:46.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T11:59:46.804+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.804+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T11:59:46.817+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.817+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T11:59:46.819+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.819+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T11:59:46.820+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.820+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T11:59:46.821+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.821+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T11:59:46.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.823+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T11:59:46.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T11:59:46.823+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T11:59:46.841+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.076 seconds
[2024-06-18T12:00:17.334+0000] {processor.py:157} INFO - Started process (PID=18340) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:00:17.336+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:00:17.337+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.336+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:00:17.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:00:17.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.396+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:00:17.412+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.412+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:00:17.414+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.414+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:00:17.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.415+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:00:17.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.415+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:00:17.417+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.417+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:00:17.418+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:17.418+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:00:17.453+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.123 seconds
[2024-06-18T12:00:48.065+0000] {processor.py:157} INFO - Started process (PID=18589) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:00:48.066+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:00:48.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.066+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:00:48.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:00:48.101+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.101+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:00:48.115+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.115+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:00:48.117+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.116+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:00:48.117+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.117+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:00:48.118+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.118+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:00:48.119+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.119+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:00:48.120+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:00:48.120+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:00:48.136+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.073 seconds
[2024-06-18T12:01:18.324+0000] {processor.py:157} INFO - Started process (PID=18827) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:01:18.326+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:01:18.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.327+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:01:18.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:01:18.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.367+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:01:18.380+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.380+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:01:18.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.382+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:01:18.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.382+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:01:18.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.383+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:01:18.385+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.385+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:01:18.386+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:18.386+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:01:18.401+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T12:01:48.569+0000] {processor.py:157} INFO - Started process (PID=19072) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:01:48.570+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:01:48.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.571+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:01:48.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:01:48.635+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.635+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:01:48.652+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.652+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:01:48.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.655+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:01:48.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.656+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:01:48.657+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.657+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:01:48.659+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.659+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:01:48.660+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:01:48.660+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:01:48.683+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.117 seconds
[2024-06-18T12:02:19.309+0000] {processor.py:157} INFO - Started process (PID=19316) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:02:19.310+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:02:19.311+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.311+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:02:19.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:02:19.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.353+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:02:19.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.382+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:02:19.386+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.386+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:02:19.387+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.387+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:02:19.387+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.387+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:02:19.389+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.389+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:02:19.390+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:19.390+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:02:19.407+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.101 seconds
[2024-06-18T12:02:49.764+0000] {processor.py:157} INFO - Started process (PID=19559) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:02:49.766+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:02:49.767+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.767+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:02:49.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:02:49.819+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.819+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:02:49.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.832+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:02:49.834+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.834+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:02:49.835+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.835+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:02:49.836+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.836+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:02:49.837+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.837+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:02:49.838+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:02:49.838+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:02:49.855+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T12:06:12.958+0000] {processor.py:157} INFO - Started process (PID=19808) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:06:12.959+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:06:12.959+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:12.959+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:06:12.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:06:13.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.000+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:06:13.015+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.014+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:06:13.018+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.017+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:06:13.018+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.018+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:06:13.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.019+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:06:13.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.021+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:06:13.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:13.021+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:06:13.036+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.080 seconds
[2024-06-18T12:06:43.390+0000] {processor.py:157} INFO - Started process (PID=20051) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:06:43.392+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:06:43.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.393+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:06:43.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:06:43.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.485+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:06:43.510+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.510+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:06:43.514+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.514+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:06:43.518+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.518+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:06:43.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.520+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:06:43.524+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.524+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:06:43.525+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:06:43.525+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:06:43.557+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2024-06-18T12:07:13.625+0000] {processor.py:157} INFO - Started process (PID=20295) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:07:13.627+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:07:13.630+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.629+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:07:13.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:07:13.695+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.695+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:07:13.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.725+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:07:13.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.729+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:07:13.731+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.731+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:07:13.734+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.734+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:07:13.739+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.739+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:07:13.742+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:13.741+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:07:13.771+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.152 seconds
[2024-06-18T12:07:44.171+0000] {processor.py:157} INFO - Started process (PID=20543) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:07:44.172+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:07:44.174+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.173+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:07:44.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:07:44.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.232+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:07:44.247+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.246+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:07:44.250+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.249+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:07:44.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.250+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:07:44.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.251+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:07:44.253+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.253+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:07:44.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:07:44.254+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:07:44.272+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.106 seconds
[2024-06-18T12:08:15.245+0000] {processor.py:157} INFO - Started process (PID=20787) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:08:15.247+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:08:15.249+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.248+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:08:15.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:08:15.333+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.333+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:08:15.360+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.359+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:08:15.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.364+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:08:15.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.366+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:08:15.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.367+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:08:15.370+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.370+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:08:15.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:15.371+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:08:15.394+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.152 seconds
[2024-06-18T12:08:45.671+0000] {processor.py:157} INFO - Started process (PID=21032) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:08:45.673+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:08:45.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.673+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:08:45.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:08:45.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.751+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:08:45.782+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.782+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:08:45.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.785+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:08:45.787+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.786+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:08:45.787+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.787+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:08:45.790+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.790+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:08:45.791+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:08:45.791+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:08:45.810+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.147 seconds
[2024-06-18T12:09:16.139+0000] {processor.py:157} INFO - Started process (PID=21276) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:09:16.140+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:09:16.142+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.141+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:09:16.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:09:16.206+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.206+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:09:16.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.226+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:09:16.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:09:16.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:09:16.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.231+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:09:16.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.234+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:09:16.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:16.235+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:09:16.257+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.121 seconds
[2024-06-18T12:09:46.414+0000] {processor.py:157} INFO - Started process (PID=21520) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:09:46.417+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:09:46.420+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.418+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:09:46.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:09:46.515+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.515+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:09:46.546+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.546+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:09:46.550+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.550+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:09:46.552+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.551+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:09:46.552+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.552+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:09:46.555+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.555+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:09:46.556+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:09:46.556+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:09:46.576+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.177 seconds
[2024-06-18T12:10:16.794+0000] {processor.py:157} INFO - Started process (PID=21764) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:10:16.798+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:10:16.802+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.800+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:10:16.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:10:16.862+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.862+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:10:16.899+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.899+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:10:16.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.903+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:10:16.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.904+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:10:16.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.904+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:10:16.907+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.907+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:10:16.907+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:16.907+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:10:16.929+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.156 seconds
[2024-06-18T12:10:47.178+0000] {processor.py:157} INFO - Started process (PID=22007) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:10:47.181+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:10:47.183+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.182+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:10:47.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:10:47.274+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.274+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:10:47.293+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.292+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:10:47.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.295+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:10:47.296+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.296+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:10:47.297+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.297+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:10:47.299+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.299+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:10:47.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:10:47.300+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:10:47.320+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.153 seconds
[2024-06-18T12:11:18.075+0000] {processor.py:157} INFO - Started process (PID=22256) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:11:18.077+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:11:18.077+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.077+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:11:18.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:11:18.140+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.140+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:11:18.156+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.156+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:11:18.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.158+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:11:18.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.159+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:11:18.160+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.160+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:11:18.162+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.162+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:11:18.163+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:18.163+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:11:18.182+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.110 seconds
[2024-06-18T12:11:48.385+0000] {processor.py:157} INFO - Started process (PID=22500) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:11:48.388+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:11:48.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.389+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:11:48.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:11:48.438+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.438+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:11:48.466+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.466+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:11:48.468+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.468+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:11:48.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:11:48.470+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.470+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:11:48.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:11:48.473+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:11:48.473+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:11:48.490+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.120 seconds
[2024-06-18T12:12:18.654+0000] {processor.py:157} INFO - Started process (PID=22743) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:12:18.656+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:12:18.657+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.656+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:12:18.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:12:18.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.725+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:12:18.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.741+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:12:18.743+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.743+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:12:18.744+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.744+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:12:18.745+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.745+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:12:18.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.746+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:12:18.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:18.747+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:12:18.767+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.121 seconds
[2024-06-18T12:12:49.046+0000] {processor.py:157} INFO - Started process (PID=22992) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:12:49.048+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:12:49.050+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.050+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:12:49.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:12:49.096+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.096+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:12:49.118+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.117+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:12:49.120+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.120+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:12:49.121+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.121+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:12:49.122+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.122+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:12:49.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.125+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:12:49.126+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:12:49.126+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:12:49.147+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.109 seconds
[2024-06-18T12:13:20.068+0000] {processor.py:157} INFO - Started process (PID=23236) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:13:20.070+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:13:20.071+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.071+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:13:20.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:13:20.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.128+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:13:20.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.143+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:13:20.145+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.145+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:13:20.145+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.145+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:13:20.146+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.146+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:13:20.148+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.148+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:13:20.148+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:20.148+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:13:20.164+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.100 seconds
[2024-06-18T12:13:50.362+0000] {processor.py:157} INFO - Started process (PID=23479) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:13:50.364+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:13:50.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.366+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:13:50.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:13:50.446+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.446+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:13:50.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.481+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:13:50.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.484+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:13:50.486+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.485+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:13:50.486+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.486+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:13:50.488+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.488+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:13:50.489+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:13:50.489+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:13:50.506+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.158 seconds
[2024-06-18T12:14:20.628+0000] {processor.py:157} INFO - Started process (PID=23724) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:14:20.630+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:14:20.631+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.631+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:14:20.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:14:20.690+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.690+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:14:20.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.710+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:14:20.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.712+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:14:20.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.713+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:14:20.714+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.714+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:14:20.716+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.716+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:14:20.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:20.718+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:14:20.775+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.172 seconds
[2024-06-18T12:14:51.363+0000] {processor.py:157} INFO - Started process (PID=23966) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:14:51.373+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:14:51.377+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.376+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:14:51.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:14:51.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.457+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:14:51.476+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.476+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:14:51.479+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.479+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:14:51.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:14:51.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.481+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:14:51.483+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.483+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:14:51.483+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:14:51.483+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:14:51.503+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.148 seconds
[2024-06-18T12:15:22.477+0000] {processor.py:157} INFO - Started process (PID=24211) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:15:22.480+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:15:22.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.481+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:15:22.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:15:22.538+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.538+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:15:22.556+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.556+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:15:22.558+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.558+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:15:22.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.559+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:15:22.561+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.561+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:15:22.563+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.563+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:15:22.564+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:22.564+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:15:22.581+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.112 seconds
[2024-06-18T12:15:52.752+0000] {processor.py:157} INFO - Started process (PID=24454) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:15:52.754+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:15:52.756+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.755+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:15:52.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:15:52.826+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.826+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:15:52.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.844+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:15:52.847+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.846+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:15:52.847+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.847+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:15:52.848+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.848+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:15:52.850+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.850+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:15:52.851+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:15:52.851+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:15:52.874+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T12:16:22.963+0000] {processor.py:157} INFO - Started process (PID=24703) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:16:22.967+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:16:22.971+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:22.969+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:16:22.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:16:23.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.021+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:16:23.035+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.035+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:16:23.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.037+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:16:23.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.037+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:16:23.038+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.038+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:16:23.040+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.040+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:16:23.041+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:23.041+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:16:23.058+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.101 seconds
[2024-06-18T12:16:53.201+0000] {processor.py:157} INFO - Started process (PID=24947) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:16:53.204+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:16:53.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.204+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:16:53.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:16:53.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.271+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:16:53.286+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.285+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:16:53.288+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.287+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:16:53.288+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.288+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:16:53.289+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.289+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:16:53.291+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.291+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:16:53.291+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:16:53.291+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:16:53.307+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.111 seconds
[2024-06-18T12:17:23.455+0000] {processor.py:157} INFO - Started process (PID=25195) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:17:23.456+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:17:23.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.456+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:17:23.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:17:23.492+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.491+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:17:23.508+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.508+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:17:23.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.511+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:17:23.512+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.512+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:17:23.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.513+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:17:23.514+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.514+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:17:23.515+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:23.515+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:17:23.535+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T12:17:53.701+0000] {processor.py:157} INFO - Started process (PID=25439) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:17:53.703+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:17:53.709+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.706+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:17:53.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:17:53.766+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.766+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:17:53.780+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.780+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:17:53.782+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.782+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:17:53.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.783+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:17:53.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.783+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:17:53.785+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.785+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:17:53.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:17:53.786+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:17:53.803+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.107 seconds
[2024-06-18T12:18:23.961+0000] {processor.py:157} INFO - Started process (PID=25683) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:18:23.963+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:18:23.968+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:23.967+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:18:24.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:18:24.036+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.036+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:18:24.052+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.052+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:18:24.054+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.054+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:18:24.055+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.055+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:18:24.056+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.056+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:18:24.058+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.058+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:18:24.058+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:24.058+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:18:24.074+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.118 seconds
[2024-06-18T12:18:54.198+0000] {processor.py:157} INFO - Started process (PID=25925) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:18:54.200+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:18:54.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.201+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:18:54.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:18:54.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.272+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:18:54.290+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.290+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:18:54.293+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.293+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:18:54.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.294+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:18:54.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.294+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:18:54.296+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.296+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:18:54.297+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:18:54.297+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:18:54.314+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.123 seconds
[2024-06-18T12:19:24.428+0000] {processor.py:157} INFO - Started process (PID=26170) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:19:24.429+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:19:24.430+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.430+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:19:24.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:19:24.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.464+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:19:24.478+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.478+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:19:24.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.481+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:19:24.482+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.482+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:19:24.482+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.482+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:19:24.484+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.484+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:19:24.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:24.485+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:19:24.503+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.079 seconds
[2024-06-18T12:19:54.845+0000] {processor.py:157} INFO - Started process (PID=26414) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:19:54.848+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:19:54.852+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.851+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:19:54.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:19:54.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.908+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:19:54.938+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.938+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:19:54.941+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.941+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:19:54.942+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.942+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:19:54.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.943+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:19:54.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.945+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:19:54.946+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:19:54.946+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:19:54.963+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.125 seconds
[2024-06-18T12:20:25.175+0000] {processor.py:157} INFO - Started process (PID=26659) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:20:25.178+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:20:25.180+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.180+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:20:25.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:20:25.247+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.247+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:20:25.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.264+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:20:25.267+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.267+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:20:25.267+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.267+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:20:25.268+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.268+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:20:25.270+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.270+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:20:25.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:25.271+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:20:25.290+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.132 seconds
[2024-06-18T12:20:55.469+0000] {processor.py:157} INFO - Started process (PID=26903) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:20:55.471+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:20:55.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.472+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:20:55.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:20:55.542+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.541+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:20:55.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.559+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:20:55.561+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.561+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:20:55.562+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.562+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:20:55.563+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.563+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:20:55.565+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.565+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:20:55.565+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:20:55.565+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:20:55.583+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.120 seconds
[2024-06-18T12:21:25.849+0000] {processor.py:157} INFO - Started process (PID=27151) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:21:25.850+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:21:25.851+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.851+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:21:25.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:21:25.891+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.891+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:21:25.921+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.921+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:21:25.924+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.924+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:21:25.925+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.925+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:21:25.926+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.926+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:21:25.928+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.928+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:21:25.929+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:25.929+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:21:25.948+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.104 seconds
[2024-06-18T12:21:56.195+0000] {processor.py:157} INFO - Started process (PID=27395) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:21:56.196+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:21:56.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.197+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:21:56.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:21:56.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.260+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:21:56.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.275+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:21:56.278+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.277+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:21:56.278+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.278+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:21:56.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.279+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:21:56.281+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.281+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:21:56.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:21:56.282+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:21:56.299+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.109 seconds
[2024-06-18T12:22:26.552+0000] {processor.py:157} INFO - Started process (PID=27643) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:22:26.553+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:22:26.554+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.554+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:22:26.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:22:26.631+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.631+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:22:26.663+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.663+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:22:26.665+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.665+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:22:26.666+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.666+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:22:26.667+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.667+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:22:26.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.669+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:22:26.671+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:26.671+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:22:26.695+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.146 seconds
[2024-06-18T12:22:57.014+0000] {processor.py:157} INFO - Started process (PID=27887) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:22:57.016+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:22:57.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.017+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:22:57.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:22:57.079+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.079+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:22:57.092+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.092+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:22:57.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.094+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:22:57.095+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.095+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:22:57.096+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.096+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:22:57.098+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.098+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:22:57.099+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:22:57.099+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:22:57.124+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.114 seconds
[2024-06-18T12:23:27.794+0000] {processor.py:157} INFO - Started process (PID=28131) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:23:27.797+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:23:27.799+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.798+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:23:27.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:23:27.882+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.882+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:23:27.903+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.903+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:23:27.907+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.906+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:23:27.907+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.907+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:23:27.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.908+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:23:27.910+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.910+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:23:27.912+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:27.912+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:23:27.932+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.144 seconds
[2024-06-18T12:23:58.072+0000] {processor.py:157} INFO - Started process (PID=28374) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:23:58.074+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:23:58.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.074+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:23:58.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:23:58.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.125+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:23:58.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.143+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:23:58.146+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.146+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:23:58.147+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.147+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:23:58.148+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.148+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:23:58.150+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.150+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:23:58.151+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:23:58.151+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:23:58.174+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.107 seconds
[2024-06-18T12:24:28.676+0000] {processor.py:157} INFO - Started process (PID=28624) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:24:28.679+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:24:28.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.681+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:24:28.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:24:28.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.741+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:24:28.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.760+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:24:28.764+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.764+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:24:28.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.765+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:24:28.766+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.766+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:24:28.768+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.768+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:24:28.769+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:24:28.769+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:24:28.788+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.122 seconds
[2024-06-18T12:31:02.295+0000] {processor.py:157} INFO - Started process (PID=175) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:31:02.297+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:31:02.298+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.298+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:31:02.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:31:02.340+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.340+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:31:02.356+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.355+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:31:02.358+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.358+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:31:02.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.359+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:31:02.360+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.360+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:31:02.363+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.362+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:31:02.364+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:02.364+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:31:02.395+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.102 seconds
[2024-06-18T12:31:32.865+0000] {processor.py:157} INFO - Started process (PID=414) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:31:32.866+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:31:32.867+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.867+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:31:32.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:31:32.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.908+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:31:32.935+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.935+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:31:32.939+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.938+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:31:32.941+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.941+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:31:32.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.943+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:31:32.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.945+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:31:32.947+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:31:32.947+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:31:32.970+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.107 seconds
[2024-06-18T12:32:03.641+0000] {processor.py:157} INFO - Started process (PID=657) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:32:03.642+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:32:03.647+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.645+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:32:03.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:32:03.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.729+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:32:03.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.765+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:32:03.770+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.770+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:32:03.776+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.776+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:32:03.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.778+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:32:03.784+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.784+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:32:03.788+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:03.787+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:32:03.868+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.230 seconds
[2024-06-18T12:32:34.066+0000] {processor.py:157} INFO - Started process (PID=902) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:32:34.068+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:32:34.069+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.069+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:32:34.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:32:34.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.136+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:32:34.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.201+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:32:34.204+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.204+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:32:34.210+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.210+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:32:34.214+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.214+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:32:34.220+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.220+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:32:34.223+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:32:34.223+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:32:34.252+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.189 seconds
[2024-06-18T12:33:05.012+0000] {processor.py:157} INFO - Started process (PID=1145) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:33:05.013+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:33:05.014+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.014+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:33:05.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:33:05.097+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.097+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:33:05.115+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.115+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:33:05.118+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.117+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:33:05.119+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.119+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:33:05.121+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.121+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:33:05.124+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.124+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:33:05.126+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:05.125+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:33:05.154+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.148 seconds
[2024-06-18T12:33:35.807+0000] {processor.py:157} INFO - Started process (PID=1389) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:33:35.821+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:33:35.837+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:35.831+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:33:35.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:33:36.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.128+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:33:36.194+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.193+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:33:36.214+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.213+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:33:36.219+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.219+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:33:36.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.226+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:33:36.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.238+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:33:36.242+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:33:36.242+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:33:36.323+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.584 seconds
[2024-06-18T12:34:06.743+0000] {processor.py:157} INFO - Started process (PID=1634) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:34:06.753+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:34:06.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:06.762+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:34:06.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:34:07.199+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.199+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:34:07.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.281+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:34:07.298+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.298+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:34:07.304+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.304+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:34:07.313+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.313+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:34:07.326+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.326+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:34:07.334+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:07.331+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:34:07.472+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.769 seconds
[2024-06-18T12:34:37.802+0000] {processor.py:157} INFO - Started process (PID=1878) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:34:37.805+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:34:37.806+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.806+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:34:37.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:34:37.883+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.883+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:34:37.905+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.905+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:34:37.908+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.908+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:34:37.909+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.909+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:34:37.910+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.910+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:34:37.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.916+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:34:37.919+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:34:37.919+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:34:38.047+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.251 seconds
[2024-06-18T12:35:08.197+0000] {processor.py:157} INFO - Started process (PID=2124) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:35:08.198+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:35:08.199+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.198+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:35:08.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:35:08.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.221+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:35:08.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.234+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:35:08.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.236+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:35:08.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.236+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:35:08.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.237+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:35:08.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.238+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:35:08.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:08.239+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:35:08.259+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.063 seconds
[2024-06-18T12:35:38.489+0000] {processor.py:157} INFO - Started process (PID=2366) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:35:38.492+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:35:38.493+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.492+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:35:38.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:35:38.537+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.537+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:35:38.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.559+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:35:38.563+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.563+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:35:38.569+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.568+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:35:38.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.571+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:35:38.575+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.575+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:35:38.577+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:35:38.577+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:35:38.609+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.124 seconds
[2024-06-18T12:36:08.799+0000] {processor.py:157} INFO - Started process (PID=2610) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:36:08.801+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:36:08.802+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.801+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:36:08.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:36:08.861+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.861+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:36:08.877+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.877+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:36:08.880+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.880+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:36:08.881+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.881+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:36:08.882+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.882+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:36:08.884+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.884+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:36:08.886+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:08.886+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:36:08.907+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.113 seconds
[2024-06-18T12:36:39.624+0000] {processor.py:157} INFO - Started process (PID=2854) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:36:39.626+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:36:39.627+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.626+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:36:39.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:36:39.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.678+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:36:39.692+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.692+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:36:39.694+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.694+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:36:39.695+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.695+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:36:39.695+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.695+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:36:39.697+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.697+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:36:39.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:36:39.698+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:36:39.715+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T12:37:10.074+0000] {processor.py:157} INFO - Started process (PID=3097) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:37:10.076+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:37:10.077+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.077+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:37:10.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:37:10.122+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.122+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:37:10.152+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.152+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:37:10.155+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.155+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:37:10.156+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.156+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:37:10.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.157+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:37:10.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.161+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:37:10.163+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:10.163+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:37:10.185+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.113 seconds
[2024-06-18T12:37:40.292+0000] {processor.py:157} INFO - Started process (PID=3341) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:37:40.294+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:37:40.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.295+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:37:40.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:37:40.343+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.343+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:37:40.362+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.362+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:37:40.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.365+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:37:40.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.366+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:37:40.368+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.368+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:37:40.370+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.370+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:37:40.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:37:40.371+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:37:40.395+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.109 seconds
[2024-06-18T12:40:07.840+0000] {processor.py:157} INFO - Started process (PID=177) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:40:07.841+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:40:07.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.842+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:40:07.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:40:07.856+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.856+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:40:07.870+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.870+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:40:07.872+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.872+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:40:07.873+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.873+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:40:07.873+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.873+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:40:07.875+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.875+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:40:07.876+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:07.876+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:40:07.894+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.055 seconds
[2024-06-18T12:40:38.140+0000] {processor.py:157} INFO - Started process (PID=433) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:40:38.142+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:40:38.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.143+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:40:38.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:40:38.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.197+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:40:38.217+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.216+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:40:38.222+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.221+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:40:38.223+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.223+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:40:38.224+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.224+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:40:38.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:40:38.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:40:38.232+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:40:38.258+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.122 seconds
[2024-06-18T12:41:08.698+0000] {processor.py:157} INFO - Started process (PID=680) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:41:08.699+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:41:08.700+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.699+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:41:08.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:41:08.742+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.742+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:41:08.755+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.755+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:41:08.757+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.757+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:41:08.758+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.758+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:41:08.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.759+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:41:08.764+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.764+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:41:08.766+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:08.766+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:41:08.788+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.101 seconds
[2024-06-18T12:41:38.934+0000] {processor.py:157} INFO - Started process (PID=926) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:41:38.936+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:41:38.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.936+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:41:38.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:41:38.978+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.978+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:41:38.993+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.993+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:41:38.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.995+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:41:38.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.996+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:41:38.997+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.997+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:41:38.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.998+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:41:39.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:41:38.999+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:41:39.030+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.104 seconds
[2024-06-18T12:42:09.143+0000] {processor.py:157} INFO - Started process (PID=1170) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:42:09.145+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:42:09.149+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.149+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:42:09.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:42:09.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.253+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:42:09.273+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.273+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:42:09.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.275+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:42:09.276+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.276+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:42:09.277+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.277+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:42:09.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.279+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:42:09.280+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:09.280+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:42:09.299+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.159 seconds
[2024-06-18T12:42:39.828+0000] {processor.py:157} INFO - Started process (PID=1415) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:42:39.833+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:42:39.836+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.835+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:42:39.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:42:39.914+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.914+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:42:39.938+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.938+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:42:39.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.943+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:42:39.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.945+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:42:39.946+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.946+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:42:39.952+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.952+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:42:39.956+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:42:39.955+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:42:39.978+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.157 seconds
[2024-06-18T12:43:10.148+0000] {processor.py:157} INFO - Started process (PID=1658) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:43:10.151+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:43:10.152+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.151+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:43:10.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:43:10.206+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.206+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:43:10.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.235+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:43:10.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.238+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:43:10.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.239+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:43:10.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.240+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:43:10.243+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.243+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:43:10.245+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:10.244+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:43:10.263+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.124 seconds
[2024-06-18T12:43:40.556+0000] {processor.py:157} INFO - Started process (PID=1903) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:43:40.558+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:43:40.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.559+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:43:40.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:43:40.628+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.628+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:43:40.648+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.648+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:43:40.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.650+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:43:40.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.651+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:43:40.652+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.652+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:43:40.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.654+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:43:40.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:43:40.655+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:43:40.671+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.121 seconds
[2024-06-18T12:44:10.835+0000] {processor.py:157} INFO - Started process (PID=2147) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:44:10.840+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:44:10.843+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.842+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:44:10.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:44:10.906+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.905+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:44:10.939+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.938+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:44:10.941+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.941+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:44:10.942+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.942+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:44:10.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.943+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:44:10.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.944+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:44:10.946+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:10.946+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:44:10.968+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.158 seconds
[2024-06-18T12:44:41.380+0000] {processor.py:157} INFO - Started process (PID=2391) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:44:41.382+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:44:41.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.383+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:44:41.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:44:41.433+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.433+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:44:41.463+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.463+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:44:41.465+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.465+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:44:41.466+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.466+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:44:41.467+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.467+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:44:41.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.468+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:44:41.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:44:41.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:44:41.489+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.118 seconds
[2024-06-18T12:45:12.182+0000] {processor.py:157} INFO - Started process (PID=2641) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:45:12.183+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:45:12.183+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:12.183+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:45:12.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:45:12.509+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:12.508+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:45:13.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.243+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:45:13.252+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.252+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:45:13.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.254+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:45:13.256+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.256+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:45:13.261+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.260+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:45:13.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:13.269+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:45:13.396+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 1.217 seconds
[2024-06-18T12:45:43.598+0000] {processor.py:157} INFO - Started process (PID=2888) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:45:43.599+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:45:43.599+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.599+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:45:43.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:45:43.658+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.658+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:45:43.671+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.671+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:45:43.673+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.673+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:45:43.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.674+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:45:43.675+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.675+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:45:43.677+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.677+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:45:43.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:45:43.678+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:45:43.694+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.099 seconds
[2024-06-18T12:46:14.097+0000] {processor.py:157} INFO - Started process (PID=3132) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:46:14.100+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:46:14.106+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.105+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:46:14.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:46:14.224+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.224+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:46:14.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.244+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:46:14.247+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.247+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:46:14.248+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.248+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:46:14.248+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.248+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:46:14.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.251+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:46:14.255+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:14.255+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:46:14.271+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.182 seconds
[2024-06-18T12:46:44.785+0000] {processor.py:157} INFO - Started process (PID=3376) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:46:44.788+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:46:44.790+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.789+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:46:44.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:46:44.867+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.867+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:46:44.887+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.887+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:46:44.890+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.890+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:46:44.891+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.891+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:46:44.893+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.893+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:46:44.895+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.895+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:46:44.898+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:46:44.898+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:46:44.917+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.145 seconds
[2024-06-18T12:47:15.232+0000] {processor.py:157} INFO - Started process (PID=3620) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:47:15.236+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:47:15.238+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.237+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:47:15.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:47:15.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.300+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:47:15.335+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.335+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:47:15.337+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.337+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:47:15.338+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.338+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:47:15.339+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.339+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:47:15.341+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.341+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:47:15.342+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:15.342+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:47:15.358+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.145 seconds
[2024-06-18T12:47:45.419+0000] {processor.py:157} INFO - Started process (PID=3870) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:47:45.420+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:47:45.421+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.421+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:47:45.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:47:45.453+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.453+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:47:45.467+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.467+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:47:45.471+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.471+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:47:45.473+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:47:45.474+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.473+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:47:45.477+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.477+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:47:45.479+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:47:45.478+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:47:45.507+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.091 seconds
[2024-06-18T12:48:15.734+0000] {processor.py:157} INFO - Started process (PID=4119) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:48:15.736+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:48:15.737+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.737+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:48:15.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:48:15.831+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.831+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:48:15.860+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.860+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:48:15.863+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.863+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:48:15.865+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.865+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:48:15.867+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.867+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:48:15.870+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.870+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:48:15.872+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:15.872+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:48:15.922+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.217 seconds
[2024-06-18T12:48:46.040+0000] {processor.py:157} INFO - Started process (PID=4365) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:48:46.041+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:48:46.042+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.042+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:48:46.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:48:46.086+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.085+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:48:46.116+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.116+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:48:46.119+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.119+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:48:46.120+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.120+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:48:46.122+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.121+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:48:46.123+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.123+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:48:46.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:48:46.125+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:48:46.144+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.108 seconds
[2024-06-18T12:49:16.688+0000] {processor.py:157} INFO - Started process (PID=4610) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:49:16.690+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:49:16.690+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.690+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:49:16.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:49:16.753+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.752+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:49:16.767+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.767+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:49:16.769+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.769+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:49:16.770+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.770+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:49:16.771+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.771+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:49:16.773+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.772+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:49:16.774+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:16.774+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:49:16.790+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.106 seconds
[2024-06-18T12:49:47.166+0000] {processor.py:157} INFO - Started process (PID=4854) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:49:47.168+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:49:47.168+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.168+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:49:47.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:49:47.251+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.250+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:49:47.268+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.268+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:49:47.270+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.270+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:49:47.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.271+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:49:47.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.272+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:49:47.274+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.274+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:49:47.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:49:47.275+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:49:47.290+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T12:50:18.413+0000] {processor.py:157} INFO - Started process (PID=5098) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:50:18.417+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T12:50:18.420+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.419+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:50:18.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T12:50:18.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.596+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T12:50:18.629+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.628+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T12:50:18.631+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.631+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T12:50:18.632+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.632+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T12:50:18.632+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.632+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T12:50:18.635+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.635+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T12:50:18.636+0000] {logging_mixin.py:154} INFO - [2024-06-18T12:50:18.636+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T12:50:18.653+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.262 seconds
[2024-06-18T14:00:57.921+0000] {processor.py:157} INFO - Started process (PID=176) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:00:57.923+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:00:57.924+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.924+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:00:57.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:00:57.965+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.965+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:00:57.981+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.981+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:00:57.984+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.984+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:00:57.986+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.986+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:00:57.989+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.988+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:00:57.993+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.993+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:00:57.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:00:57.995+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:00:58.030+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.112 seconds
[2024-06-18T14:01:08.773+0000] {processor.py:157} INFO - Started process (PID=177) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:01:08.774+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:01:08.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.775+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:01:08.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:01:08.811+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.811+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:01:08.834+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.834+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:01:08.837+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.837+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:01:08.838+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.838+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:01:08.839+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.839+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:01:08.841+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.841+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:01:08.843+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:08.843+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:01:08.867+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T14:01:39.368+0000] {processor.py:157} INFO - Started process (PID=421) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:01:39.370+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:01:39.371+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.370+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:01:39.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:01:39.399+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.398+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:01:39.411+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.411+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:01:39.414+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.414+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:01:39.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.415+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:01:39.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.415+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:01:39.417+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.417+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:01:39.418+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:01:39.418+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:01:39.434+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.068 seconds
[2024-06-18T14:02:09.499+0000] {processor.py:157} INFO - Started process (PID=659) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:02:09.500+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:02:09.501+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.500+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:02:09.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:02:09.556+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.556+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:02:09.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.568+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:02:09.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.571+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:02:09.573+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.573+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:02:09.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.574+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:02:09.577+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.577+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:02:09.578+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:09.578+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:02:09.600+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.104 seconds
[2024-06-18T14:02:39.951+0000] {processor.py:157} INFO - Started process (PID=903) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:02:39.952+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:02:39.953+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:39.953+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:02:39.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:02:39.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:39.998+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:02:40.014+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:40.013+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:02:40.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:40.016+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:02:40.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:40.017+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:02:40.017+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:40.017+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:02:40.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:40.019+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:02:40.020+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:02:40.020+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:02:40.036+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.088 seconds
[2024-06-18T14:03:10.406+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:03:10.408+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:03:10.409+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.409+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:03:10.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:03:10.453+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.453+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:03:10.467+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.466+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:03:10.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:03:10.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:03:10.470+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.470+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:03:10.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:03:10.473+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:10.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:03:10.488+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.091 seconds
[2024-06-18T14:03:41.334+0000] {processor.py:157} INFO - Started process (PID=1391) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:03:41.335+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:03:41.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.336+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:03:41.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:03:41.377+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.377+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:03:41.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.391+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:03:41.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.392+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:03:41.393+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.393+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:03:41.394+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.394+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:03:41.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.396+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:03:41.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:03:41.396+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:03:41.412+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.082 seconds
[2024-06-18T14:04:12.389+0000] {processor.py:157} INFO - Started process (PID=1635) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:04:12.390+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:04:12.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.390+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:04:12.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:04:12.429+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.429+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:04:12.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.456+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:04:12.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.459+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:04:12.460+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.460+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:04:12.461+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.461+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:04:12.463+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.463+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:04:12.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:12.464+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:04:12.480+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T14:04:43.201+0000] {processor.py:157} INFO - Started process (PID=1879) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:04:43.206+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:04:43.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.207+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:04:43.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:04:43.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.260+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:04:43.285+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.285+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:04:43.291+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.291+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:04:43.295+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.294+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:04:43.296+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.296+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:04:43.299+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.299+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:04:43.301+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:04:43.301+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:04:43.321+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.139 seconds
[2024-06-18T14:05:13.559+0000] {processor.py:157} INFO - Started process (PID=2123) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:05:13.566+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:05:13.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.566+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:05:13.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:05:13.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.654+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:05:13.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.669+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:05:13.671+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.670+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:05:13.671+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.671+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:05:13.672+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.672+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:05:13.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.674+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:05:13.675+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:13.674+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:05:13.692+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.139 seconds
[2024-06-18T14:05:44.396+0000] {processor.py:157} INFO - Started process (PID=2367) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:05:44.398+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:05:44.399+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.398+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:05:44.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:05:44.446+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.446+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:05:44.466+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.466+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:05:44.468+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.468+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:05:44.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:05:44.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:05:44.471+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.471+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:05:44.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:05:44.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:05:44.488+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.094 seconds
[2024-06-18T14:06:14.819+0000] {processor.py:157} INFO - Started process (PID=2611) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:06:14.821+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:06:14.822+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.822+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:06:14.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:06:14.885+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.885+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:06:14.899+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.899+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:06:14.901+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.901+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:06:14.901+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.901+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:06:14.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.902+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:06:14.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.904+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:06:14.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:14.904+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:06:14.920+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.105 seconds
[2024-06-18T14:06:45.252+0000] {processor.py:157} INFO - Started process (PID=2854) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:06:45.263+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:06:45.265+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.264+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:06:45.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:06:45.340+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.340+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:06:45.357+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.357+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:06:45.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.359+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:06:45.360+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.360+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:06:45.361+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.361+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:06:45.362+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.362+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:06:45.363+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:06:45.363+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:06:45.379+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.136 seconds
[2024-06-18T14:07:15.557+0000] {processor.py:157} INFO - Started process (PID=3099) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:07:15.558+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:07:15.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.559+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:07:15.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:07:15.638+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.638+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:07:15.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.656+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:07:15.659+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.659+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:07:15.661+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.660+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:07:15.662+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.662+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:07:15.664+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.664+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:07:15.664+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:15.664+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:07:15.688+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.138 seconds
[2024-06-18T14:07:45.785+0000] {processor.py:157} INFO - Started process (PID=3345) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:07:45.786+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:07:45.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.786+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:07:45.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:07:45.809+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.809+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:07:45.822+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.821+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:07:45.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.823+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:07:45.824+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.824+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:07:45.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.825+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:07:45.826+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.826+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:07:45.827+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:07:45.827+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:07:45.846+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.063 seconds
[2024-06-18T14:08:15.983+0000] {processor.py:157} INFO - Started process (PID=3586) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:08:15.985+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:08:15.985+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:15.985+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:08:15.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:08:16.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:16.016+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:08:16.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:16.029+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:08:16.033+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:16.033+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:08:16.034+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:16.033+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:08:16.034+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:16.034+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:08:16.036+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:16.036+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:08:16.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:16.037+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:08:16.080+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.101 seconds
[2024-06-18T14:08:46.560+0000] {processor.py:157} INFO - Started process (PID=3830) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:08:46.564+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:08:46.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.568+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:08:46.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:08:46.639+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.639+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:08:46.672+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.672+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:08:46.675+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.674+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:08:46.676+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.676+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:08:46.676+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.676+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:08:46.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.678+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:08:46.679+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:08:46.679+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:08:46.697+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.177 seconds
[2024-06-18T14:09:16.952+0000] {processor.py:157} INFO - Started process (PID=4074) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:09:16.953+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:09:16.954+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:16.954+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:09:16.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:09:17.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:17.007+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:09:17.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:17.021+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:09:17.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:17.023+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:09:17.024+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:17.024+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:09:17.024+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:17.024+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:09:17.026+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:17.026+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:09:17.027+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:17.027+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:09:17.043+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T14:09:47.408+0000] {processor.py:157} INFO - Started process (PID=4318) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:09:47.410+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:09:47.412+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.410+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:09:47.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:09:47.490+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.490+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:09:47.508+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.508+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:09:47.510+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.510+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:09:47.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.511+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:09:47.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.511+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:09:47.514+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.513+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:09:47.515+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:09:47.515+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:09:48.005+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.602 seconds
[2024-06-18T14:10:18.203+0000] {processor.py:157} INFO - Started process (PID=4562) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:10:18.207+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:10:18.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.208+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:10:18.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:10:18.276+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.276+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:10:18.292+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.292+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:10:18.294+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.294+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:10:18.296+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.295+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:10:18.297+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.297+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:10:18.299+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.299+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:10:18.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:18.300+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:10:18.326+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.144 seconds
[2024-06-18T14:10:48.498+0000] {processor.py:157} INFO - Started process (PID=4805) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:10:48.501+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:10:48.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.502+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:10:48.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:10:48.559+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.558+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:10:48.579+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.579+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:10:48.582+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.582+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:10:48.583+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.583+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:10:48.584+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.584+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:10:48.586+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.585+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:10:48.587+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:10:48.587+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:10:48.603+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.125 seconds
[2024-06-18T14:11:18.902+0000] {processor.py:157} INFO - Started process (PID=5049) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:11:18.905+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:11:18.906+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.906+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:11:18.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:11:18.947+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.947+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:11:18.959+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.959+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:11:18.961+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.961+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:11:18.962+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.962+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:11:18.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.963+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:11:18.964+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.964+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:11:18.965+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:18.965+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:11:18.980+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2024-06-18T14:11:49.187+0000] {processor.py:157} INFO - Started process (PID=5293) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:11:49.188+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:11:49.189+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.189+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:11:49.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:11:49.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.229+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:11:49.250+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.250+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:11:49.254+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.253+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:11:49.255+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.255+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:11:49.256+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.256+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:11:49.259+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.259+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:11:49.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:11:49.260+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:11:49.288+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.107 seconds
[2024-06-18T14:12:19.363+0000] {processor.py:157} INFO - Started process (PID=5536) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:12:19.364+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:12:19.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.365+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:12:19.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:12:19.403+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.403+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:12:19.417+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.417+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:12:19.419+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.418+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:12:19.419+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.419+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:12:19.420+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.420+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:12:19.422+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.422+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:12:19.422+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:19.422+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:12:19.438+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.081 seconds
[2024-06-18T14:12:50.187+0000] {processor.py:157} INFO - Started process (PID=5780) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:12:50.188+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:12:50.189+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.189+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:12:50.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:12:50.242+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.241+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:12:50.262+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.262+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:12:50.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.264+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:12:50.265+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.265+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:12:50.266+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.266+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:12:50.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.270+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:12:50.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:12:50.272+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:12:50.293+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.110 seconds
[2024-06-18T14:13:20.419+0000] {processor.py:157} INFO - Started process (PID=6024) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:13:20.421+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:13:20.421+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.421+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:13:20.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:13:20.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.459+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:13:20.473+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.473+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:13:20.475+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.475+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:13:20.476+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.476+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:13:20.477+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.477+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:13:20.478+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.478+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:13:20.479+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:20.479+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:13:20.494+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.078 seconds
[2024-06-18T14:13:50.973+0000] {processor.py:157} INFO - Started process (PID=6268) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:13:50.978+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:13:50.982+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:50.980+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:13:51.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:13:51.041+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:51.041+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:13:51.056+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:51.056+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:13:51.058+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:51.058+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:13:51.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:51.059+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:13:51.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:51.059+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:13:51.061+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:51.061+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:13:51.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:13:51.062+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:13:51.077+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.111 seconds
[2024-06-18T14:14:21.204+0000] {processor.py:157} INFO - Started process (PID=6514) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:14:21.205+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:14:21.206+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.206+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:14:21.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:14:21.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.229+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:14:21.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.240+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:14:21.242+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.242+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:14:21.243+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.243+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:14:21.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.243+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:14:21.245+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.245+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:14:21.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:21.246+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:14:21.261+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.059 seconds
[2024-06-18T14:14:52.166+0000] {processor.py:157} INFO - Started process (PID=6756) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:14:52.167+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:14:52.168+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.168+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:14:52.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:14:52.203+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.203+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:14:52.219+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.219+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:14:52.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.221+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:14:52.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.221+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:14:52.222+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.222+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:14:52.224+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.224+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:14:52.224+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:14:52.224+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:14:52.238+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.075 seconds
[2024-06-18T14:15:22.519+0000] {processor.py:157} INFO - Started process (PID=7000) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:15:22.521+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:15:22.522+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.521+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:15:22.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:15:22.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.574+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:15:22.587+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.587+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:15:22.589+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.589+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:15:22.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.590+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:15:22.591+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.591+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:15:22.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.592+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:15:22.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:22.594+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:15:22.609+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.094 seconds
[2024-06-18T14:15:53.167+0000] {processor.py:157} INFO - Started process (PID=7244) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:15:53.169+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:15:53.170+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.170+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:15:53.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:15:53.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.207+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:15:53.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.226+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:15:53.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:15:53.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:15:53.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:15:53.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.232+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:15:53.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:15:53.232+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:15:53.248+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T14:16:23.765+0000] {processor.py:157} INFO - Started process (PID=7487) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:16:23.767+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:16:23.768+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.768+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:16:23.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:16:23.817+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.817+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:16:23.829+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.829+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:16:23.831+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.831+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:16:23.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.832+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:16:23.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.832+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:16:23.834+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.834+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:16:23.835+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:23.835+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:16:23.850+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.089 seconds
[2024-06-18T14:16:54.071+0000] {processor.py:157} INFO - Started process (PID=7731) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:16:54.072+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:16:54.073+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.073+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:16:54.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:16:54.118+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.118+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:16:54.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.130+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:16:54.132+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.132+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:16:54.132+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.132+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:16:54.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.133+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:16:54.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.134+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:16:54.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:16:54.135+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:16:54.157+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.092 seconds
[2024-06-18T14:17:24.489+0000] {processor.py:157} INFO - Started process (PID=7975) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:17:24.492+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:17:24.493+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.493+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:17:24.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:17:24.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.530+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:17:24.545+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.545+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:17:24.547+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.547+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:17:24.548+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.548+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:17:24.549+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.549+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:17:24.552+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.552+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:17:24.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:24.553+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:17:24.573+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T14:17:55.404+0000] {processor.py:157} INFO - Started process (PID=8218) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:17:55.406+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:17:55.406+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.406+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:17:55.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:17:55.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.469+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:17:55.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:17:55.489+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.489+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:17:55.491+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.490+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:17:55.491+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.491+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:17:55.493+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.493+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:17:55.495+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:17:55.495+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:17:55.513+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.112 seconds
[2024-06-18T14:18:25.891+0000] {processor.py:157} INFO - Started process (PID=8461) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:18:25.901+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:18:25.910+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:25.907+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:18:25.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:18:26.190+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:26.190+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:18:26.257+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:26.257+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:18:26.265+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:26.264+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:18:26.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:26.269+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:18:26.272+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:26.271+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:18:26.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:26.274+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:18:26.278+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:26.278+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:18:26.323+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.440 seconds
[2024-06-18T14:18:57.135+0000] {processor.py:157} INFO - Started process (PID=8705) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:18:57.138+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:18:57.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.139+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:18:57.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:18:57.195+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.195+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:18:57.218+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.218+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:18:57.223+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.223+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:18:57.225+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.224+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:18:57.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.226+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:18:57.228+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.228+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:18:57.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:18:57.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:18:57.466+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.345 seconds
[2024-06-18T14:19:28.016+0000] {processor.py:157} INFO - Started process (PID=8949) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:19:28.018+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:19:28.019+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.019+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:19:28.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:19:28.074+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.074+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:19:28.089+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.089+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:19:28.091+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.091+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:19:28.092+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.092+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:19:28.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.094+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:19:28.097+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.097+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:19:28.101+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:28.101+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:19:28.306+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.309 seconds
[2024-06-18T14:19:58.422+0000] {processor.py:157} INFO - Started process (PID=9202) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:19:58.423+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:19:58.423+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.423+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:19:58.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:19:58.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.456+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:19:58.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.469+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:19:58.471+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.471+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:19:58.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:19:58.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.472+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:19:58.474+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.474+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:19:58.475+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:19:58.475+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:19:58.492+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.072 seconds
[2024-06-18T14:20:28.695+0000] {processor.py:157} INFO - Started process (PID=9436) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:20:28.697+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:20:28.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.698+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:20:28.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:20:28.735+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.735+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:20:28.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.748+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:20:28.750+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.750+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:20:28.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.751+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:20:28.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.751+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:20:28.753+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.753+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:20:28.754+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:28.753+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:20:28.768+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.080 seconds
[2024-06-18T14:20:59.687+0000] {processor.py:157} INFO - Started process (PID=9680) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:20:59.688+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:20:59.689+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.689+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:20:59.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:20:59.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.761+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:20:59.778+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.777+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:20:59.780+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.780+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:20:59.781+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.780+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:20:59.781+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.781+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:20:59.784+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.783+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:20:59.785+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:20:59.785+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:20:59.803+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.120 seconds
[2024-06-18T14:21:30.044+0000] {processor.py:157} INFO - Started process (PID=9924) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:21:30.046+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:21:30.047+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.046+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:21:30.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:21:30.114+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.114+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:21:30.307+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.307+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:21:30.309+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.308+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:21:30.309+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.309+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:21:30.310+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.310+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:21:30.312+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.312+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:21:30.312+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:21:30.312+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:21:30.328+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.290 seconds
[2024-06-18T14:22:00.950+0000] {processor.py:157} INFO - Started process (PID=10168) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:22:00.953+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T14:22:00.954+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:00.954+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:22:00.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T14:22:00.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:00.995+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T14:22:01.027+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:01.027+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T14:22:01.029+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:01.029+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T14:22:01.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:01.030+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T14:22:01.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:01.030+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T14:22:01.033+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:01.032+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T14:22:01.034+0000] {logging_mixin.py:154} INFO - [2024-06-18T14:22:01.034+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T14:22:01.232+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.301 seconds
[2024-06-18T15:06:41.710+0000] {processor.py:157} INFO - Started process (PID=10460) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:06:41.711+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:06:41.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.712+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:06:41.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:06:41.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.748+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:06:41.923+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.923+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:06:41.927+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.926+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:06:41.931+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.931+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:06:41.932+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.932+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:06:41.934+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.934+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:06:41.935+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:41.935+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:06:41.957+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.251 seconds
[2024-06-18T15:06:49.554+0000] {processor.py:157} INFO - Started process (PID=177) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:06:49.556+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:06:49.558+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.558+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:06:49.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:06:49.589+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.588+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:06:49.601+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.601+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:06:49.602+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.602+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:06:49.603+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.603+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:06:49.604+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.604+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:06:49.606+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.606+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:06:49.607+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:06:49.607+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:06:49.622+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.071 seconds
[2024-06-18T15:07:20.248+0000] {processor.py:157} INFO - Started process (PID=421) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:07:20.249+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:07:20.250+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.250+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:07:20.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:07:20.284+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.284+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:07:20.300+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.300+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:07:20.302+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.302+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:07:20.303+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.303+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:07:20.304+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.303+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:07:20.305+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.305+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:07:20.306+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:20.306+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:07:20.322+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.076 seconds
[2024-06-18T15:07:50.505+0000] {processor.py:157} INFO - Started process (PID=659) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:07:50.508+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:07:50.512+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.509+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:07:50.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:07:50.557+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.557+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:07:50.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.571+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:07:50.573+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.573+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:07:50.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.574+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:07:50.575+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.575+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:07:50.577+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.577+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:07:50.578+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:07:50.578+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:07:50.593+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.097 seconds
[2024-06-18T15:08:20.683+0000] {processor.py:157} INFO - Started process (PID=903) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:08:20.685+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:08:20.687+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.686+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:08:20.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:08:20.772+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.771+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:08:20.800+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.800+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:08:20.805+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.805+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:08:20.806+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.806+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:08:20.807+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.807+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:08:20.811+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.811+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:08:20.814+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:20.814+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:08:20.850+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.177 seconds
[2024-06-18T15:08:50.999+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:08:51.000+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:08:51.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.000+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:08:51.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:08:51.051+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.051+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:08:51.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.066+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:08:51.068+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.068+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:08:51.069+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.069+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:08:51.072+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.072+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:08:51.074+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.074+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:08:51.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:08:51.075+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:08:51.092+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.096 seconds
[2024-06-18T15:09:21.617+0000] {processor.py:157} INFO - Started process (PID=1391) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:09:21.618+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:09:21.619+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.619+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:09:21.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:09:21.667+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.666+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:09:21.691+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.691+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:09:21.695+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.695+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:09:21.696+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.696+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:09:21.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.699+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:09:21.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.702+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:09:21.703+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:21.703+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:09:21.728+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.114 seconds
[2024-06-18T15:09:52.418+0000] {processor.py:157} INFO - Started process (PID=1635) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:09:52.420+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:09:52.421+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.421+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:09:52.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:09:52.499+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.498+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:09:52.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.513+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:09:52.515+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.515+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:09:52.516+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.516+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:09:52.518+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.518+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:09:52.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.520+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:09:52.521+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:09:52.521+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:09:52.546+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.132 seconds
[2024-06-18T15:10:22.950+0000] {processor.py:157} INFO - Started process (PID=1879) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:10:22.951+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:10:22.952+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:22.952+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:10:22.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:10:22.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:22.995+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:10:23.011+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.010+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:10:23.014+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.014+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:10:23.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.016+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:10:23.018+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.018+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:10:23.020+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.020+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:10:23.021+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:23.021+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:10:23.039+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.091 seconds
[2024-06-18T15:10:53.151+0000] {processor.py:157} INFO - Started process (PID=2123) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:10:53.152+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:10:53.152+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.152+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:10:53.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:10:53.187+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.187+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:10:53.201+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.201+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:10:53.204+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.204+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:10:53.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.205+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:10:53.206+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.206+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:10:53.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.207+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:10:53.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:10:53.208+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:10:53.228+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.080 seconds
[2024-06-18T15:11:23.727+0000] {processor.py:157} INFO - Started process (PID=2367) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:11:23.728+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:11:23.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.729+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:11:23.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:11:23.776+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.776+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:11:23.791+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.791+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:11:23.793+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.793+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:11:23.794+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.794+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:11:23.795+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.795+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:11:23.797+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.796+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:11:23.798+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:23.798+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:11:23.822+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.097 seconds
[2024-06-18T15:11:54.202+0000] {processor.py:157} INFO - Started process (PID=2611) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:11:54.205+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:11:54.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.206+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:11:54.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:11:54.245+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.245+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:11:54.258+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.258+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:11:54.261+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.261+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:11:54.261+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.261+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:11:54.262+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.262+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:11:54.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.264+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:11:54.265+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:11:54.264+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:11:54.281+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.093 seconds
[2024-06-18T15:12:24.565+0000] {processor.py:157} INFO - Started process (PID=2855) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:12:24.566+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:12:24.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.567+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:12:24.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:12:24.606+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.606+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:12:24.618+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.618+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:12:24.620+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.620+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:12:24.621+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.620+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:12:24.621+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.621+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:12:24.623+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.623+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:12:24.624+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:24.624+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:12:24.640+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.079 seconds
[2024-06-18T15:12:54.892+0000] {processor.py:157} INFO - Started process (PID=3099) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:12:54.894+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:12:54.895+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:54.895+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:12:54.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:12:54.988+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:54.987+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:12:54.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:54.998+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:12:55.000+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.000+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:12:55.001+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.001+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:12:55.001+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.001+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:12:55.003+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.003+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:12:55.004+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:12:55.004+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:12:55.021+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.131 seconds
[2024-06-18T15:13:25.134+0000] {processor.py:157} INFO - Started process (PID=3343) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:13:25.135+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:13:25.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.135+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:13:25.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:13:25.170+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.169+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:13:25.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.182+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:13:25.184+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.184+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:13:25.185+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.185+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:13:25.186+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.186+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:13:25.188+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.188+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:13:25.190+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:25.190+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:13:25.213+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.081 seconds
[2024-06-18T15:13:55.659+0000] {processor.py:157} INFO - Started process (PID=3587) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:13:55.660+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:13:55.661+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.660+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:13:55.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:13:55.701+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.701+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:13:55.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.718+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:13:55.721+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.721+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:13:55.724+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.724+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:13:55.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.725+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:13:55.726+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.726+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:13:55.727+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:13:55.727+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:13:55.742+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.087 seconds
[2024-06-18T15:14:25.981+0000] {processor.py:157} INFO - Started process (PID=3830) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:14:25.983+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:14:25.984+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:25.984+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:14:25.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:14:26.023+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.023+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:14:26.035+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.035+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:14:26.037+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.037+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:14:26.038+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.038+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:14:26.039+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.039+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:14:26.040+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.040+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:14:26.041+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:26.041+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:14:26.056+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.078 seconds
[2024-06-18T15:14:56.296+0000] {processor.py:157} INFO - Started process (PID=4074) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:14:56.297+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:14:56.298+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.298+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:14:56.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:14:56.358+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.358+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:14:56.377+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.377+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:14:56.381+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.380+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:14:56.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.381+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:14:56.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.382+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:14:56.385+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.385+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:14:56.387+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:14:56.386+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:14:56.405+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.113 seconds
[2024-06-18T15:15:26.713+0000] {processor.py:157} INFO - Started process (PID=4318) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:15:26.714+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:15:26.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.715+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:15:26.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:15:26.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.761+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:15:26.776+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.776+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:15:26.779+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.779+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:15:26.780+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.780+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:15:26.781+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.781+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:15:26.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.782+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:15:26.784+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:26.784+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:15:26.802+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.092 seconds
[2024-06-18T15:15:56.900+0000] {processor.py:157} INFO - Started process (PID=4562) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:15:56.901+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:15:56.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.902+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:15:56.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:15:56.937+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.937+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:15:56.957+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.957+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:15:56.962+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.962+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:15:56.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.963+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:15:56.965+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.965+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:15:56.969+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.969+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:15:56.970+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:15:56.970+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:15:56.989+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.091 seconds
[2024-06-18T15:16:27.257+0000] {processor.py:157} INFO - Started process (PID=4806) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:16:27.259+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:16:27.261+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.260+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:16:27.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:16:27.303+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.303+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:16:27.315+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.315+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:16:27.317+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.317+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:16:27.318+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.318+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:16:27.318+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.318+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:16:27.320+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.320+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:16:27.321+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:27.321+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:16:27.336+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T15:16:58.121+0000] {processor.py:157} INFO - Started process (PID=5050) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:16:58.123+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:16:58.124+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.124+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:16:58.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:16:58.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.159+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:16:58.174+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.174+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:16:58.176+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.176+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:16:58.176+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.176+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:16:58.177+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.177+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:16:58.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.179+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:16:58.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:16:58.179+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:16:58.193+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.075 seconds
[2024-06-18T15:17:28.494+0000] {processor.py:157} INFO - Started process (PID=5293) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:17:28.496+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:17:28.497+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.497+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:17:28.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:17:28.529+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.529+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:17:28.541+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.541+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:17:28.542+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.542+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:17:28.543+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.543+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:17:28.544+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.544+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:17:28.545+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.545+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:17:28.546+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:28.546+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:17:28.562+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.070 seconds
[2024-06-18T15:17:59.106+0000] {processor.py:157} INFO - Started process (PID=5537) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:17:59.107+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:17:59.107+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.107+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:17:59.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:17:59.184+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.183+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:17:59.202+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.201+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:17:59.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.205+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:17:59.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.207+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:17:59.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.209+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:17:59.212+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.212+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:17:59.213+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:17:59.213+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:17:59.241+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.138 seconds
[2024-06-18T15:18:29.556+0000] {processor.py:157} INFO - Started process (PID=5781) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:18:29.557+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:18:29.558+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.557+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:18:29.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:18:29.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.593+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:18:29.606+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.606+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:18:29.608+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.607+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:18:29.608+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.608+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:18:29.609+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.609+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:18:29.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.611+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:18:29.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:29.611+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:18:29.628+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.074 seconds
[2024-06-18T15:18:59.804+0000] {processor.py:157} INFO - Started process (PID=6025) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:18:59.805+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:18:59.805+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.805+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:18:59.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:18:59.846+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.845+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:18:59.857+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.857+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:18:59.860+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.860+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:18:59.861+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.860+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:18:59.861+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.861+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:18:59.863+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.863+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:18:59.864+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:18:59.864+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:18:59.882+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.081 seconds
[2024-06-18T15:19:30.603+0000] {processor.py:157} INFO - Started process (PID=6267) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:19:30.605+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:19:30.605+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.605+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:19:30.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:19:30.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.654+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:19:30.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.669+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:19:30.673+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.673+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:19:30.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.674+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:19:30.675+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.675+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:19:30.677+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.677+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:19:30.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:19:30.678+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:19:30.705+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.106 seconds
[2024-06-18T15:20:00.836+0000] {processor.py:157} INFO - Started process (PID=6513) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:20:00.838+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:20:00.839+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.838+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:20:00.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:20:00.880+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.879+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:20:00.894+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.894+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:20:00.897+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.897+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:20:00.898+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.898+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:20:00.899+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.899+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:20:00.901+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.901+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:20:00.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:00.902+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:20:00.923+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T15:20:31.317+0000] {processor.py:157} INFO - Started process (PID=6757) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:20:31.318+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:20:31.319+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.319+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:20:31.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:20:31.360+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.360+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:20:31.372+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.372+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:20:31.374+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.374+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:20:31.375+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.375+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:20:31.375+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.375+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:20:31.377+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.377+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:20:31.378+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:20:31.378+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:20:31.394+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.080 seconds
[2024-06-18T15:21:01.773+0000] {processor.py:157} INFO - Started process (PID=7001) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:21:01.774+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:21:01.776+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.775+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:21:01.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:21:01.812+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.812+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:21:01.823+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.823+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:21:01.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.824+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:21:01.825+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.825+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:21:01.826+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.826+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:21:01.827+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.827+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:21:01.828+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:01.828+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:21:01.842+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.074 seconds
[2024-06-18T15:21:32.232+0000] {processor.py:157} INFO - Started process (PID=7245) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:21:32.233+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:21:32.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.233+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:21:32.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:21:32.260+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.260+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:21:32.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.271+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:21:32.273+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.273+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:21:32.274+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.274+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:21:32.274+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.274+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:21:32.276+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.276+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:21:32.277+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:21:32.277+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:21:32.291+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.060 seconds
[2024-06-18T15:22:02.908+0000] {processor.py:157} INFO - Started process (PID=7489) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:22:02.910+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:22:02.911+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.910+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:22:02.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:22:02.944+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.944+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:22:02.958+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.958+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:22:02.960+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.960+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:22:02.961+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.961+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:22:02.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.962+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:22:02.965+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.964+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:22:02.966+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:02.966+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:22:02.990+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2024-06-18T15:22:33.096+0000] {processor.py:157} INFO - Started process (PID=7733) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:22:33.097+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:22:33.098+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.098+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:22:33.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:22:33.148+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.148+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:22:33.160+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.159+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:22:33.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.161+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:22:33.162+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.162+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:22:33.163+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.163+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:22:33.164+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.164+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:22:33.165+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:22:33.165+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:22:33.181+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.088 seconds
[2024-06-18T15:23:03.514+0000] {processor.py:157} INFO - Started process (PID=7977) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:23:03.516+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:23:03.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.517+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:23:03.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:23:03.648+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.648+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:23:03.662+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.662+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:23:03.667+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.666+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:23:03.668+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.668+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:23:03.671+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.671+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:23:03.674+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.674+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:23:03.675+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:03.675+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:23:03.900+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.389 seconds
[2024-06-18T15:23:34.028+0000] {processor.py:157} INFO - Started process (PID=8243) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:23:34.029+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:23:34.029+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.029+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:23:34.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:23:34.070+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.070+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:23:34.093+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.093+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:23:34.098+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.098+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:23:34.100+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.100+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:23:34.103+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.103+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:23:34.106+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.106+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:23:34.107+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:23:34.107+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:23:34.132+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.106 seconds
[2024-06-18T15:24:04.331+0000] {processor.py:157} INFO - Started process (PID=8492) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:24:04.332+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:24:04.333+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.332+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:24:04.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:24:04.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.353+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:24:04.364+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.364+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:24:04.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.365+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:24:04.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.366+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:24:04.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.366+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:24:04.368+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.368+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:24:04.368+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:04.368+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:24:04.381+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.052 seconds
[2024-06-18T15:24:34.735+0000] {processor.py:157} INFO - Started process (PID=8709) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:24:34.739+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:24:34.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.740+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:24:34.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:24:34.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.774+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:24:34.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.786+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:24:34.788+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.788+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:24:34.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.789+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:24:34.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.789+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:24:34.791+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.791+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:24:34.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:24:34.792+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:24:34.809+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.077 seconds
[2024-06-18T15:25:05.148+0000] {processor.py:157} INFO - Started process (PID=8953) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:25:05.149+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:25:05.149+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.149+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:25:05.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:25:05.182+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.182+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:25:05.194+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.194+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:25:05.196+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.196+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:25:05.196+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.196+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:25:05.197+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.197+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:25:05.198+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.198+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:25:05.199+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:05.199+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:25:05.215+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.070 seconds
[2024-06-18T15:25:35.505+0000] {processor.py:157} INFO - Started process (PID=9197) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:25:35.509+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:25:35.510+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.510+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:25:35.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:25:35.547+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.547+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:25:35.576+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.576+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:25:35.581+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.581+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:25:35.583+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.583+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:25:35.584+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.584+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:25:35.587+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.587+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:25:35.589+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:25:35.589+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:25:35.616+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.114 seconds
[2024-06-18T15:26:05.712+0000] {processor.py:157} INFO - Started process (PID=9441) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:26:05.715+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:26:05.716+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.715+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:26:05.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:26:05.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.747+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:26:05.758+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.758+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:26:05.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.760+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:26:05.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:26:05.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:26:05.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.763+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:26:05.764+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:05.764+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:26:05.779+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.069 seconds
[2024-06-18T15:26:36.617+0000] {processor.py:157} INFO - Started process (PID=9685) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:26:36.618+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:26:36.618+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.618+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:26:36.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:26:36.670+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.670+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:26:36.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.686+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:26:36.971+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.971+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:26:36.973+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.973+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:26:36.974+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.974+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:26:36.976+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.976+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:26:36.977+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:26:36.977+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:26:36.996+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.382 seconds
[2024-06-18T15:27:07.429+0000] {processor.py:157} INFO - Started process (PID=9929) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:27:07.430+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:27:07.431+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.431+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:27:07.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:27:07.474+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.474+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:27:07.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:27:07.489+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.489+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:27:07.490+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.490+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:27:07.490+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.490+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:27:07.492+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.492+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:27:07.493+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:07.493+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:27:07.707+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.279 seconds
[2024-06-18T15:27:38.513+0000] {processor.py:157} INFO - Started process (PID=10173) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:27:38.514+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:27:38.514+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.514+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:27:38.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:27:38.570+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.569+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:27:38.587+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.587+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:27:38.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.590+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:27:38.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.593+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:27:38.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.596+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:27:38.599+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.599+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:27:38.600+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:27:38.600+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:27:38.615+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.106 seconds
[2024-06-18T15:28:09.237+0000] {processor.py:157} INFO - Started process (PID=10417) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:28:09.241+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:28:09.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.242+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:28:09.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:28:09.288+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.287+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:28:09.478+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.478+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:28:09.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:28:09.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.480+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:28:09.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.481+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:28:09.482+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.482+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:28:09.483+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:09.483+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:28:09.497+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.262 seconds
[2024-06-18T15:28:40.135+0000] {processor.py:157} INFO - Started process (PID=10661) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:28:40.137+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:28:40.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.140+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:28:40.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:28:40.183+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.183+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:28:40.199+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.199+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:28:40.397+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.397+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:28:40.398+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.398+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:28:40.399+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.399+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:28:40.400+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.400+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:28:40.401+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:28:40.401+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:28:40.417+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.285 seconds
[2024-06-18T15:29:10.590+0000] {processor.py:157} INFO - Started process (PID=10905) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:29:10.591+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:29:10.592+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.592+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:29:10.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:29:10.622+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.622+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:29:10.649+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.649+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:29:10.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.651+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:29:10.652+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.652+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:29:10.653+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.653+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:29:10.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.654+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:29:10.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:10.655+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:29:10.681+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.092 seconds
[2024-06-18T15:29:41.565+0000] {processor.py:157} INFO - Started process (PID=11149) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:29:41.567+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:29:41.571+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.570+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:29:41.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:29:41.633+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.633+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:29:41.647+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.647+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:29:41.649+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.649+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:29:41.650+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.650+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:29:41.651+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.651+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:29:41.653+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.652+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:29:41.653+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:29:41.653+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:29:41.673+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.135 seconds
[2024-06-18T15:30:12.349+0000] {processor.py:157} INFO - Started process (PID=11393) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:30:12.350+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:30:12.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.351+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:30:12.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:30:12.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.388+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:30:12.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.587+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:30:12.589+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.589+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:30:12.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.590+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:30:12.591+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.591+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:30:12.592+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.592+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:30:12.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:12.593+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:30:12.607+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.262 seconds
[2024-06-18T15:30:43.639+0000] {processor.py:157} INFO - Started process (PID=11637) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:30:43.641+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:30:43.642+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.642+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:30:43.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:30:43.681+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.681+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:30:43.695+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.694+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:30:43.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.698+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:30:43.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.698+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:30:43.699+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.699+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:30:43.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.702+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:30:43.703+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:30:43.703+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:30:43.720+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.092 seconds
[2024-06-18T15:31:14.700+0000] {processor.py:157} INFO - Started process (PID=11881) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:31:14.702+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:31:14.703+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.702+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:31:14.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:31:14.749+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.749+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:31:14.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.760+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:31:14.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.762+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:31:14.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.763+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:31:14.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.763+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:31:14.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.765+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:31:14.766+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:14.766+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:31:14.781+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.083 seconds
[2024-06-18T15:31:44.927+0000] {processor.py:157} INFO - Started process (PID=12125) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:31:44.934+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:31:44.938+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:44.937+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:31:44.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:31:44.986+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:44.986+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:31:44.999+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:44.999+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:31:45.001+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.001+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:31:45.001+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.001+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:31:45.002+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.002+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:31:45.004+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.004+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:31:45.005+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:31:45.005+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:31:45.022+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.100 seconds
[2024-06-18T15:32:15.138+0000] {processor.py:157} INFO - Started process (PID=12369) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:32:15.141+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:32:15.142+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.141+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:32:15.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:32:15.192+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.192+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:32:15.204+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.204+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:32:15.206+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.206+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:32:15.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.207+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:32:15.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.208+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:32:15.209+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.209+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:32:15.210+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:15.210+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:32:15.226+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T15:32:45.349+0000] {processor.py:157} INFO - Started process (PID=12612) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:32:45.350+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:32:45.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.351+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:32:45.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:32:45.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.388+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:32:45.404+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.404+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:32:45.406+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.406+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:32:45.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.407+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:32:45.408+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.408+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:32:45.410+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.410+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:32:45.411+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:32:45.411+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:32:45.431+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T15:33:15.518+0000] {processor.py:157} INFO - Started process (PID=12853) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:33:15.520+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:33:15.521+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.521+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:33:15.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:33:15.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.553+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:33:15.565+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.565+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:33:15.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.567+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:33:15.567+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.567+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:33:15.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.568+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:33:15.570+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.569+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:33:15.570+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:15.570+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:33:15.585+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.072 seconds
[2024-06-18T15:33:45.869+0000] {processor.py:157} INFO - Started process (PID=13099) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:33:45.871+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:33:45.873+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.872+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:33:45.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:33:45.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.944+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:33:45.960+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.960+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:33:45.963+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.963+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:33:45.964+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.964+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:33:45.964+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.964+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:33:45.966+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.966+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:33:45.967+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:33:45.967+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:33:45.989+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.124 seconds
[2024-06-18T15:34:16.456+0000] {processor.py:157} INFO - Started process (PID=13343) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:34:16.458+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:34:16.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.459+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:34:16.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:34:16.499+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.499+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:34:16.514+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.514+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:34:16.516+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.516+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:34:16.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.517+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:34:16.518+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.518+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:34:16.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.520+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:34:16.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:16.520+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:34:16.536+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.086 seconds
[2024-06-18T15:34:46.734+0000] {processor.py:157} INFO - Started process (PID=13587) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:34:46.735+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:34:46.736+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.735+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:34:46.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:34:46.773+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.773+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:34:46.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.789+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:34:46.791+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.791+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:34:46.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.792+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:34:46.793+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.793+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:34:46.795+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.795+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:34:46.796+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:34:46.796+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:34:46.814+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.082 seconds
[2024-06-18T15:35:17.283+0000] {processor.py:157} INFO - Started process (PID=13831) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:35:17.284+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:35:17.285+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.285+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:35:17.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:35:17.323+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.323+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:35:17.340+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.340+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:35:17.343+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.343+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:35:17.344+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.344+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:35:17.345+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.345+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:35:17.348+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.348+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:35:17.348+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:17.348+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:35:17.395+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.114 seconds
[2024-06-18T15:35:47.661+0000] {processor.py:157} INFO - Started process (PID=14075) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:35:47.666+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:35:47.667+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.667+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:35:47.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:35:47.721+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.721+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:35:47.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.741+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:35:47.745+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.744+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:35:47.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.747+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:35:47.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.748+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:35:47.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.750+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:35:47.754+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:35:47.754+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:35:47.787+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.132 seconds
[2024-06-18T15:36:17.865+0000] {processor.py:157} INFO - Started process (PID=14318) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:36:17.866+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:36:17.867+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.867+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:36:17.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:36:17.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.904+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:36:17.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.920+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:36:17.922+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.922+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:36:17.925+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.925+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:36:17.926+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.926+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:36:17.928+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.928+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:36:17.929+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:17.929+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:36:17.950+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.087 seconds
[2024-06-18T15:36:48.047+0000] {processor.py:157} INFO - Started process (PID=14562) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:36:48.050+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:36:48.050+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.050+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:36:48.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:36:48.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.141+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:36:48.155+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.155+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:36:48.158+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.158+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:36:48.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.159+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:36:48.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.159+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:36:48.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.161+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:36:48.162+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:36:48.161+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:36:48.179+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.133 seconds
[2024-06-18T15:37:18.345+0000] {processor.py:157} INFO - Started process (PID=14806) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:37:18.347+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:37:18.348+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.348+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:37:18.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:37:18.386+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.386+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:37:18.401+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.401+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:37:18.404+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.404+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:37:18.406+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.406+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:37:18.407+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.407+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:37:18.411+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.410+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:37:18.412+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:18.412+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:37:18.430+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.088 seconds
[2024-06-18T15:37:48.621+0000] {processor.py:157} INFO - Started process (PID=15050) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:37:48.624+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:37:48.629+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.629+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:37:48.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:37:48.684+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.684+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:37:48.707+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.707+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:37:48.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.710+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:37:48.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.711+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:37:48.712+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.712+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:37:48.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.715+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:37:48.716+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:37:48.716+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:37:48.751+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.132 seconds
[2024-06-18T15:38:19.330+0000] {processor.py:157} INFO - Started process (PID=15294) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:38:19.332+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:38:19.333+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.332+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:38:19.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:38:19.375+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.375+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:38:19.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.388+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:38:19.390+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.390+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:38:19.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.391+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:38:19.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.392+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:38:19.393+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.393+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:38:19.394+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:19.394+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:38:19.409+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.082 seconds
[2024-06-18T15:38:50.288+0000] {processor.py:157} INFO - Started process (PID=15538) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:38:50.289+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:38:50.291+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.290+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:38:50.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:38:50.340+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.340+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:38:50.370+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.370+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:38:50.383+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.383+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:38:50.387+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.386+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:38:50.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.387+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:38:50.390+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.390+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:38:50.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:38:50.392+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:38:50.415+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.131 seconds
[2024-06-18T15:39:20.560+0000] {processor.py:157} INFO - Started process (PID=15781) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:39:20.561+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:39:20.562+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.562+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:39:20.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:39:20.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.596+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:39:20.608+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.608+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:39:20.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.609+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:39:20.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.610+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:39:20.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.611+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:39:20.613+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.613+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:39:20.614+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:20.614+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:39:20.629+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.073 seconds
[2024-06-18T15:39:50.674+0000] {processor.py:157} INFO - Started process (PID=16025) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:39:50.677+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:39:50.678+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.678+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:39:50.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:39:50.715+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.715+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:39:50.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.729+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:39:50.731+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.731+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:39:50.734+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.734+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:39:50.734+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.734+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:39:50.736+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.736+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:39:50.738+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:39:50.738+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:39:50.754+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.083 seconds
[2024-06-18T15:40:20.885+0000] {processor.py:157} INFO - Started process (PID=16268) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:40:20.887+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:40:20.888+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.888+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:40:20.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:40:20.927+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.926+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:40:20.940+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.939+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:40:20.941+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.941+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:40:20.942+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.942+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:40:20.943+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.943+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:40:20.944+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.944+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:40:20.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:20.945+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:40:20.961+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.081 seconds
[2024-06-18T15:40:51.028+0000] {processor.py:157} INFO - Started process (PID=16512) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:40:51.030+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:40:51.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.030+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:40:51.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:40:51.075+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.075+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:40:51.091+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.090+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:40:51.093+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.093+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:40:51.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.094+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:40:51.095+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.095+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:40:51.097+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.097+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:40:51.098+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:40:51.098+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:40:51.118+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.092 seconds
[2024-06-18T15:41:21.526+0000] {processor.py:157} INFO - Started process (PID=16763) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:41:21.526+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:41:21.527+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.527+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:41:21.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:41:21.561+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.561+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:41:21.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.574+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:41:21.576+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.576+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:41:21.577+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.577+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:41:21.578+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.578+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:41:21.579+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.579+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:41:21.581+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:21.581+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:41:21.598+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.076 seconds
[2024-06-18T15:41:51.654+0000] {processor.py:157} INFO - Started process (PID=17007) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:41:51.656+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:41:51.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.656+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:41:51.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:41:51.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.683+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:41:51.695+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.695+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:41:51.697+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.697+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:41:51.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.697+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:41:51.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.698+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:41:51.700+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.700+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:41:51.701+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:41:51.701+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:41:51.715+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.064 seconds
[2024-06-18T15:42:22.552+0000] {processor.py:157} INFO - Started process (PID=17245) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:42:22.553+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:42:22.553+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.553+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:42:22.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:42:22.578+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.578+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:42:22.591+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.591+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:42:22.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.593+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:42:22.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.594+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:42:22.594+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.594+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:42:22.596+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.596+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:42:22.597+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:22.597+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:42:22.621+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.071 seconds
[2024-06-18T15:42:52.692+0000] {processor.py:157} INFO - Started process (PID=17485) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:42:52.693+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:42:52.694+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.694+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:42:52.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:42:52.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.725+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:42:52.738+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.738+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:42:52.740+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.740+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:42:52.745+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.745+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:42:52.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.747+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:42:52.749+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.749+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:42:52.751+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:42:52.751+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:42:52.772+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.081 seconds
[2024-06-18T15:43:23.014+0000] {processor.py:157} INFO - Started process (PID=17726) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:43:23.015+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:43:23.015+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.015+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:43:23.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:43:23.054+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.054+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:43:23.078+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.078+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:43:23.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.084+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:43:23.086+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.086+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:43:23.087+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.087+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:43:23.089+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.089+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:43:23.091+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:23.091+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:43:23.116+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.105 seconds
[2024-06-18T15:43:53.912+0000] {processor.py:157} INFO - Started process (PID=17977) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:43:53.913+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:43:53.914+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.914+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:43:53.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:43:53.942+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.942+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:43:53.955+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.955+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:43:53.957+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.957+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:43:53.958+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.958+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:43:53.959+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.959+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:43:53.961+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.961+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:43:53.962+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:43:53.962+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:43:53.982+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.073 seconds
[2024-06-18T15:44:24.944+0000] {processor.py:157} INFO - Started process (PID=18221) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:44:24.945+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:44:24.946+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.946+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:44:24.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:44:24.976+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.976+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:44:24.992+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.992+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:44:24.995+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.994+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:44:24.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.995+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:44:24.996+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.996+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:44:24.998+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.998+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:44:24.999+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:24.999+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:44:25.016+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.074 seconds
[2024-06-18T15:44:56.015+0000] {processor.py:157} INFO - Started process (PID=18465) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:44:56.016+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:44:56.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.016+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:44:56.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:44:56.047+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.047+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:44:56.063+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.062+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:44:56.065+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.065+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:44:56.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.066+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:44:56.067+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.067+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:44:56.069+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.068+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:44:56.070+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:44:56.070+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:44:56.089+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.077 seconds
[2024-06-18T15:45:26.910+0000] {processor.py:157} INFO - Started process (PID=18708) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:45:26.911+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:45:26.912+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:26.912+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:45:26.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:45:26.999+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:26.999+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:45:27.011+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.010+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:45:27.012+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.012+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:45:27.013+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.013+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:45:27.013+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.013+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:45:27.015+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.015+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:45:27.016+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:27.016+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:45:27.039+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.132 seconds
[2024-06-18T15:45:57.894+0000] {processor.py:157} INFO - Started process (PID=18953) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:45:57.894+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:45:57.895+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.895+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:45:57.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:45:57.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.917+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:45:57.930+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.929+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:45:57.931+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.931+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:45:57.932+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.932+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:45:57.933+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.933+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:45:57.934+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.934+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:45:57.935+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:45:57.935+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:45:57.954+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.062 seconds
[2024-06-18T15:46:28.427+0000] {processor.py:157} INFO - Started process (PID=19196) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:46:28.432+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:46:28.433+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.433+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:46:28.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:46:28.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.472+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:46:28.493+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.492+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:46:28.500+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.500+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:46:28.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.502+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:46:28.503+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.503+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:46:28.505+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.505+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:46:28.507+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:28.507+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:46:28.529+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.105 seconds
[2024-06-18T15:46:58.597+0000] {processor.py:157} INFO - Started process (PID=19435) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:46:58.599+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:46:58.601+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.601+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:46:58.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:46:58.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.702+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:46:58.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.717+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:46:58.722+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.722+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:46:58.723+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.723+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:46:58.725+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.725+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:46:58.728+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.728+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:46:58.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:46:58.729+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:46:58.752+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.158 seconds
[2024-06-18T15:47:29.205+0000] {processor.py:157} INFO - Started process (PID=19684) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:47:29.206+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:47:29.207+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.207+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:47:29.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:47:29.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.245+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:47:29.259+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.259+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:47:29.262+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.262+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:47:29.265+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.265+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:47:29.267+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.267+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:47:29.269+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.269+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:47:29.271+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:29.271+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:47:29.306+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.104 seconds
[2024-06-18T15:47:59.476+0000] {processor.py:157} INFO - Started process (PID=19922) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:47:59.478+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:47:59.480+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.480+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:47:59.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:47:59.540+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.540+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:47:59.566+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.566+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:47:59.568+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.568+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:47:59.569+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.569+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:47:59.570+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.570+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:47:59.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.572+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:47:59.573+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:47:59.573+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:47:59.597+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.124 seconds
[2024-06-18T15:48:30.375+0000] {processor.py:157} INFO - Started process (PID=20172) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:48:30.376+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:48:30.377+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.376+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:48:30.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:48:30.426+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.426+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:48:30.446+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.446+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:48:30.450+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.450+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:48:30.452+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.452+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:48:30.454+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.454+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:48:30.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.457+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:48:30.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:48:30.458+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:48:30.483+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.110 seconds
[2024-06-18T15:49:00.525+0000] {processor.py:157} INFO - Started process (PID=20411) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:49:00.526+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:49:00.527+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.526+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:49:00.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:49:00.572+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.572+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:49:00.586+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.586+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:49:00.587+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.587+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:49:00.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.588+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:49:00.589+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.589+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:49:00.590+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.590+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:49:00.592+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:00.592+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:49:00.608+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2024-06-18T15:49:31.184+0000] {processor.py:157} INFO - Started process (PID=20661) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:49:31.185+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:49:31.185+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.185+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:49:31.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:49:31.213+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.212+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:49:31.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.226+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:49:31.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:49:31.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:49:31.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.231+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:49:31.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.232+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:49:31.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:49:31.234+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:49:31.254+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.072 seconds
[2024-06-18T15:50:02.214+0000] {processor.py:157} INFO - Started process (PID=20904) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:50:02.215+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:50:02.216+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.215+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:50:02.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:50:02.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.231+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:50:02.243+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.243+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:50:02.245+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.245+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:50:02.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.245+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:50:02.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.246+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:50:02.248+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.248+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:50:02.248+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:02.248+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:50:02.265+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.053 seconds
[2024-06-18T15:50:33.187+0000] {processor.py:157} INFO - Started process (PID=21148) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:50:33.188+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:50:33.189+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.188+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:50:33.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:50:33.214+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.214+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:50:33.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.227+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:50:33.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:50:33.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.231+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:50:33.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.232+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:50:33.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.234+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:50:33.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:50:33.235+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:50:33.257+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.072 seconds
[2024-06-18T15:51:03.319+0000] {processor.py:157} INFO - Started process (PID=21388) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:51:03.320+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:51:03.320+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.320+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:51:03.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:51:03.354+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.353+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:51:03.365+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.365+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:51:03.366+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.366+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:51:03.367+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.367+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:51:03.368+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.368+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:51:03.369+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.369+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:51:03.370+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:03.370+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:51:03.383+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.066 seconds
[2024-06-18T15:51:33.410+0000] {processor.py:157} INFO - Started process (PID=21630) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:51:33.412+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:51:33.413+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.412+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:51:33.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:51:33.446+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.446+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:51:33.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.458+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:51:33.460+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.460+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:51:33.461+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.461+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:51:33.461+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.461+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:51:33.463+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.463+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:51:33.464+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:51:33.464+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:51:33.479+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.074 seconds
[2024-06-18T15:52:04.168+0000] {processor.py:157} INFO - Started process (PID=21874) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:52:04.169+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:52:04.171+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.170+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:52:04.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:52:04.218+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.218+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:52:04.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.233+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:52:04.235+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.235+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:52:04.236+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.236+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:52:04.237+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.237+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:52:04.239+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.238+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:52:04.240+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:04.239+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:52:04.261+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.096 seconds
[2024-06-18T15:52:34.698+0000] {processor.py:157} INFO - Started process (PID=22118) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:52:34.700+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:52:34.701+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.700+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:52:34.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:52:34.739+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.739+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:52:34.750+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.750+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:52:34.752+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.752+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:52:34.753+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.753+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:52:34.753+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.753+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:52:34.755+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.755+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:52:34.756+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:52:34.756+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:52:34.770+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.076 seconds
[2024-06-18T15:53:05.037+0000] {processor.py:157} INFO - Started process (PID=22361) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:53:05.042+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:53:05.046+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.044+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:53:05.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:53:05.106+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.105+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:53:05.123+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.123+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:53:05.127+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.127+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:53:05.128+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.128+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:53:05.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.129+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:53:05.132+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.132+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:53:05.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:05.134+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:53:05.158+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.135 seconds
[2024-06-18T15:53:35.453+0000] {processor.py:157} INFO - Started process (PID=22606) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:53:35.455+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:53:35.456+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.456+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:53:35.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:53:35.502+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.502+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:53:35.519+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.519+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:53:35.522+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.521+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:53:35.522+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.522+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:53:35.523+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.523+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:53:35.525+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.525+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:53:35.525+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:53:35.525+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:53:35.544+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.097 seconds
[2024-06-18T15:54:06.605+0000] {processor.py:157} INFO - Started process (PID=22850) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:54:06.607+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:54:06.609+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.608+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:54:06.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:54:06.669+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.669+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:54:06.683+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.683+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:54:06.685+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.685+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:54:06.685+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.685+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:54:06.686+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.686+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:54:06.690+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.690+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:54:06.691+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:06.691+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:54:06.709+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.111 seconds
[2024-06-18T15:54:36.853+0000] {processor.py:157} INFO - Started process (PID=23094) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:54:36.854+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:54:36.855+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.855+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:54:36.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:54:36.900+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.900+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:54:36.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.914+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:54:36.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.917+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:54:36.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.918+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:54:36.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.920+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:54:36.923+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.923+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:54:36.926+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:54:36.926+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:54:36.947+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.097 seconds
[2024-06-18T15:55:06.994+0000] {processor.py:157} INFO - Started process (PID=23337) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:55:06.996+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:55:06.997+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:06.997+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:55:07.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:55:07.064+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.064+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:55:07.081+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.080+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:55:07.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.083+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:55:07.085+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.085+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:55:07.087+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.087+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:55:07.089+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.089+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:55:07.090+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:07.090+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:55:07.111+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.121 seconds
[2024-06-18T15:55:37.511+0000] {processor.py:157} INFO - Started process (PID=23582) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:55:37.512+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:55:37.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.512+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:55:37.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:55:37.564+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.564+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:55:37.577+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.577+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:55:37.579+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.579+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:55:37.580+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.580+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:55:37.581+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.581+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:55:37.582+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.582+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:55:37.583+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:55:37.583+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:55:37.598+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T15:56:08.450+0000] {processor.py:157} INFO - Started process (PID=23826) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:56:08.452+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:56:08.454+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.453+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:56:08.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:56:08.516+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.515+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:56:08.527+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.527+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:56:08.529+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.529+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:56:08.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.530+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:56:08.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.530+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:56:08.532+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.532+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:56:08.533+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:08.533+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:56:08.549+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.103 seconds
[2024-06-18T15:56:39.350+0000] {processor.py:157} INFO - Started process (PID=24070) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:56:39.350+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:56:39.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.351+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:56:39.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:56:39.380+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.380+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:56:39.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.391+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:56:39.394+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.394+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:56:39.395+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.395+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:56:39.396+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.396+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:56:39.397+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.397+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:56:39.398+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:56:39.398+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:56:39.414+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.066 seconds
[2024-06-18T15:57:09.788+0000] {processor.py:157} INFO - Started process (PID=24314) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:57:09.789+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:57:09.790+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.789+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:57:09.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:57:09.831+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.831+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:57:09.843+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.843+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:57:09.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.844+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:57:09.845+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.845+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:57:09.846+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.846+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:57:09.850+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.850+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:57:09.852+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:09.852+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:57:09.871+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.087 seconds
[2024-06-18T15:57:40.770+0000] {processor.py:157} INFO - Started process (PID=24558) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:57:40.772+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:57:40.772+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.772+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:57:40.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:57:40.832+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.832+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:57:40.846+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.846+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:57:40.849+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.848+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:57:40.849+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.849+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:57:40.850+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.850+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:57:40.852+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.852+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:57:40.853+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:57:40.853+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:57:40.869+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.103 seconds
[2024-06-18T15:58:10.995+0000] {processor.py:157} INFO - Started process (PID=24802) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:58:10.996+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:58:10.997+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:10.997+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:58:11.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:58:11.043+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.043+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:58:11.056+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.056+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:58:11.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.059+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:58:11.061+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.061+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:58:11.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.062+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:58:11.066+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.066+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:58:11.068+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:11.068+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:58:11.096+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.105 seconds
[2024-06-18T15:58:41.967+0000] {processor.py:157} INFO - Started process (PID=25046) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:58:41.969+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:58:41.973+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:41.972+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:58:41.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:58:42.012+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.012+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:58:42.028+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.027+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:58:42.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.030+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:58:42.031+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.031+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:58:42.032+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.032+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:58:42.035+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.035+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:58:42.036+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:58:42.036+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:58:42.056+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.093 seconds
[2024-06-18T15:59:12.687+0000] {processor.py:157} INFO - Started process (PID=25290) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:59:12.688+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:59:12.690+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.689+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:59:12.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:59:12.746+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.746+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:59:12.758+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.758+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:59:12.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.760+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:59:12.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:59:12.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.762+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:59:12.764+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.764+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:59:12.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:12.765+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:59:12.786+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.103 seconds
[2024-06-18T15:59:42.853+0000] {processor.py:157} INFO - Started process (PID=25534) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:59:42.855+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T15:59:42.856+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.856+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:59:42.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T15:59:42.904+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.903+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T15:59:42.921+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.921+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T15:59:42.924+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.924+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T15:59:42.925+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.925+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T15:59:42.926+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.925+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T15:59:42.927+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.927+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T15:59:42.928+0000] {logging_mixin.py:154} INFO - [2024-06-18T15:59:42.928+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T15:59:42.945+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T16:00:12.999+0000] {processor.py:157} INFO - Started process (PID=25778) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:00:13.001+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:00:13.005+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.002+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:00:13.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:00:13.205+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.205+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:00:13.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.221+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:00:13.223+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.223+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:00:13.225+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.225+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:00:13.227+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.227+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:00:13.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:00:13.231+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:13.231+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:00:13.273+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.277 seconds
[2024-06-18T16:00:43.670+0000] {processor.py:157} INFO - Started process (PID=26022) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:00:43.670+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:00:43.671+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.671+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:00:43.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:00:43.708+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.708+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:00:43.724+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.724+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:00:43.727+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.726+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:00:43.727+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.727+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:00:43.729+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.729+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:00:43.732+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.732+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:00:43.733+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:00:43.733+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:00:43.750+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.082 seconds
[2024-06-18T16:01:14.682+0000] {processor.py:157} INFO - Started process (PID=26266) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:01:14.685+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:01:14.690+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.687+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:01:14.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:01:14.733+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.733+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:01:14.745+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.744+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:01:14.746+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.746+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:01:14.747+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.747+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:01:14.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.748+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:01:14.749+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.749+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:01:14.750+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:14.750+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:01:14.765+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.091 seconds
[2024-06-18T16:01:44.841+0000] {processor.py:157} INFO - Started process (PID=26510) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:01:44.843+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:01:44.844+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.843+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:01:44.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:01:44.966+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.966+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:01:44.981+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.981+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:01:44.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.982+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:01:44.983+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.983+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:01:44.984+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.984+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:01:44.985+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.985+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:01:44.986+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:01:44.986+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:01:45.011+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.174 seconds
[2024-06-18T16:02:15.094+0000] {processor.py:157} INFO - Started process (PID=26761) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:02:15.095+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:02:15.095+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.095+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:02:15.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:02:15.124+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.124+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:02:15.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.136+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:02:15.139+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.139+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:02:15.140+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.140+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:02:15.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.140+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:02:15.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.142+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:02:15.143+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:15.143+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:02:15.162+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.071 seconds
[2024-06-18T16:02:45.194+0000] {processor.py:157} INFO - Started process (PID=27004) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:02:45.195+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:02:45.195+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.195+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:02:45.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:02:45.218+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.218+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:02:45.228+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.227+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:02:45.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:02:45.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:02:45.230+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.230+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:02:45.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.232+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:02:45.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:02:45.232+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:02:45.245+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.052 seconds
[2024-06-18T16:03:15.425+0000] {processor.py:157} INFO - Started process (PID=27241) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:03:15.426+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:03:15.427+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.427+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:03:15.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:03:15.472+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.472+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:03:15.484+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.484+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:03:15.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.486+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:03:15.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:03:15.488+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.488+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:03:15.490+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.490+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:03:15.490+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:15.490+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:03:15.507+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T16:03:45.589+0000] {processor.py:157} INFO - Started process (PID=27485) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:03:45.592+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:03:45.593+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.593+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:03:45.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:03:45.628+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.628+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:03:45.639+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.639+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:03:45.641+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.641+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:03:45.642+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.642+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:03:45.642+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.642+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:03:45.645+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.645+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:03:45.646+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:03:45.646+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:03:45.661+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.077 seconds
[2024-06-18T16:04:15.697+0000] {processor.py:157} INFO - Started process (PID=27729) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:04:15.698+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:04:15.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.698+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:04:15.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:04:15.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.741+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:04:15.757+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.757+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:04:15.759+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.759+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:04:15.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.760+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:04:15.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:04:15.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.762+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:04:15.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:15.763+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:04:15.787+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.093 seconds
[2024-06-18T16:04:45.876+0000] {processor.py:157} INFO - Started process (PID=27975) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:04:45.878+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:04:45.881+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.880+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:04:45.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:04:45.905+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.905+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:04:45.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.916+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:04:45.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.918+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:04:45.919+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.919+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:04:45.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.920+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:04:45.921+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.921+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:04:45.922+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:04:45.922+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:04:45.936+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.062 seconds
[2024-06-18T16:05:16.626+0000] {processor.py:157} INFO - Started process (PID=28224) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:05:16.627+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:05:16.627+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.627+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:05:16.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:05:16.667+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.667+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:05:16.697+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.697+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:05:16.700+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.700+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:05:16.701+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.701+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:05:16.704+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.703+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:05:16.708+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.707+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:05:16.710+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:16.710+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:05:16.725+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.102 seconds
[2024-06-18T16:05:47.068+0000] {processor.py:157} INFO - Started process (PID=28461) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:05:47.069+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:05:47.070+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.070+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:05:47.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:05:47.121+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.121+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:05:47.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.132+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:05:47.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.134+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:05:47.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.135+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:05:47.135+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.135+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:05:47.137+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.137+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:05:47.138+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:05:47.138+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:05:47.153+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.087 seconds
[2024-06-18T16:06:17.380+0000] {processor.py:157} INFO - Started process (PID=28707) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:06:17.381+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:06:17.382+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.382+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:06:17.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:06:17.416+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.416+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:06:17.431+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.431+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:06:17.434+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.434+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:06:17.435+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.435+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:06:17.435+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.435+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:06:17.437+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.437+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:06:17.438+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:17.438+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:06:17.455+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.077 seconds
[2024-06-18T16:06:47.498+0000] {processor.py:157} INFO - Started process (PID=28951) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:06:47.499+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:06:47.499+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.499+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:06:47.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:06:47.526+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.526+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:06:47.539+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.538+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:06:47.541+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.541+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:06:47.542+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.542+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:06:47.543+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.543+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:06:47.545+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.544+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:06:47.545+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:06:47.545+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:06:47.561+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.066 seconds
[2024-06-18T16:07:17.855+0000] {processor.py:157} INFO - Started process (PID=29193) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:07:17.859+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:07:17.862+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.861+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:07:17.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:07:17.902+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.902+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:07:17.913+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.912+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:07:17.914+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.914+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:07:17.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.915+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:07:17.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.915+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:07:17.917+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.917+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:07:17.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:17.918+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:07:17.933+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.090 seconds
[2024-06-18T16:07:48.185+0000] {processor.py:157} INFO - Started process (PID=29437) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:07:48.187+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:07:48.191+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.189+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:07:48.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:07:48.232+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.232+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:07:48.244+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.244+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:07:48.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.246+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:07:48.246+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.246+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:07:48.247+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.247+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:07:48.248+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.248+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:07:48.250+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:07:48.250+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:07:48.264+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.081 seconds
[2024-06-18T16:08:18.352+0000] {processor.py:157} INFO - Started process (PID=29683) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:08:18.353+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:08:18.354+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.354+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:08:18.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:08:18.377+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.377+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:08:18.388+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.388+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:08:18.390+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.390+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:08:18.391+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.391+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:08:18.392+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.392+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:08:18.393+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.393+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:08:18.394+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:18.394+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:08:18.408+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.058 seconds
[2024-06-18T16:08:48.526+0000] {processor.py:157} INFO - Started process (PID=29925) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:08:48.527+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:08:48.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.529+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:08:48.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:08:48.565+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.565+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:08:48.579+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.579+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:08:48.582+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.582+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:08:48.582+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.582+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:08:48.583+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.583+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:08:48.585+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.585+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:08:48.586+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:08:48.586+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:08:48.601+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.100 seconds
[2024-06-18T16:46:36.837+0000] {processor.py:157} INFO - Started process (PID=30175) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:46:36.838+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T16:46:36.838+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.838+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:46:36.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T16:46:36.893+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.893+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T16:46:36.939+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.939+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T16:46:36.942+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.942+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T16:46:36.944+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.944+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T16:46:36.946+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.945+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T16:46:36.952+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.952+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T16:46:36.955+0000] {logging_mixin.py:154} INFO - [2024-06-18T16:46:36.954+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T16:46:36.996+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.161 seconds
[2024-06-18T17:23:55.624+0000] {processor.py:157} INFO - Started process (PID=30420) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:23:55.626+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:23:55.627+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.627+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:23:55.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:23:55.684+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.684+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:23:55.759+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.759+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:23:55.763+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.763+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:23:55.765+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.765+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:23:55.768+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.768+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:23:55.775+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.775+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:23:55.777+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:23:55.776+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:23:55.811+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.190 seconds
[2024-06-18T17:24:26.746+0000] {processor.py:157} INFO - Started process (PID=30665) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:24:26.747+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:24:26.748+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.747+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:24:26.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:24:26.784+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.784+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:24:26.800+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.800+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:24:26.804+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.803+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:24:26.806+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.806+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:24:26.808+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.808+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:24:26.811+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.811+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:24:26.814+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:26.814+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:24:26.839+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.096 seconds
[2024-06-18T17:24:57.047+0000] {processor.py:157} INFO - Started process (PID=30906) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:24:57.048+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:24:57.049+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.049+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:24:57.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:24:57.103+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.102+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:24:57.126+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.126+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:24:57.129+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.129+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:24:57.131+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.131+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:24:57.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.133+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:24:57.138+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.137+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:24:57.139+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:24:57.139+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:24:57.172+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.128 seconds
[2024-06-18T17:25:28.028+0000] {processor.py:157} INFO - Started process (PID=31153) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:25:28.030+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:25:28.031+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.030+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:25:28.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:25:28.074+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.074+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:25:28.090+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.090+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:25:28.092+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.092+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:25:28.093+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.093+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:25:28.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.094+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:25:28.101+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.101+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:25:28.102+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:28.102+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:25:28.127+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.103 seconds
[2024-06-18T17:25:58.325+0000] {processor.py:157} INFO - Started process (PID=31394) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:25:58.326+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:25:58.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.327+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:25:58.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:25:58.375+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.375+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:25:58.409+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.409+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:25:58.412+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.412+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:25:58.413+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.413+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:25:58.417+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.416+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:25:58.422+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.421+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:25:58.423+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:25:58.422+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:25:58.462+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.139 seconds
[2024-06-18T17:26:29.414+0000] {processor.py:157} INFO - Started process (PID=31643) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:26:29.415+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:26:29.416+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.416+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:26:29.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:26:29.445+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.445+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:26:29.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.457+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:26:29.458+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.458+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:26:29.459+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.459+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:26:29.460+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.460+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:26:29.461+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.461+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:26:29.462+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:29.462+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:26:29.477+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.065 seconds
[2024-06-18T17:26:59.984+0000] {processor.py:157} INFO - Started process (PID=31887) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:26:59.986+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:26:59.988+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:26:59.987+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:26:59.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:27:00.028+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.028+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:27:00.046+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.046+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:27:00.050+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.049+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:27:00.051+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.051+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:27:00.052+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.052+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:27:00.057+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.056+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:27:00.059+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:00.059+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:27:00.078+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.096 seconds
[2024-06-18T17:27:30.839+0000] {processor.py:157} INFO - Started process (PID=32131) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:27:30.841+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:27:30.842+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.841+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:27:30.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:27:30.898+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.898+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:27:30.912+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.912+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:27:30.914+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.914+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:27:30.915+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.915+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:27:30.916+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.916+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:27:30.918+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.918+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:27:30.920+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:27:30.919+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:27:30.937+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.100 seconds
[2024-06-18T17:28:01.545+0000] {processor.py:157} INFO - Started process (PID=32375) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:28:01.548+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:28:01.550+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.550+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:28:01.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:28:01.586+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.586+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:28:01.601+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.601+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:28:01.604+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.604+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:28:01.605+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.605+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:28:01.607+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.606+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:28:01.610+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.610+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:28:01.611+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:01.611+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:28:01.635+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.093 seconds
[2024-06-18T17:28:31.942+0000] {processor.py:157} INFO - Started process (PID=32619) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:28:31.943+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:28:31.945+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:31.944+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:28:31.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:28:31.987+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:31.986+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:28:32.001+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.001+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:28:32.003+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.003+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:28:32.004+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.004+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:28:32.005+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.005+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:28:32.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.007+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:28:32.009+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:28:32.009+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:28:32.032+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.095 seconds
[2024-06-18T17:29:02.297+0000] {processor.py:157} INFO - Started process (PID=32863) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:29:02.298+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:29:02.299+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.299+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:29:02.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:29:02.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.336+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:29:02.349+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.349+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:29:02.351+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.351+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:29:02.352+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.352+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:29:02.353+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.353+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:29:02.355+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.355+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:29:02.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:02.359+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:29:02.392+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.097 seconds
[2024-06-18T17:29:33.140+0000] {processor.py:157} INFO - Started process (PID=33106) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:29:33.143+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:29:33.146+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.145+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:29:33.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:29:33.187+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.187+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:29:33.216+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.216+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:29:33.221+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.220+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:29:33.226+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.226+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:29:33.229+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.229+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:29:33.233+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.233+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:29:33.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:29:33.234+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:29:33.252+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.124 seconds
[2024-06-18T17:30:03.831+0000] {processor.py:157} INFO - Started process (PID=33350) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:30:03.833+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:30:03.834+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.834+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:30:03.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:30:03.879+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.879+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:30:03.892+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.892+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:30:03.894+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.894+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:30:03.895+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.894+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:30:03.895+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.895+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:30:03.897+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.897+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:30:03.898+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:03.897+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:30:03.912+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.086 seconds
[2024-06-18T17:30:34.229+0000] {processor.py:157} INFO - Started process (PID=33594) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:30:34.230+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:30:34.234+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.233+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:30:34.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:30:34.264+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.264+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:30:34.275+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.275+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:30:34.278+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.278+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:30:34.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.278+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:30:34.279+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.279+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:30:34.281+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.281+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:30:34.282+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:30:34.282+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:30:34.298+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.070 seconds
[2024-06-18T17:31:04.460+0000] {processor.py:157} INFO - Started process (PID=33838) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:31:04.461+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:31:04.462+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.462+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:31:04.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:31:04.497+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.497+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:31:04.519+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.519+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:31:04.523+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.523+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:31:04.525+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.524+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:31:04.526+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.526+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:31:04.530+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.530+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:31:04.534+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:04.533+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:31:04.556+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.099 seconds
[2024-06-18T17:31:34.647+0000] {processor.py:157} INFO - Started process (PID=34082) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:31:34.649+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:31:34.650+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.650+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:31:34.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:31:34.698+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.698+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:31:34.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.713+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:31:34.716+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.715+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:31:34.718+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.717+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:31:34.719+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.719+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:31:34.721+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.721+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:31:34.722+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:31:34.722+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:31:34.751+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.108 seconds
[2024-06-18T17:32:05.447+0000] {processor.py:157} INFO - Started process (PID=34326) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:32:05.449+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:32:05.452+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.451+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:32:05.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:32:05.537+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.537+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:32:05.570+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.570+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:32:05.574+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.573+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:32:05.577+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.577+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:32:05.580+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.579+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:32:05.584+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.583+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:32:05.588+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:05.588+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:32:05.619+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.193 seconds
[2024-06-18T17:32:36.059+0000] {processor.py:157} INFO - Started process (PID=34570) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:32:36.060+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:32:36.062+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.061+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:32:36.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:32:36.109+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.109+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:32:36.122+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.122+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:32:36.125+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.125+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:32:36.126+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.126+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:32:36.127+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.127+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:32:36.129+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.129+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:32:36.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:32:36.130+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:32:36.150+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.097 seconds
[2024-06-18T17:33:06.578+0000] {processor.py:157} INFO - Started process (PID=34813) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:33:06.580+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:33:06.581+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.581+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:33:06.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:33:06.625+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.625+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:33:06.638+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.637+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:33:06.640+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.639+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:33:06.640+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.640+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:33:06.641+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.641+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:33:06.643+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.643+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:33:06.644+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:06.644+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:33:06.662+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.089 seconds
[2024-06-18T17:33:37.091+0000] {processor.py:157} INFO - Started process (PID=35057) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:33:37.093+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:33:37.094+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.094+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:33:37.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:33:37.130+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.130+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:33:37.145+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.145+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:33:37.147+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.147+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:33:37.148+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.148+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:33:37.149+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.149+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:33:37.151+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.151+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:33:37.152+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:33:37.152+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:33:37.172+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2024-06-18T17:34:07.742+0000] {processor.py:157} INFO - Started process (PID=35301) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:34:07.743+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:34:07.744+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.744+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:34:07.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:34:07.774+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.774+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:34:07.787+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.787+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:34:07.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.789+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:34:07.791+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.791+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:34:07.792+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.792+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:34:07.793+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.793+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:34:07.794+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:07.794+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:34:07.813+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.075 seconds
[2024-06-18T17:34:38.082+0000] {processor.py:157} INFO - Started process (PID=35545) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:34:38.083+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:34:38.084+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.084+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:34:38.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:34:38.120+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.120+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:34:38.134+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.133+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:34:38.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.136+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:34:38.138+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.137+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:34:38.139+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.139+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:34:38.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.141+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:34:38.142+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:34:38.142+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:34:38.163+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T17:35:08.563+0000] {processor.py:157} INFO - Started process (PID=35790) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:35:08.602+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:35:08.603+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.602+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:35:08.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:35:08.638+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.637+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:35:08.652+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.652+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:35:08.654+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.654+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:35:08.655+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.655+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:35:08.656+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.656+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:35:08.657+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.657+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:35:08.658+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:08.658+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:35:08.675+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.117 seconds
[2024-06-18T17:35:38.972+0000] {processor.py:157} INFO - Started process (PID=36034) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:35:38.974+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:35:38.975+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:38.975+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:35:38.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:35:39.007+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.007+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:35:39.022+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.022+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:35:39.025+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.025+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:35:39.027+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.027+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:35:39.030+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.029+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:35:39.033+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.032+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:35:39.034+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:35:39.034+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:35:39.054+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T17:36:09.708+0000] {processor.py:157} INFO - Started process (PID=36277) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:36:09.711+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:36:09.713+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.712+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:36:09.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:36:09.760+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.760+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:36:09.777+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.777+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:36:09.779+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.779+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:36:09.780+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.780+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:36:09.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.782+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:36:09.785+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.785+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:36:09.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:09.786+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:36:09.805+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.103 seconds
[2024-06-18T17:36:40.372+0000] {processor.py:157} INFO - Started process (PID=36521) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:36:40.399+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:36:40.400+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.400+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:36:40.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:36:40.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.469+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:36:40.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:36:40.491+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.491+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:36:40.492+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.492+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:36:40.494+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.494+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:36:40.498+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.498+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:36:40.500+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:36:40.500+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:36:40.519+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.157 seconds
[2024-06-18T17:37:11.079+0000] {processor.py:157} INFO - Started process (PID=36765) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:37:11.081+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:37:11.082+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.082+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:37:11.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:37:11.116+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.116+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:37:11.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.133+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:37:11.136+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.136+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:37:11.137+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.137+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:37:11.138+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.138+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:37:11.140+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.140+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:37:11.141+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:11.141+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:37:11.161+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.087 seconds
[2024-06-18T17:37:41.725+0000] {processor.py:157} INFO - Started process (PID=37009) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:37:41.731+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:37:41.732+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.732+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:37:41.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:37:41.771+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.771+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:37:41.783+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.783+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:37:41.785+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.785+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:37:41.786+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.786+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:37:41.788+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.788+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:37:41.789+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.789+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:37:41.790+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:37:41.790+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:37:41.807+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.087 seconds
[2024-06-18T17:38:12.125+0000] {processor.py:157} INFO - Started process (PID=37253) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:38:12.126+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:38:12.127+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.126+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:38:12.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:38:12.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.159+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:38:12.179+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.179+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:38:12.187+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.187+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:38:12.190+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.190+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:38:12.191+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.191+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:38:12.193+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.193+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:38:12.196+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:12.196+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:38:12.224+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.102 seconds
[2024-06-18T17:38:42.699+0000] {processor.py:157} INFO - Started process (PID=37504) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:38:42.701+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:38:42.702+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.702+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:38:42.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:38:42.741+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.741+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:38:42.756+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.755+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:38:42.758+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.758+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:38:42.759+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.759+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:38:42.759+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.759+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:38:42.761+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.761+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:38:42.762+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:38:42.762+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:38:42.781+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.086 seconds
[2024-06-18T17:39:13.466+0000] {processor.py:157} INFO - Started process (PID=37748) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:39:13.468+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T17:39:13.469+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.469+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:39:13.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T17:39:13.511+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.510+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T17:39:13.523+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.523+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T17:39:13.525+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.525+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T17:39:13.526+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.526+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T17:39:13.527+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.526+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T17:39:13.529+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.528+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T17:39:13.529+0000] {logging_mixin.py:154} INFO - [2024-06-18T17:39:13.529+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T17:39:13.545+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.084 seconds
[2024-06-18T18:11:08.331+0000] {processor.py:157} INFO - Started process (PID=37986) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T18:11:08.334+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T18:11:08.336+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.336+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T18:11:08.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T18:11:08.429+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.428+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T18:11:08.481+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.481+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T18:11:08.484+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.484+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T18:11:08.485+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.485+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T18:11:08.487+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.487+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T18:11:08.489+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.489+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T18:11:08.491+0000] {logging_mixin.py:154} INFO - [2024-06-18T18:11:08.490+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T18:11:08.525+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.211 seconds
[2024-06-18T19:34:54.453+0000] {processor.py:157} INFO - Started process (PID=38230) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T19:34:54.455+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T19:34:54.457+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.457+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T19:34:54.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T19:34:54.498+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.498+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T19:34:54.513+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.513+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T19:34:54.516+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.516+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T19:34:54.517+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.517+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T19:34:54.518+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.518+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T19:34:54.520+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.520+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T19:34:54.521+0000] {logging_mixin.py:154} INFO - [2024-06-18T19:34:54.521+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T19:34:54.543+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.094 seconds
[2024-06-18T20:57:01.159+0000] {processor.py:157} INFO - Started process (PID=38474) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T20:57:01.194+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T20:57:01.208+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.207+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T20:57:01.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T20:57:01.395+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.395+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T20:57:01.410+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.410+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T20:57:01.413+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.413+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T20:57:01.414+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.414+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T20:57:01.415+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.415+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T20:57:01.417+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.417+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T20:57:01.418+0000] {logging_mixin.py:154} INFO - [2024-06-18T20:57:01.418+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T20:57:01.440+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.290 seconds
[2024-06-18T22:35:26.325+0000] {processor.py:157} INFO - Started process (PID=38718) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T22:35:26.326+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T22:35:26.327+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.327+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T22:35:26.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T22:35:26.359+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.359+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T22:35:26.376+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.376+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T22:35:26.379+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.378+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T22:35:26.385+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.384+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T22:35:26.389+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.388+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T22:35:26.401+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.400+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T22:35:26.405+0000] {logging_mixin.py:154} INFO - [2024-06-18T22:35:26.405+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T22:35:26.478+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.157 seconds
[2024-06-18T23:55:33.814+0000] {processor.py:157} INFO - Started process (PID=38962) to work on /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T23:55:33.834+0000] {processor.py:829} INFO - Processing file /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2024-06-18T23:55:33.847+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:33.847+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T23:55:33.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1']) retrieved from /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py
[2024-06-18T23:55:34.133+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.133+0000] {dag.py:2941} INFO - Sync 6 DAGs
[2024-06-18T23:55:34.152+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.152+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2024-06-18T23:55:34.155+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.155+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2024-06-18T23:55:34.157+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.157+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2024-06-18T23:55:34.159+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.159+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2024-06-18T23:55:34.161+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.160+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_1 to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
[2024-06-18T23:55:34.163+0000] {logging_mixin.py:154} INFO - [2024-06-18T23:55:34.163+0000] {dag.py:3722} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2024-06-18T23:55:34.194+0000] {processor.py:179} INFO - Processing /home/airflow/.local/lib/python3.8/site-packages/airflow/example_dags/example_datasets.py took 0.386 seconds
