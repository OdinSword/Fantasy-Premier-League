[2024-06-22T14:34:36.101+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: kafka_spark_dag.kafka_data_stream scheduled__2024-06-22T14:29:34.981921+00:00 [queued]>
[2024-06-22T14:34:36.105+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: kafka_spark_dag.kafka_data_stream scheduled__2024-06-22T14:29:34.981921+00:00 [queued]>
[2024-06-22T14:34:36.106+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2024-06-22T14:34:36.113+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): kafka_data_stream> on 2024-06-22 14:29:34.981921+00:00
[2024-06-22T14:34:36.116+0000] {standard_task_runner.py:57} INFO - Started process 63823 to run task
[2024-06-22T14:34:36.118+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'kafka_spark_dag', 'kafka_data_stream', 'scheduled__2024-06-22T14:29:34.981921+00:00', '--job-id', '2029', '--raw', '--subdir', 'DAGS_FOLDER/dag_kafka_spark.py', '--cfg-path', '/tmp/tmpva5_ik0p']
[2024-06-22T14:34:36.119+0000] {standard_task_runner.py:85} INFO - Job 2029: Subtask kafka_data_stream
[2024-06-22T14:34:36.143+0000] {task_command.py:416} INFO - Running <TaskInstance: kafka_spark_dag.kafka_data_stream scheduled__2024-06-22T14:29:34.981921+00:00 [running]> on host 2ad9230613d5
[2024-06-22T14:34:36.178+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.ForeignKeyViolation: insert or update on table "rendered_task_instance_fields" violates foreign key constraint "rtif_ti_fkey"
DETAIL:  Key (dag_id, task_id, run_id, map_index)=(kafka_spark_dag, kafka_data_stream, scheduled__2024-06-22T14:29:34.981921+00:00, -1) is not present in table "task_instance".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1518, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1651, in _execute_task_with_callbacks
    RenderedTaskInstanceFields.write(rtif)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.8/contextlib.py", line 120, in __exit__
    next(self.gen)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 39, in create_session
    session.commit()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3589, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.ForeignKeyViolation) insert or update on table "rendered_task_instance_fields" violates foreign key constraint "rtif_ti_fkey"
DETAIL:  Key (dag_id, task_id, run_id, map_index)=(kafka_spark_dag, kafka_data_stream, scheduled__2024-06-22T14:29:34.981921+00:00, -1) is not present in table "task_instance".

[SQL: INSERT INTO rendered_task_instance_fields (dag_id, task_id, run_id, map_index, rendered_fields, k8s_pod_yaml) VALUES (%(dag_id)s, %(task_id)s, %(run_id)s, %(map_index)s, %(rendered_fields)s, %(k8s_pod_yaml)s)]
[parameters: {'dag_id': 'kafka_spark_dag', 'task_id': 'kafka_data_stream', 'run_id': 'scheduled__2024-06-22T14:29:34.981921+00:00', 'map_index': -1, 'rendered_fields': '{"templates_dict": null, "op_args": [], "op_kwargs": {}}', 'k8s_pod_yaml': 'null'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2024-06-22T14:34:36.191+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=kafka_spark_dag, task_id=kafka_data_stream, execution_date=20240622T142934, start_date=20240622T143436, end_date=20240622T143436
[2024-06-22T14:34:36.196+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 2029 for task kafka_data_stream ((psycopg2.errors.ForeignKeyViolation) update or delete on table "dag_run" violates foreign key constraint "task_instance_dag_run_fkey" on table "task_instance"
DETAIL:  Key (dag_id, run_id)=(kafka_spark_dag, scheduled__2024-06-12T10:08:45.496202+00:00) is still referenced from table "task_instance".

[SQL: UPDATE dag_run SET queued_at=%(queued_at)s, execution_date=%(execution_date)s, start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, run_id=%(run_id)s, creating_job_id=%(creating_job_id)s, data_interval_start=%(data_interval_start)s, data_interval_end=%(data_interval_end)s, last_scheduling_decision=%(last_scheduling_decision)s, dag_hash=%(dag_hash)s, updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'queued_at': datetime.datetime(2024, 6, 22, 14, 34, 35, 359605, tzinfo=Timezone('UTC')), 'execution_date': datetime.datetime(2024, 6, 22, 14, 29, 34, 981921, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2024, 6, 22, 14, 34, 35, 368779, tzinfo=Timezone('UTC')), 'end_date': None, 'state': 'running', 'run_id': 'scheduled__2024-06-22T14:29:34.981921+00:00', 'creating_job_id': 246, 'data_interval_start': datetime.datetime(2024, 6, 22, 14, 29, 34, 981921, tzinfo=Timezone('UTC')), 'data_interval_end': datetime.datetime(2024, 6, 22, 14, 34, 34, 981921, tzinfo=Timezone('UTC')), 'last_scheduling_decision': datetime.datetime(2024, 6, 22, 14, 34, 35, 690206, tzinfo=Timezone('UTC')), 'dag_hash': '2c61da43d3adc4ae30aef6136a9f0fee', 'updated_at': datetime.datetime(2024, 6, 22, 14, 34, 35, 693113, tzinfo=Timezone('UTC')), 'dag_run_id': 234}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 63823)
[2024-06-22T14:34:36.216+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-06-22T14:34:36.227+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
